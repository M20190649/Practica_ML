 false discovery rate control statistical quality assessment annotator crowdsourced ranking rapid growth crowdsourcing platform become easy relatively inexpensive collect dataset label multiple annotator short time however due lack control quality annotator abnormal annotator may affect position bias potentially degrade quality final consensus label paper introduce statistical framework model detect annotator 's position bias order control false discovery rate fdr without prior knowledge amount biased annotator expected fraction false discovery among discovery high order assure discovery indeed true replicable key technical development relies new knockoff filter adapt problem new algorithm base inverse scale space dynamic whose discretization potentially suitable large scale crowdsourcing data analysis study support experiment simulated example real-world data propose framework provide u useful tool quantitatively study annotator 's abnormal behavior crowdsourcing data arise machine learning sociology computer vision multimedia etc