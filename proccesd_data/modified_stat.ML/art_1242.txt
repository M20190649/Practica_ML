 binarsity penalization one-hot encoded feature linear supervise learn paper deal problem large-scale linear supervise learning setting large number continuous feature available propose combine well-known trick one-hot encoding continuous feature new penalization call emph binarsity group binary feature come one-hot encoding single raw continuous feature penalization use total-variation regularization together extra linear constraint induce two interesting property model weight one-hot encoded feature piecewise constant eventually block sparse non-asymptotic oracle inequality generalized linear model propose moreover sparse additive model assumption prove procedure match state-of-the-art setting numerical experiment illustrate good performance approach several datasets also noteworthy method numerical complexity comparable standard ell penalization