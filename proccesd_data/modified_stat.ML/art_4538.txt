 zero-truncated poisson tensor factorization massive binary tensor present scalable bayesian model low-rank factorization massive tensor binary observation propose model following key property contrast model base logistic probit likelihood use zero-truncated poisson likelihood binary data allow model scale number emph one tensor especially appeal massive sparse binary tensor side-information form binary pairwise relationship e.g. adjacency network object tensor mode also leverage especially useful cold-start setting model admit simple bayesian inference via batch well emph online mcmc latter allows scale even emph dense binary data i.e. number one tensor network also massive addition non-negative factor matrix model provide easy interpretability tensor rank infer data evaluate model several large-scale real-world binary tensor achieve excellent computational scalability also demonstrate usefulness leverage side-information provide form mode-network