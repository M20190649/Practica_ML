 thompson sample complex bandit problem consider stochastic multi-armed bandit problem complex action set basic arm decision maker play complex action rather basic arm round reward complex action function basic arm reward feedback observe may necessarily reward per-arm instance complex action subset arm may observe maximum reward chosen subset thus feedback across complex action may couple due nature reward function prove frequentist regret bound thompson sampling general set involve parameter action observation space likelihood function bound hold discretely-supported prior parameter space without additional structural property closed-form posterior conjugate prior structure independence across arm regret bound scale logarithmically time importantly improved constant non-trivially capture coupling across complex action due structure reward application derive improve regret bound class complex bandit problem involve select subset arm include first nontrivial regret bound nonlinear max reward feedback subset