 second order linear model study fundamental class regression model call second order linear model slm slm extend linear model high order functional space attract considerable research interest recently yet efficiently learn slm full generality use nonconvex solver still remain open question due several fundamental limitation conventional gradient descent learn framework study try attack problem gradient-free approach call moment-estimation-sequence me method show conventional gradient descent heuristic bias skewness distribution therefore longer best practice learn slm base me framework design nonconvex alternate iteration process train -dimension rank- k slm within kd memory one-pass dataset propose method converge globally linearly achieve epsilon recovery error retrieve k cdot mathrm polylog kd epsilon sample furthermore theoretical analysis reveals slms learn every sub-gaussian distribution instance sample so-called tau -mip distribution slm learn p tau sample p tau positive constant depend skewness kurtosis distribution non-mip distribution addition diagonal-free oracle necessary sufficient guarantee learnability slm numerical simulation verify sharpness bound sampling complexity linear convergence rate algorithm