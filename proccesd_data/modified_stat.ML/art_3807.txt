 efficient approach escape high order saddle point non-convex optimization local search heuristic non-convex optimization popular applied machine learning however general hard guarantee algorithm even converge local minimum due existence complicated saddle point structure high dimension many function degenerate saddle point first second order derivative distinguish local optimum paper use high order derivative escape saddle point design first efficient algorithm guarantee converge third order local optimum exist technique second order also show np-hard extend find fourth order local optimum