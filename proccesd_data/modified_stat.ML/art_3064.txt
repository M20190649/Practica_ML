 high-performance distribute ml scale parameter server consistency model machine learn ml application increase data size model complexity practitioner turn distribute cluster satisfy increase computational memory demand unfortunately effective use cluster ml require considerable expertise write distributed code highly-abstracted framework like hadoop practice approach performance see specialized ml implementation recent parameter server p paradigm middle ground extreme allow easy conversion single-machine parallel ml application distribute one maintain high throughput relaxed consistency model allow inconsistent parameter read however due insufficient theoretical study clear consistency model really ensure correct ml algorithm output time remain many theoretically-motivated undiscovered opportunity maximize computational throughput motivate challenge study theoretical guarantee empirical behavior iterative-convergent ml algorithm exist p consistency model use gleaned insight improve consistency model use eager p communication mechanism implement new p system enable ml algorithm reach solution quickly