 importance sample stochastic optimization variational inference variational inference approximate posterior distribution probabilistic model parameterized density maximize low bound model evidence modern solution fit flexible approximation stochastic gradient descent use monte carlo approximation gradient enable variational inference arbitrary differentiable probabilistic model consequently make variational inference feasible probabilistic programming language work develop efficient inference algorithm task consider importance sampling estimate gradient show gradient respect approximation parameter often evaluate efficiently without need re-compute gradient model proceed derive practical algorithm use importance sample estimate speed computation.we present importance sample stochastic gradient descent outperform standard stochastic gradient descent clear margin range model provide justifiable variant stochastic average gradient variational inference