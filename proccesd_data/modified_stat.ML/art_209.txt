 efficient hierarchical clustering continuous data present new sequential monte carlo sampler coalescent base bayesian hierarchical clustering model appropriate model non-i.i.d data offer substantial reduction computational cost compare original sampler without resort approximation also propose quadratic complexity approximation practice show almost loss performance compare counterpart show byproduct formulation obtain greedy algorithm exhibit performance improvement greedy algorithm particularly small data set order exploit correlation structure data describe incorporate gaussian process prior model flexible way model non-i.i.d data result artificial real data show significant improvement closely related approach