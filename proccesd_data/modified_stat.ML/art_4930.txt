 rich theory convex constrain optimization reduced projection improve rate paper focus convex constrain optimization problem solution subject convex inequality constraint particular aim challenge problem projection constrain domain linear optimization inequality constraint time-consuming render project gradient method conditional gradient method a.k.a frank-wolfe algorithm expensive paper develop projection reduce optimization algorithm smooth non-smooth optimization improved convergence rate certain regularity condition constraint function first present general theory optimization one projection application smooth optimization one projection yield epsilon iteration complexity improve epsilon iteration complexity establish non-smooth optimization reduce strong convexity introduce local error bound condition develop fast algorithm non-strongly convex optimization price logarithmic number projection particular achieve iteration complexity widetilde epsilon theta non-smooth optimization widetilde epsilon theta smooth optimization theta appear local error bound condition characterize functional local growth rate around optimal solution novel application solve constrain ell minimization problem positive semi-definite constrain distance metric learning problem demonstrate propose algorithm achieve significant speed-up compare previous algorithm