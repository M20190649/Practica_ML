 cluster scale sublinearly cluster variational em acceleration gmms k -means one iteration standard k -means i.e. lloyd 's algorithm standard em gaussian mixture model gmms scale linearly number cluster c data point n data dimensionality study explore whether one iteration k -means em gmms scale sublinearly c run-time improve cluster objective remains effective tool apply complexity reduction variational em typically use make training generative model exponentially many hidden state tractable apply novel theoretical result truncated variational em make tractable cluster algorithms efficient basic idea use partial variational e-step reduce linear complexity mathcal ncd require full e-step sublinear complexity main observation linear dependency c reduce dependency much small parameter g relate cluster neighborhood relation focus two version partial variational em clustering variational gmm scale mathcal ng variational k -means scale mathcal ngd per iteration empirical result show algorithm still require comparable number iteration improve cluster objective value k -means data many cluster consequently observe reduction net computational demand two three order magnitude generally result provide substantial empirical evidence favor cluster scale sublinearly c