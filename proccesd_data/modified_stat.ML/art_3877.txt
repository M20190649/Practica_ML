 hyperband novel bandit-based approach hyperparameter optimization performance machine learn algorithms depends critically identify good set hyperparameters recent approach use bayesian optimization adaptively select configuration focus speed random search adaptive resource allocation early-stopping formulate hyperparameter optimization pure-exploration non-stochastic infinite-armed bandit problem predefined resource like iteration data sample feature allocate randomly sampled configuration introduce novel algorithm hyperband framework analyze theoretical property provide several desirable guarantee furthermore compare hyperband popular bayesian optimization method suite hyperparameter optimization problem observe hyperband provide order-of-magnitude speedup competitor set variety deep-learning kernel-based learning problem