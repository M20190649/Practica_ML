 spectral algorithm latent junction tree latent variable model elegant framework capture rich probabilistic dependency many application however current approach typically parametrize model use conditional probability table learn relies predominantly local search heuristic expectation maximization use tensor algebra propose alternative parameterization latent variable model model structure junction tree still allow computation marginals among observed variable novel representation lead moderate increase number parameter junction tree low treewidth let u design local-minimum-free algorithm learn parameterization main computation algorithm involve tensor operation svds order magnitude faster em algorithm large datasets knowledge first provably consistent parameter learning technique large class low-treewidth latent graphical model beyond tree demonstrate advantage method synthetic real datasets