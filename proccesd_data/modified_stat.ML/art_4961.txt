 softplus regression convex polytopes construct flexible nonlinear predictive distribution paper introduce family softplus function base regression model convolve stack combine operation convolve countably infinite stack gamma distribution whose scale depend covariates generalize logistic regression use single hyperplane partition covariate space two half softplus regression employ multiple hyperplanes construct confined space relate single convex polytope define intersection multiple half-spaces union multiple convex polytopes separate one class gamma process introduce support convolution countably infinite stack covariate-dependent gamma distribution bayesian inference gibbs sample derive via novel data augmentation marginalization technique use deconvolve demix highly complex nonlinear predictive distribution example result demonstrate softplus regression provide flexible nonlinear decision boundary achieve classification accuracy comparable kernel support vector machine require significant less computation out-of-sample prediction