 stability condition online learnability stability general notion quantify sensitivity learning algorithm 's output small change training dataset e.g deletion replacement single training sample condition recently show powerful characterize learnability general learning set i.i.d sample uniform convergence necessary learnability stability sufficient necessary learnability show similar stability condition also sufficient online learnability i.e whether exist learn algorithm sequence example potentially choose adversarially produce sequence hypothesis regret limit respect best hypothesis hindsight introduce online stability stability condition relate uniform-leave-one-out stability batch setting sufficient online learnability particular show popular class online learner namely algorithms fall category follow-the- regularized -leader mirror descent gradient-based method randomized algorithm like weighted majority hedge guarantee regret online stability property provide example suggest existence algorithm stability condition might fact necessary online learnability restricted binary classification setting establish stability condition fact sufficient necessary also show large class online learnable problem general learning setting namely notion sub-exponential covering no-regret online algorithm stability condition exists