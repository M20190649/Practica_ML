 generalization bound representative domain adaptation paper propose novel framework analyze theoretical property learning process representative type domain adaptation combine data multiple source one target briefly call representative domain adaptation particular use integral probability metric measure difference distribution two domain meanwhile compare h-divergence discrepancy distance develop hoeffding-type bennett-type mcdiarmid-type deviation inequality multiple domain respectively present symmetrization inequality representative domain adaptation next use derived inequality obtain hoeffding-type bennett-type generalization bound respectively base uniform entropy number moreover present generalization bound base rademacher complexity finally analyze asymptotic convergence rate convergence learning process representative domain adaptation discuss factor affect asymptotic behavior learning process numerical experiment support theoretical finding well meanwhile give comparison exist result domain adaptation classical result same-distribution assumption