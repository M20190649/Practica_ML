 feature selection via l -penalized squared-loss mutual information feature selection technique screen less important feature many exist supervised feature selection algorithm use redundancy relevancy main criterion select feature however feature interaction potentially key characteristic real-world problem receive much attention attempt take feature interaction account propose l -lsmi l -regularization base algorithm maximize squared-loss variant mutual information select feature output numerical result show l -lsmi performs well handle redundancy detect non-linear dependency consider feature interaction