 sensitivity map hilbert-schmidt independence criterion kernel dependence measure yield accurate estimate nonlinear relation random variable also endorse solid theoretical property convergence rate besides empirical estimate easy compute closed form involve linear algebra operation however hamper two important problem high computational cost involve two kernel matrix sample size compute store interpretability measure remain hidden behind implicit feature map address two issue introduce sensitivity map sm hilbert-schmidt independence criterion hsic sensitivity map allow u explicitly analyze visualize relative relevance example feature dependence measure also present randomized hsic rhsic corresponding sensitivity map cope large scale problem build upon framework random feature bochner 's theorem approximate involved kernel canonical hsic power rhsic measure scale favourably number sample approximate hsic sensitivity map efficiently convergence bound measure sensitivity map also provide proposal illustrate synthetic example challenge real problem dependence estimation feature selection causal inference empirical data