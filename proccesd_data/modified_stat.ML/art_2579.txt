 safe screen variational inequality application lasso sparse learn technique routinely use feature selection result model usually small number non-zero entry safe screening eliminate feature guarantee zero coefficient certain value regularization parameter technique improve computational efficiency safe screening gain increase attention since solve sparse learn formulation usually high computational cost especially number feature large one need try several regularization parameter select suitable model paper propose approach call sasvi safe screen variational inequality sasvi make use variational inequality provide sufficient necessary optimality condition dual problem several exist approach lasso screening cast relaxed version propose sasvi thus sasvi provide strong safe screening rule study monotone property sasvi lasso base sure removal regularization parameter identify feature experimental result synthetic real data set report demonstrate effectiveness propose sasvi lasso screening