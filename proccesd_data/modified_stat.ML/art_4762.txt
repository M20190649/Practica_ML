 causal bandit learn good intervention via causal inference study problem use causal model improve rate good intervention learn online stochastic environment formalism combine multi-arm bandit causal inference model novel type bandit feedback exploit exist approach propose new algorithm exploit causal feedback prove bound simple regret strictly well quantity algorithm use additional causal information