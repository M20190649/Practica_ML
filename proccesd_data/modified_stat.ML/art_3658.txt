 adjustable bound rectifier towards deep binary representation binary representation desirable memory efficiency computation speed robustness paper propose adjustable bounded rectifier learn binary representation deep neural network hard constrain representation across layer binary make training unreasonably difficult softly encourage activation diverge real value binary approximate step function final representation completely binary test approach mnist cifar ilsvrc dataset systematically study training dynamic binarization process approach binarize last layer representation without loss performance binarize layer reasonably small degradation memory space save may allow sophisticated model deploy thus compensate loss best knowledge first work report result current deep network architecture use complete binary middle representation give learned representation find firing inhibition binary neuron usually associate meaningful interpretation across different class suggest semantic structure neural network may manifest guided binarization process