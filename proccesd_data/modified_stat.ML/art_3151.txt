 explain harness adversarial example several machine learning model include neural network consistently misclassify adversarial example -- -inputs form apply small intentionally worst-case perturbation example dataset perturbed input result model output incorrect answer high confidence early attempt explain phenomenon focus nonlinearity overfitting argue instead primary cause neural network vulnerability adversarial perturbation linear nature explanation support new quantitative result give first explanation intriguing fact generalization across architecture train set moreover view yield simple fast method generate adversarial example use approach provide example adversarial training reduce test set error maxout network mnist dataset