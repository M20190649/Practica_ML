 locally weight learning naive bayes classifier consequence strong usually violate conditional independence assumption cia naive bayes nb classifier performance nb becomes less less favorable compare sophisticated classifier sample size increase learn phenomenon size training data large either relax assumption apply nb reduce data set say example use nb local model latter approach trade ignored information robustness model assumption paper consider use nb model locally weight data special weighting function design cia hold unweighted data also hold weighted data new method intuitive capable handle class imbalance theoretically sound locally weighted learner naive bayes base classification k near neighbor empirical study show new method appropriate choice parameter outperforms seven exist classifier similar nature