 compressed gaussian process nonparametric regression massive number sample n feature p increasingly important problem big n setting common strategy partition feature space separately apply simple model partition set propose alternative approach avoid partitioning associated sensitivity neighborhood choice distance metric use random compression combine gaussian process regression propose approach particularly motivate setting response conditionally independent feature give projection low dimensional manifold conditionally random compression matrix smoothness parameter posterior distribution regression surface posterior predictive distribution available analytically run analysis parallel many random compression matrix smoothness parameter model averaging use combine result algorithm implement rapidly even big n p problem strong theoretical justification find yield state art predictive performance