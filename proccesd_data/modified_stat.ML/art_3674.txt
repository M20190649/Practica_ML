 variance reduction sgd distributed importance sampling human able accelerate learning select training material informative appropriate level difficulty propose framework distribute deep learning one set worker search informative example parallel single worker update model example select importance sampling lead model update use unbiased estimate gradient also minimum variance sampling proposal proportional l -norm gradient show experimentally method reduce gradient variance even context cost synchronization across machine ignore factor importance sampling update instantly across training set