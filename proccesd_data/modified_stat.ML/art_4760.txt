 sketch large-scale learning mixture model learn parameter voluminous data prohibitive term memory computational requirement propose compressive learning framework estimate model parameter sketch training data sketch collection generalized moment underlying probability distribution data compute single pas training set easily computable stream distribute datasets propose framework share similarities compressive sensing aim drastically reduce dimension high-dimensional signal preserve ability reconstruct perform estimation task derive iterative algorithm analogous sparse reconstruction algorithm context linear inverse problem exemplify framework compressive estimation gaussian mixture model gmm provide heuristic choice sketching procedure theoretical guarantee reconstruction experimentally show synthetic data propose algorithm yield result comparable classical expectation-maximization em technique require significantly less memory few computation number database element large demonstrate potential approach real large-scale data training sample task model-based speaker verification finally draw connection propose framework approximate hilbert space embedding probability distribution use random feature show propose sketching operator see innovative method design translation-invariant kernel adapt analysis gmms also use theoretical framework derive information preservation guarantee spirit infinite-dimensional compressive sensing