 train confidence-calibrated classifier detect out-of-distribution sample problem detect whether test sample in-distribution i.e. train distribution classifier out-of-distribution sufficiently different arise many real-world machine learning application however state-of-art deep neural network know highly overconfident prediction i.e. distinguish in- out-of-distributions recently handle issue several threshold-based detector propose give pre-trained neural classifier however performance prior work highly depend train classifier since focus improve inference procedure paper develop novel training method classifier inference algorithm work well particular suggest two additional term add original loss e.g. cross entropy first one force sample out-of-distribution le confident classifier second one implicitly generate effective training sample first one essence method jointly train classification generative neural network out-of-distribution demonstrate effectiveness use deep convolutional neural network various popular image datasets