 monte-carlo utility estimate bayesian reinforcement learn paper introduce set algorithm monte-carlo bayesian reinforcement learning firstly monte-carlo estimation upper bound bayes-optimal value function employ construct optimistic policy secondly gradient-based algorithm approximate upper low bound introduce finally introduce new class gradient algorithm bayesian bellman error minimisation theoretically show gradient method sound experimentally demonstrate superiority upper bound method term reward obtain however also show bayesian bellman error method close second despite significant computational simplicity