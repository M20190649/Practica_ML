 context-aware learning finite mixture model work introduce algorithms able exploit contextual information order improve maximum-likelihood ml parameter estimation finite mixture model fmm demonstrate benefit property several scenario propose algorithm derive probabilistic framework regard situation regular fmm graph extend context-related variable respect standard expectation-maximization em methodology thus render explicit supervision completely redundant show direct application miss information principle compare algorithm learn behaviour operates extremity supervised unsupervised learning proportionally information content contextual assistance simulation result demonstrate superiority context-aware fmm training compare conventional unsupervised training term estimation precision standard error convergence rate classification accuracy regression fitness various scenario also highlight important difference among outlined situation finally improved classification outcome contextually enhance fmms showcased brain-computer interface application scenario