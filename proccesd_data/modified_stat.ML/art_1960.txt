 regret analysis stochastic nonstochastic multi-armed bandit problem multi-armed bandit problem basic example sequential decision problem exploration-exploitation trade-off balance stay option give high payoff past explore new option might give high payoff future although study bandit problem date back thirty exploration-exploitation trade-off arise several modern application ad placement website optimization packet routing mathematically multi-armed bandit define payoff process associate option survey focus two extreme case analysis regret particularly simple elegant i.i.d payoff adversarial payoff besides basic setting finitely many action also analyze important variant extension contextual bandit model