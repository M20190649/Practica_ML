 information direct sampling bandit heteroscedastic noise stochastic bandit problem goal maximize unknown function via sequence noisy evaluation typically observation noise assume independent evaluation point satisfy tail bound uniformly domain restrictive assumption many application work consider bandit heteroscedastic noise explicitly allow noise distribution depend evaluation point show lead new trade-off information regret take account exist approach like upper confidence bound algorithms ucb thompson sampling address shortcoming introduce frequentist regret analysis framework similar bayesian framework russo van roy prove new high-probability regret bound general possibly randomized policy depend quantity refer regret-information ratio bound define frequentist version information direct sample id minimize regret-information ratio possible action sample distribution relies concentration inequality online least square regression separable hilbert space generalize case heteroscedastic noise formulate several variant id linear reproduce kernel hilbert space response function yield novel algorithm bayesian optimization also prove frequentist regret bound homoscedastic case recover know bound ucb much well noise heteroscedastic empirically demonstrate linear setting heteroscedastic noise method outperform ucb thompson sampling stay competitive noise homoscedastic