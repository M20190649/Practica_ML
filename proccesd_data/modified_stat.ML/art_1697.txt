 regularization strategy empirical bayesian learning mkl multiple kernel learn mkl structure sparsity multi-task learning recently receive considerable attention paper show different mkl algorithm understand application either regularization kernel weight block-norm-based regularization common structured sparsity multi-task learning show two regularization strategy systematically map concave conjugate operation kernel-weight-based regularizer separable component naturally consider generative probabilistic model behind mkl base model propose learn algorithm kernel weight maximization marginal likelihood show numerical experiment ell -norm mkl elastic-net mkl achieve comparable accuracy uniform kernel combination although uniform kernel combination might preferable simplicity ell -norm mkl elastic-net mkl learn usefulness information source represent kernel particular elastic-net mkl achieves sparsity kernel weight