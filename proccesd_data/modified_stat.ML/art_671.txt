 statistical theory deep learning via proximal splitting paper develop statistical theory implementation deep learning model show elegant variable splitting scheme alternating direction method multiplier optimise deep learning objective allow non-smooth non-convex regularisation penalty induce sparsity parameter weight provide link traditional shallow layer statistical model principal component slice inverse regression deep layer model also define degree freedom deep learning predictor predictive mse criterion perform model selection compare architecture design focus deep multiclass logistic learning although method apply generally result suggest interesting previously under-exploited relationship deep learning proximal splitting technique illustrate methodology provide multi-class logit classification analysis fisher 's iris data illustrate convergence algorithm finally conclude direction future research