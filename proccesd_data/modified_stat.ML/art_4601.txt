 online optimization smoothed piecewise constant function study online optimization smoothed piecewise constant function domain motivate problem adaptively pick parameter learn algorithm recently introduce framework gupta roughgarden majority machine learning literature focus lipschitz-continuous function function bounded gradient good reason -- -any learning algorithm suffers linear regret even piecewise constant function choose adversarially arguably simple non-lipschitz continuous function smoothed setting consider inspire seminal work spielman teng recent work gupta roughgarden -- -in setting sequence function may choose adversary however uncertainty location discontinuity give algorithm achieve sublinear regret full information bandit setting