 classification noisy label importance reweighting paper study classification problem sample label randomly corrupt scenario unobservable sample noise-free label however observe true label independently flip probability rho random label noise class-conditional address two fundamental problem raise scenario first best use abundant surrogate loss function design traditional classification problem label noise prove surrogate loss function use classification noisy label use importance reweighting consistency assurance label noise ultimately hinder search optimal classifier noise-free sample open problem obtain noise rate rho show rate upper bound conditional probability p x noisy sample consequently rate estimate upper bound easily reach classification problem experimental result synthetic real datasets confirm efficiency method