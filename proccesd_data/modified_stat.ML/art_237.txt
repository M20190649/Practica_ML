 empirical comparison v-fold penalisation cross validation model selection distribution-free regression model selection crucial issue machine-learning wide variety penalisation method possibly data dependent complexity penalty recently introduce purpose however empirical performance generally well document literature goal paper investigate extent recent technique successfully use tuning regularisation kernel parameter support vector regression svr complexity measure regression tree cart task traditionally solved via v-fold cross-validation vfcv give efficient result reasonable computational cost disadvantage however vfcv procedure know provide asymptotically suboptimal risk estimate number example tends infinity recently penalisation procedure call v-fold penalisation propose improve vfcv support theoretical argument report extensive set experiment compare v-fold penalisation vfcv svr cart calibration several benchmark datasets highlight case vfcv v-fold penalisation provide poor estimate risk respectively introduce modified penalisation technique reduce estimation error