 rectified gaussian scale mixture sparse non-negative least square problem paper develop bayesian evidence maximization framework solve sparse non-negative least square s-nnls problem introduce family probability density refer rectified gaussian scale mixture r- gsm model sparsity enforce prior distribution solution r-gsm prior encompass variety heavy-tailed density rectified laplacian rectify student- distribution proper choice mixing density utilize hierarchical representation induce r-gsm prior develop evidence maximization framework base expectation-maximization em algorithm use em base method estimate hyper-parameters obtain point estimate solution refer propose method rectified sparse bayesian learn r-sbl provide four r- sbl variant offer range option computational complexity quality e-step computation method include markov chain monte carlo em linear minimum mean-square-error estimation approximate message passing diagonal approximation use numerical experiment show propose r-sbl method outperform exist s-nnls solver term signal support recovery performance also robust structure design matrix