 weighted bandit bandit learn distort value expect motivate model human decision making propose explain commonly observed deviation conventional expect value preference formulate two stochastic multi-armed bandit problem distorted probability cost distribution classic k -armed bandit linearly parameterized bandit setting propose algorithm inspire upper confidence bound ucb incorporate cost distortion exhibit sublinear regret assume holder continuous weight distortion function k -armed setting show algorithm call w-ucb achieve problem-dependent regret l log n delta frac alpha n number play delta gap distort expect value best next best arm l alpha h lder constant distortion function upper bound cost problem-independent regret bound kl alpha n alpha also present match low bound regret show regret w-ucb essentially unimprovable class h lder-continuous weight distortion linearly parameterized setting develop new algorithm variant optimism face uncertainty linear bandit oful algorithm call woful weight-distorted oful show regret sqrt n mbox polylog n high probability sub-gaussian cost distribution finally numerical example demonstrate advantage result use distortion-aware learning algorithm