 loss factorization weakly supervise learning label noise robustness prove empirical risk well-known loss function factor linear term aggregate label term label free express sum loss hold true even non-smooth non-convex loss rkhs first term kernel mean operator -- focal quantity work -- characterize sufficient statistic label result tighten know generalization bound shed new light interpretation factorization direct application weakly supervise learning particular demonstrate algorithms like sgd proximal method adapt minimal effort handle weak supervision mean operator estimate apply idea learn asymmetric noisy label connect extend prior work furthermore show loss enjoy data-dependent mean operator form noise robustness contrast know negative result