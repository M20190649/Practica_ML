 monte carlo bayesian reinforcement learn bayesian reinforcement learn brl encodes prior knowledge world model represent uncertainty model parameter maintain probability distribution paper present monte carlo brl mc-brl simple general approach brl mc-brl sample priori finite set hypothesis model parameter value form discrete partially observable markov decision process pomdp whose state space cross product state space reinforcement learn task sampled model parameter space pomdp require conjugate distribution belief representation early work solve relatively easily point-based approximation algorithm mc-brl naturally handle fully partially observable world theoretical experimental result show discrete pomdp approximate underlie brl task well guarantee performance