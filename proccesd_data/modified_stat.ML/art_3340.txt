 re-scale boosting regression classification boosting learning scheme combine weak prediction rule produce strong composite estimator underlie intuition one obtain accurate prediction rule combine rough one although boosting prove consistent overfitting-resistant numerical convergence rate relatively slow aim paper develop new boosting strategy call re-scale boosting rboosting accelerate numerical convergence rate consequently improve learning performance boosting study show rboosting possess almost optimal numerical convergence rate sense logarithmic factor reach minimax nonlinear approximation rate use rboosting tackle classification regression problem deduce tight generalization error estimate theoretical experimental result show rboosting outperforms boost term generalization