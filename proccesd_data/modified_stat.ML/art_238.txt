 mad-bayes map-based asymptotic derivation bayes classical mixture gaussians model relate k-means via small-variance asymptotics covariance gaussians tend zero negative log-likelihood mixture gaussians model approach k-means objective em algorithm approach k-means algorithm kulis jordan use observation obtain novel k-means-like algorithm gibbs sampler dirichlet process dp mixture instead consider apply small-variance asymptotics directly posterior bayesian nonparametric model framework independent specific bayesian inference algorithm major advantage generalize immediately range model beyond dp mixture illustrate apply framework feature learn setting beta process indian buffet process provide appropriate bayesian nonparametric prior obtain novel objective function go beyond cluster learn penalize new grouping relax mutual exclusivity exhaustivity assumption clustering demonstrate several algorithm scalable simple implement empirical result demonstrate benefit new framework