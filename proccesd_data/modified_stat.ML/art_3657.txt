 reduce overfitting deep network decorrelating representation one major challenge train deep neural network prevent overfitting many technique data augmentation novel regularizers dropout propose prevent overfitting without require massive amount training data work propose new regularizer call decov lead significantly reduce overfitting indicate difference train val performance good generalization regularizer encourage diverse non-redundant representation deep neural network minimize cross-covariance hidden activation simple intuition explore number past work surprisingly never apply regularizer supervised learning experiment across range datasets network architecture show loss always reduce overfitting almost always maintain increase generalization performance often improving performance dropout