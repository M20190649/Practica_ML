 obtain calibrate probability boost boost decision tree typically yield good accuracy precision roc area however output boost well calibrate posterior probability boost yield poor square error cross-entropy empirically demonstrate adaboost predicts distort probability examine three calibration method correct distortion platt scaling isotonic regression logistic correction also experiment boost use log-loss instead usual exponential loss experiment show logistic correction boost log-loss work well boost weak model decision stump yield poor performance boost complex model full decision tree platt scaling isotonic regression however significantly improve probability predict