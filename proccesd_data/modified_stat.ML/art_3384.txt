 multi-objective optimization self-adjusting weighted gradient machine learning task much focus machine learning research place create new architecture optimization method overall loss function seldom question paper interpret machine learn multi-objective optimization perspective show limitation default linear combination loss function data set introduce hypervolume indicator alternative show gradient hypervolume define self-adjusting weighted mean individual loss gradient make similar gradient weighted mean loss without require weight define priori enable inner boosting-like behavior current model use automatically place high weight sample high loss without require use multiple model result denoising autoencoder show new formulation able achieve good mean loss direct optimization mean loss provide evidence conjecture self-adjusting weight create smooth loss surface