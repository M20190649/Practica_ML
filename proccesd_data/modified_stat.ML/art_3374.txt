 belief flow robust online learn paper introduce new probabilistic model online learning dynamically incorporate information stochastic gradient arbitrary loss function similar probabilistic filtering model maintain gaussian belief optimal weight parameter unlike traditional bayesian update model incorporate small number gradient evaluation location choose use thompson sampling make computationally tractable belief transform via linear flow field optimally update belief distribution use rule derive information theoretic principle several version algorithm show use different constraint flow field compare conventional online learn algorithm result give several classification task include logistic regression multilayer neural network