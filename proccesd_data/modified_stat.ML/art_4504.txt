 improve offline evaluation contextual bandit algorithm via bootstrapping technique many recommendation application news recommendation item rec- ommended come go fast pace challenge recommender system rs face setting online learn algorithms seem straight forward solution contextual bandit framework introduce purpose general evaluation r critical issue live evaluation of- ten avoid due potential loss revenue hence need offline evaluation method two option available model base meth- od bias nature thus difficult trust use alone data drive method therefore consider evaluat- ing online learn algorithm past data simple method exist litera- ture nonetheless accuracy satisfac- tory mainly due mechanism data re- jection allow exploitation small fraction data precisely address issue paper highlight limita- tions previous method present new method base bootstrapping technique new method come two important improve- ments much accurate provide measure quality estimation latter highly desirable property order minimize risk entail put online r first time provide theoretical ex- perimental proof superiority compare state-of-the-art method well analysis convergence measure quality