 structure efficient variational deep learning matrix gaussian posterior introduce variational bayesian neural network parameter govern via probability distribution random matrix specifically employ matrix variate gaussian cite gupta matrix parameter posterior distribution explicitly model covariance among input output dimension layer furthermore approximate covariance matrix achieve efficient way represent correlation also cheap fully factorize parameter posterior show local reprarametrization trick cite kingma variational posterior distribution arrive gaussian process cite rasmussen gaussian interpretation hidden unit layer similarly cite gal dropout provide connection deep gaussian process continue take advantage duality incorporate pseudo-data cite snelson sparse model turn allows efficient sample maintain property original model validity propose approach verify extensive experiment