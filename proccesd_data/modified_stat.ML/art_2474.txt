 optimal stochastic strongly convex optimization logarithmic number projection consider stochastic strongly convex optimization complex inequality constraint complex inequality constraint may lead computationally expensive projection algorithmic iteration stochastic gradient descent sgd method reduce computation cost pertain projection propose epoch-projection stochastic gradient descent epro-sgd method propose epro-sgd method consist sequence epoch apply sgd augmented objective function iteration within epoch perform projection end epoch give strongly convex optimization total number iteration epro-sgd require log projection meanwhile attain optimal convergence rate expectation high probability exploit structure optimization problem propose proximal variant epro-sgd namely epro-orda base optimal regularized dual average method apply propose method real-world application empirical result demonstrate effectiveness method