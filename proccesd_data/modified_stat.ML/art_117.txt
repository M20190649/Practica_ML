 estimate subagging cross-validation article derive concentration inequality cross-validation estimate generalization error subagged estimator classification regressor general loss function class predictor finite infinite vc-dimension consider slightly generalize formalism introduce cite dud cover large variety cross-validation procedure include leave-one-out cross-validation k -fold cross-validation hold-out cross-validation split sample leave- upsilon -out cross-validation bigskip noindent interesting consequence probability upper bound bound minimum hoeffding-type bound vapnik-type bound thus small even small learning set finally give simple rule subbag predictor bigskip