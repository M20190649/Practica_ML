 lil ucb optimal exploration algorithm multi-armed bandit paper propose novel upper confidence bound ucb procedure identify arm large mean multi-armed bandit game fixed confidence set use small number total sample procedure improve sense number sample require identify best arm within constant factor low bound base law iterated logarithm lil inspire lil construct confidence bound explicitly account infinite time horizon algorithm addition use novel stopping time algorithm avoid union bound arm observe ucb-type algorithm prove algorithm optimal constant also show simulation provide superior performance respect state-of-the-art