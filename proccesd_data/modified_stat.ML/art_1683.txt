 nesvm fast gradient method support vector machine support vector machine svms invaluable tool many practical application artificial intelligence e.g. classification event recognition however popular svm solver sufficiently efficient application great deal sample well large number feature paper thus present nesvm fast gradient svm solver optimize various svm model e.g. classical svm linear programming svm least square svm compare svm-perf cite svm perf cite perfml convergence rate solve dual svm upper bound mathcal sqrt k wherein k number iteration pegasos cite pegasos online svm converge rate mathcal k primal svm nesvm achieve optimal convergence rate mathcal k linear time complexity particular nesvm smooth non-differentiable hinge loss ell -norm primal svm optimal gradient method without line search adopt solve optimization iteration round current gradient historical gradient combine determine descent direction lipschitz constant determine step size two matrix-vector multiplication require iteration round therefore nesvm efficient exist svm solver addition nesvm available linear nonlinear kernel also propose homotopy nesvm accelerate nesvm dynamically decrease smooth parameter use continuation method experiment census income categorization indoor outdoor scene classification event recognition scene recognition suggest efficiency effectiveness nesvm matlab code nesvm available website assessment