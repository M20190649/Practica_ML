 fast learn rate lp-mkl minimax optimality paper give new sharp generalization bound lp-mkl generalized framework multiple kernel learn mkl impose lp-mixed-norm regularization instead l -mixed-norm regularization utilize localization technique obtain sharp learning rate bound characterize decay rate eigenvalue associated kernel large decay rate give fast convergence rate furthermore give minimax learn rate ball characterize lp-mixed-norm product space show derive learn rate lp-mkl achieves minimax optimal rate lp-mixed-norm ball