 second-order stochastic optimization machine learning linear time first-order stochastic method state-of-the-art large-scale machine learn optimization owe efficient per-iteration complexity second-order method able provide fast convergence much less explored due high cost compute second-order information paper develop second-order stochastic method optimization problem machine learning match per-iteration cost gradient base method certain setting improve upon overall running time popular first-order method furthermore algorithm desirable property implementable time linear sparsity input data