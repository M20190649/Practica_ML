 fast black-box variational inference stochastic trust-region optimization introduce trustvi fast second-order algorithm black-box variational inference base trust-region optimization reparameterization trick iteration trustvi proposes assess step base minibatches draw variational distribution algorithm provably converge stationary point implement trustvi stan framework compare two alternative automatic differentiation variational inference advi hessian-free stochastic gradient variational inference hfsgvi former base stochastic first-order optimization latter use second-order information lack convergence guarantee trustvi typically converge least one order magnitude faster advi demonstrate value stochastic second-order information trustvi often find substantially good variational distribution hfsgvi demonstrate convergence theory matter practice