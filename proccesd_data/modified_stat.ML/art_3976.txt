 regret bound lifelong learning consider problem transfer learning online setting different task present sequentially process within-task algorithm propose lifelong learning strategy refine underlie data representation use within-task algorithm thereby transfer information one task next show within-task algorithm come regret bound strategy inherit good property bound expectation general loss function uniform convex loss discuss application dictionary learning finite set predictor latter case improve previous sqrt bound per task sample size