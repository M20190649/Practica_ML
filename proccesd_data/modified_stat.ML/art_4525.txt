 asynchronous stochastic convex optimization show asymptotically completely asynchronous stochastic gradient procedure achieve optimal even constant factor convergence rate solution convex optimization problem nearly condition require asymptotic optimality standard stochastic gradient procedure roughly noise inherent stochastic approximation scheme dominate noise asynchrony also give empirical evidence demonstrate strong performance asynchronous parallel stochastic optimization scheme demonstrate robustness inherent stochastic approximation problem allow substantially fast parallel asynchronous solution method