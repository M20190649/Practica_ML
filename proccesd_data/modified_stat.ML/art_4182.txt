 practical method solve contextual bandit problem use decision tree many efficient algorithm strong theoretical guarantee propose contextual multi-armed bandit problem however apply algorithm practice difficult require domain expertise build appropriate feature tune parameter propose new method contextual bandit problem simple practical apply little domain expertise algorithm relies decision tree model context-reward relationship decision tree non-parametric interpretable work well without hand-crafted feature guide exploration-exploitation trade-off use bootstrapping approach abstract thompson sample non-bayesian setting also discuss several computational heuristic demonstrate performance method several datasets