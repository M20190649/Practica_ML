 bootstrapped thompson sample deep exploration technical note present new approach carry kind exploration achieve thompson sampling without explicitly maintain sample posterior distribution approach base bootstrap technique use combination observed artificially generate data latter serf induce prior distribution demonstrate critical effective exploration explain approach apply multi-armed bandit reinforcement learning problem relate thompson sampling approach particularly well-suited context exploration couple deep learning since setting maintain generate sample posterior distribution become computationally infeasible