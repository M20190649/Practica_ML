 convex surrogate operator general non-modular loss function empirical risk minimization frequently employ convex surrogate underlie discrete loss function order achieve computational tractability optimization however classical convex surrogate tightly bound modular loss function sub-modular function supermodular function separately maintain polynomial time computation work novel generic convex surrogate general non-modular loss function introduce provide first time tractable solution loss function neither super-modular submodular convex surro-gate base submodular-supermodular decomposition existence uniqueness prove paper take sum two convex surrogate separately bound supermodular component submodular component use slack-rescaling lov sz hinge respectively proven surrogate convex piecewise linear extension loss function subgradient computation polynomial time empirical result report non-submodular loss base rensen-dice difference function real-world face track dataset ten thousand frame demonstrate improved performance efficiency scalabil-ity novel convex surrogate