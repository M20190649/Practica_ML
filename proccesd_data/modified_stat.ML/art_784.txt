 laplacian eigenmaps sparse noisy similarity measurement manifold learning dimensionality reduction technique ubiquitous science engineering computationally expensive procedure apply large data set similarity expensive compute date little work do investigate tradeoff computational resource quality learned representation present theoretical experimental exploration question particular consider laplacian eigenmaps embeddings base kernel matrix explore embeddings behave kernel matrix corrupt occlusion noise main theoretical result show modest noise occlusion assumption high probability recover good approximation laplacian eigenmaps embed base uncorrupted kernel matrix result also show regularization aid approximation experimentally explore effect noise occlusion laplacian eigenmaps embeddings two real-world data set one speech processing one neuroscience well synthetic data set