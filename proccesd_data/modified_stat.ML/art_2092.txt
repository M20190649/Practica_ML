 efficient practical stochastic subgradient descent nuclear norm regularization describe novel subgradient method broad class matrix optimization problem involve nuclear norm regularization unlike exist approach method execute cheap iteration combine low-rank stochastic subgradients efficient incremental svd update make possible highly optimize parallelizable dense linear algebra operation small matrix practical algorithm always maintain low-rank factorization iterates conveniently hold memory efficiently multiply generate prediction matrix completion setting empirical comparison confirm approach highly competitive several recently propose state-of-the-art solver problem