 predict nearly well optimal twice differentiable regressor study nonlinear regression real value data individual sequence manner provide result guarantee hold without statistical assumption address convergence undertraining issue conventional nonlinear regression method introduce algorithm elegantly mitigate issue via incremental hierarchical structure i.e. via incremental decision tree particularly present piecewise linear nonlinear regression algorithm partition regressor space data driven manner learn linear model region unlike conventional approach algorithm gradually increase number disjoint partition regressor space sequential manner accord observe data data driven approach algorithm sequentially asymptotically achieve performance optimal twice differentiable regression function data sequence unknown arbitrary length computational complexity introduced algorithm logarithmic data length certain regularity condition provide explicit description algorithm demonstrate significant gain well-known benchmark real data set chaotic signal