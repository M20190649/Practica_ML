 convergence analysis dynamic special kind two-layered neural network ell ell regularization paper make extension convergence analysis dynamic two-layered bias-free network one relu output take consideration two popular regularization term ell ell norm parameter vector w add square loss function coefficient lambda prove lambda small weight vector w converges optimal solution hat w respect new loss function probability geq varepsilon -a random initiation sphere center origin varepsilon small value constant numerical experiment include phase diagram repeat simulation verify theory