 quasi-newton approach nonsmooth convex optimization problem machine learning extend well-known bfgs quasi-newton method memory-limited variant lbfgs optimization nonsmooth convex objective do rigorous fashion generalize three component bfgs subdifferentials local quadratic model identification descent direction wolfe line search condition prove technical condition result subbfgs algorithm globally convergent objective function value apply memory-limited variant sublbfgs l -regularized risk minimization binary hinge loss extend algorithm multiclass multilabel setting develop new efficient exact line search algorithm prove worst-case time complexity bound show line search also use extend recently develop bundle method multiclass multilabel setting also apply direction-finding component algorithm l -regularized risk minimization logistic loss contexts method perform comparable good specialized state-of-the-art solver number publicly available datasets open source implementation algorithm freely available