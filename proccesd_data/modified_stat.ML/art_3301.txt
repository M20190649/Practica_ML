 early stopping nonparametric variational inference show unconverged stochastic gradient descent interpret procedure sample nonparametric variational approximate posterior distribution distribution implicitly define transformation initial distribution sequence optimization update track change entropy sequence transformation optimization form scalable unbiased estimate variational low bound log marginal likelihood use bound optimize hyperparameters instead use cross-validation bayesian interpretation sgd suggests improve overfitting-resistant optimization procedure give theoretical foundation popular trick early stopping ensembling investigate property marginal likelihood estimator neural network model