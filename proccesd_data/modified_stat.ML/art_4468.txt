 adaptive parallel temper stochastic maximum likelihood learning rbms restrict boltzmann machine rbm attract lot attention late one principle building block deep network train rbms remain problematic however intractibility partition function maximum likelihood gradient require robust sampler accurately sample model despite loss ergodicity often incur learning use parallel tempering negative phase stochastic maximum likelihood sml-pt help address issue impose trade-off computational complexity high ergodicity require careful hand-tuning temperature paper show trade-off unnecessary choice optimal temperature automate minimize average return time concept first propose katzgraber et al. chain spawn dynamically need thus minimize computational overhead show synthetic dataset result good likelihood score