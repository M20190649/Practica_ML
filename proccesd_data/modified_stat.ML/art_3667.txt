 fast parallel gibbs sample general discrete bayesian network fundamental task machine learning related field perform inference bayesian network since exact inference take exponential time general variety approximate method use gibbs sampling one accurate approach provide unbiased sample posterior historically expensive large model paper present optimized parallel gibbs sampler augment state replication state augment marginal estimation decrease convergence time find improve quality parameter estimate accelerate convergence experiment synthetic real data show gibbs sampler substantially fast state art sampler jag without sacrifice accuracy ultimate objective introduce gibbs sampler researcher many field expand range feasible inference problem