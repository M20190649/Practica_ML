 time-varying gaussian process bandit optimization consider sequential bayesian optimization problem bandit feedback adopt formulation allow reward function vary time model reward function use gaussian process whose evolution obey simple markov model introduce two natural extension classical gaussian process upper confidence bound gp-ucb algorithm first r-gp-ucb reset gp-ucb regular interval second tv-gp-ucb instead forget old data smooth fashion main contribution comprises novel regret bound algorithm provide explicit characterization trade-off time horizon rate function varies illustrate performance algorithm synthetic real data find gradual forgetting tv-gp-ucb perform favorably compare sharp resetting r-gp-ucb moreover algorithms significantly outperform classical gp-ucb since treat stale fresh data equally