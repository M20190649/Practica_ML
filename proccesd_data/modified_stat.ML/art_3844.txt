 distribute multi-task learning share representation study problem distributed multi-task learning share representation machine aim learn separate related task unknown share low-dimensional subspace i.e predictor matrix low rank consider setting task handle different machine sample task available locally machine study communication-efficient method exploit share structure