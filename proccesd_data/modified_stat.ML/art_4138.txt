 classify document within multiple hierarchical datasets use multi-task learn multi-task learning mtl supervised learning paradigm prediction model several related task learn jointly achieve good generalization performance training example per task mtl considerably outperform traditional single task learn stl term prediction accuracy work develop mtl base approach classify document archive within dual concept hierarchy namely dmoz wikipedia solve multi-class classification problem define one-versus-rest binary classification task different class across two hierarchical datasets instead learn linear discriminant different task independently use mtl approach relationship different task across datasets establish use non-parametric lazy near neighbor approach also develop evaluate transfer learn tl approach compare mtl tl method standard single task learning semi-supervised learning approach empirical result demonstrate strength developed method show improvement especially few number train example per classification task