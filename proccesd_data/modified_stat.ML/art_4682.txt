 piece-wise quadratic approximation arbitrary error function fast robust machine learn machine learning approach stem application minimize mean square distance principle base computationally efficient quadratic optimization method however face high-dimensional noisy data quadratic error functionals demonstrate many weakness include high sensitivity contaminate factor dimensionality curse therefore lot recent application machine learning exploited property non-quadratic error functionals base l norm even sub-linear potential correspond quasinorms l p p back side approach increase computational cost optimization till far approach suggest deal arbitrary error functionals flexible computationally efficient framework paper develop theory basic universal data approximation algorithm k -means principal component principal manifold graph regularize sparse regression base piece-wise quadratic error potential subquadratic growth pqsq potential develop new universal framework minimize arbitrary sub-quadratic error potential use algorithm guarantee fast convergence local global error minimum theory pqsq potential base notion cone minorant function represent natural approximation formalism base application min-plus algebra approach apply exist machine learn method include method data approximation regularize sparse regression lead improvement computational cost accuracy trade-off demonstrate synthetic real-life datasets pqsq-based machine learn method achieve order magnitude faster computational performance corresponding state-of-the-art method