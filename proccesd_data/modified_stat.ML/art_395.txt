 new perspective k-support cluster norm k -support norm regularizer successfully apply sparse vector prediction problem show belong general class norm formulate parameterized infimum quadratic extend k -support norm matrix observe special case matrix cluster norm use formulation derive efficient algorithm compute proximity operator norm improve upon standard algorithm k -support norm allow u apply proximal gradient method cluster norm also describe solve regularization problem employ centered version norm finally apply matrix regularizers different matrix completion multitask learn datasets result indicate spectral k -support norm cluster norm give state art performance problem significantly outperform trace norm elastic net penalty