 expectation propagation neural network sparsity-promoting prior propose novel approach nonlinear regression use two-layer neural network nn model structure sparsity-favoring hierarchical prior network weight present expectation propagation ep approach approximate integration posterior distribution weight hierarchical scale parameter prior residual scale use factorized posterior approximation derive computationally efficient algorithm whose complexity scale similarly ensemble independent sparse linear model approach enable flexible definition weight prior different sparseness property independent laplace prior common scale parameter gaussian automatic relevance determination ard prior different relevance parameter input approach extend beyond standard activation function nn model structure form flexible nonlinear predictor multiple sparse linear model effect hierarchical prior predictive performance algorithm assess use simulated real-world data comparison make two alternative model ard prior gaussian process nn covariance function marginal maximum posteriori estimate relevance parameter nn markov chain monte carlo integration unknown model parameter