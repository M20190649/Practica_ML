 large-scale kernel-based feature extraction via budget nonlinear subspace track kernel-based method enjoy powerful generalization capability handle variety learn task method provide sufficient training data broadly-applicable class nonlinear function approximate desired accuracy nevertheless inherent nonparametric nature kernel-based estimator computational memory requirement become prohibitive large-scale datasets response formidable challenge present work put forward low-rank kernel-based feature extraction approach particularly tailor online operation data stream need store memory novel generative model introduce approximate high-dimensional possibly infinite feature via low-rank nonlinear subspace learning lead direct kernel function approximation offline online solver develop subspace learn task along affordable version number stored data vector confine predefined budget analytical result provide performance bound well kernel matrix well kernel-based classification regression task approximate leverage budget online subspace learning feature extraction scheme test synthetic real datasets demonstrate benchmark efficiency propose method linear classification regression apply extracted feature