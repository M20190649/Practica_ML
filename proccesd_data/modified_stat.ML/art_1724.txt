 randomize smoothing stochastic optimization analyze convergence rate stochastic optimization procedure non-smooth convex optimization problem combine randomize smooth technique accelerated gradient method obtain convergence rate stochastic optimization procedure expectation high probability optimal dependence variance gradient estimate best knowledge first variance-based rate non-smooth optimization give several application result statistical estimation problem provide experimental result demonstrate effectiveness propose algorithm also describe combination algorithm recent work decentralized optimization yield distributed stochastic optimization algorithm order-optimal