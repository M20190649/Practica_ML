 attend diagnose clinical time series analysis use attention model widespread adoption electronic health record increased emphasis predictive model effectively deal clinical time-series data power recurrent neural network rnn architecture long short-term memory lstm unit deep neural network achieve state-of-the-art result several clinical prediction task despite success rnns sequential nature prohibit parallelize computing thus make inefficient particularly process long sequence recently architecture base solely attention mechanism show remarkable success transduction task nlp computationally superior paper first time utilize attention model clinical time-series modeling thereby dispense recurrence entirely develop textit sand simply attend diagnose architecture employ masked self-attention mechanism use positional encoding dense interpolation strategy incorporate temporal order furthermore develop multi-task variant textit sand jointly infer model multiple diagnosis task use recent mimic-iii benchmark datasets demonstrate propose approach achieve state-of-the-art performance task outperform lstm model classical baseline hand-engineered feature