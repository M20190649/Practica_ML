 optimize kernel machine use deep learn building highly non-linear non-parametric model central several state-of-the-art machine learn system kernel method form important class technique induce reproducing kernel hilbert space rkhs infer non-linear model construction similarity function data method particularly prefer case training data size limit prior knowledge data similarity available despite usefulness limit computational complexity inability support end-to-end learning task-specific objective hand deep neural network become de facto solution end-to-end inference several learn paradigm article explore idea use deep architecture perform kernel machine optimization computational efficiency end-to-end inferencing end develop dkmo deep kernel machine optimization framework create ensemble dense embeddings use nystrom kernel approximation utilizes deep learning generate task-specific representation fusion embeddings intuitively filter network train fuse information ensemble linear subspace rkhs furthermore introduce kernel dropout regularization enable improved training convergence finally extend framework multiple kernel case couple global fusion layer pre-trained deep kernel machine constituent kernel use case study limited training data lack explicit feature source demonstrate effectiveness framework conventional model inferencing technique