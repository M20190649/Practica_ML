 second-order kernel online convex optimization adaptive sketch kernel online convex optimization koco framework combine expressiveness non-parametric kernel model regret guarantee online learning first-order koco method functional gradient descent require mathcal time space per iteration information loss convexity achieve minimax optimal mathcal sqrt regret nonetheless many common loss kernel problem squared loss logistic loss square hinge loss posses strong curvature exploit case second-order koco method achieve mathcal log text det boldsymbol k regret show scale mathcal text eff log text eff effective dimension problem usually much small mathcal sqrt main drawback second-order method much high mathcal space time complexity paper introduce kernel online newton step kons new second-order koco method also achieve mathcal text eff log regret address computational complexity second-order method introduce new matrix sketch algorithm kernel matrix boldsymbol k show chosen parameter gamma leq sketched-kons reduce space time complexity factor gamma mathcal gamma space time per iteration incur gamma time regret