 asymptotic behavior minimal-exploration allocation policy almost sure arbitrarily slow grow regret purpose paper provide understanding structure sequential allocation stochastic multi-armed bandit mab problem establish probability one finite horizon bound convergence rate sample pseudo regret associate two simple class allocation policy pi slowly increasing function g subject mild regularity constraint construct two policy g -forcing g -inflated sample mean achieve measure regret order g n almost surely n infty bound additionally almost sure upper low bound remainder term establish construction herein function g effectively control exploration classical exploration exploitation tradeoff