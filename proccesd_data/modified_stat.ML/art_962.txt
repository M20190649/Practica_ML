 linear time feature selection regularized least-squares propose novel algorithm greedy forward feature selection regularized least-squares rls regression classification also know least-squares support vector machine ridge regression algorithm call greedy rls start empty feature set iteration add feature whose addition provide best leave-one-out cross-validation performance method considerably faster previously propose one since time complexity linear number training example number feature original data set desired size set select feature therefore side effect obtain new training algorithm learn sparse linear rls predictor use large scale learning speed possible due matrix calculus base short-cuts leave-one-out feature addition experimentally demonstrate scalability algorithm ability find good quality feature set