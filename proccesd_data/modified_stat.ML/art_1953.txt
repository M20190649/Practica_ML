 distribution-dependent sample complexity large margin learn obtain tight distribution-specific characterization sample complexity large-margin classification l regularization introduce margin-adapted dimension simple function second order statistic data distribution show distribution-specific upper low bound sample complexity govern margin-adapted dimension data distribution upper bound universal low bound hold rich family sub-gaussian distribution independent feature conclude new quantity tightly characterize true sample complexity large-margin classification prove low bound develop several new tool independent interest include new connection shatter hardness learning new property shatter linear classifier new low bound small eigenvalue random gram matrix generate sub-gaussian variable result use quantitatively compare large margin learn learning rule improve effectiveness method use sample complexity bound active learning