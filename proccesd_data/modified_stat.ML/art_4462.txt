 estimation r nyi entropy mutual information base generalized nearest-neighbor graph present simple computationally efficient nonparametric estimator r 'enyi entropy mutual information base i.i.d sample drawn unknown absolutely continuous distribution r estimator calculate sum p -th power euclidean length edge generalized nearest-neighbor graph sample empirical copula sample respectively first time prove almost sure consistency estimator upper bound rate convergence latter assumption density underlie sample lipschitz continuous experiment demonstrate usefulness independent subspace analysis