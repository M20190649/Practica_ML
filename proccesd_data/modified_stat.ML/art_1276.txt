 boost structural sparsity differential inclusion approach boost gradient descent algorithm one popular method machine learning paper novel boosting-type algorithm propose base restricted gradient descent structural sparsity control whose underlying dynamic govern differential inclusion particular present iterative regularization path structural sparsity parameter sparse linear transforms base variable splitting linearized bregman iteration hence call emph split lbi despite simplicity split lbi outperform popular generalized lasso theory experiment theory path consistency present equip proper early stopping split lbi may achieve model selection consistency family irrepresentable condition weak necessary sufficient condition generalized lasso furthermore ell error bound also give minimax optimal rate utility benefit algorithm illustrate several application include image denoising partial order ranking sport team world university group crowdsourced rank data