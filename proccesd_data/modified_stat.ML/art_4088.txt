 interpretable recurrent neural network use sequential sparse recovery recurrent neural network rnns powerful effective process sequential data however rnns usually consider black box model whose internal structure learned parameter interpretable paper propose interpretable rnn base sequential iterative soft-thresholding algorithm sista solve sequential sparse recovery problem model sequence correlated observation sequence sparse latent vector architecture result sista-rnn implicitly define computational structure sista result novel stack rnn architecture furthermore weight sista-rnn perfectly interpretable parameter principled statistical model case include sparsifying dictionary iterative step size regularization parameter addition particular sequential compressive sense task sista-rnn train faster achieve good performance conventional state-of-the-art black box rnns include long-short term memory lstm rnns