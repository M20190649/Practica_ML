 wasserstein discriminant analysis wasserstein discriminant analysis wda new supervised method improve classification high-dimensional data compute suitable linear map onto low dimensional subspace follow blueprint classical linear discriminant analysis lda wda select projection matrix maximize ratio two quantity dispersion project point come different class divide dispersion project point come class quantify dispersion wda us regularize wasserstein distance rather cross-variance measure usually consider notably lda thanks underlying principle optimal transport wda able capture global distribution scale local sample scale interaction class regularize wasserstein distance compute use sinkhorn matrix scale algorithm show optimization wda tackle use automatic differentiation sinkhorn iteration numerical experiment show promising result term prediction visualization toy example real life datasets mnist deep feature obtain subset caltech dataset