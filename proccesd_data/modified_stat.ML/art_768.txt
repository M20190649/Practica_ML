 scale dynamic topic model dynamic topic model dtms effective discover topic capture evolution trend time series data posterior inference dtms exist method batch algorithm scan full dataset update model make inexact variational approximation mean-field assumption due lack scalable inference algorithm despite usefulness dtms capture large topic dynamic paper fill research void present fast parallelizable inference algorithm use gibbs sample stochastic gradient langevin dynamic make unwarranted assumption also present metropolis-hastings base sampler topic assignment word token distributed environment algorithm require little communication worker sample almost embarrassingly parallel scale large-scale application able learn large dynamic topic model knowledge learn dynamic topic million document less half hour empirical result show algorithm order magnitude faster baseline also achieve low perplexity