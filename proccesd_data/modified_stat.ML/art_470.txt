 distribute estimation information loss exponential family distribute learning probabilistic model multiple data repository minimum communication increasingly important study simple communication-efficient learning framework first calculate local maximum likelihood estimate mle base data subset combine local mles achieve best possible approximation global mle give whole dataset study framework 's statistical property show efficiency loss compare global setting relate much underlying distribution family deviate full exponential family draw connection theory information loss fisher rao efron show full-exponential-family-ness represent low bound error rate arbitrary combination local mles achieve kl-divergence-based combination method common linear combination method also study empirical property method show kl method significantly outperform linear combination practical setting issue model misspecification non-convexity heterogeneous data partition