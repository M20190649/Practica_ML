 know see visualization intuitive interpretability research interpretability machine learn system focus development rigorous notion interpretability suggest good understanding deficiency intuitive notion interpretability need well show visualization enables also impede intuitive interpretability presuppose two level technical pre-interpretation dimensionality reduction regularization furthermore argue use positive concept emulate distributed semantic structure machine learning model introduce significant human bias model consequence suggest intuitive interpretability need singular representation internal model state avoid