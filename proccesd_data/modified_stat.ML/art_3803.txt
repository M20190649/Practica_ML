 parallel bayesian global optimization expensive function consider parallel global optimization derivative-free expensive-to-evaluate function propose efficient method base stochastic approximation implement conceptual bayesian optimization algorithm propose ginsbourger et al heart algorithm maximize information criterion call multi-points expect improvement '' q-ei accomplish use infinitessimal perturbation analysis ipa construct stochastic gradient estimator show estimator unbiased also show stochastic gradient ascent algorithm use constructed gradient estimator converge stationary point q-ei surface therefore number multiple start gradient ascent algorithm number step start grow large one-step bayes optimal set point recover show numerical experiment method maximize q-ei faster method base closed-form evaluation use high-dimensional integration consider many parallel function evaluation comparable speed consider also show result one-step bayes optimal algorithm parallel global optimization find high-quality solution few evaluation heuristic base approximately maximize q-ei high-quality open source implementation algorithm available open source metric optimization engine moe