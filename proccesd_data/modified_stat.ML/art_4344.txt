 liuboost locality inform underboosting imbalanced data classification problem class imbalance along class-overlapping become major issue domain supervised learning supervised learning algorithms assume equal cardinality class consideration optimize cost function assumption hold true imbalanced datasets result sub-optimal classification therefore various approach undersampling oversampling cost-sensitive learning ensemble base method propose deal imbalanced datasets however undersampling suffers information loss oversampling suffers increase runtime potential overfitting cost-sensitive method suffer due inadequately defined cost assignment scheme paper propose novel boost base method call liuboost liuboost us sample balance datasets every boosting iteration like rusboost incorporate cost term every instance base hardness weight update formula minimize information loss introduce undersampling liuboost extensively evaluate imbalanced datasets result indicate significant improvement exist best perform method rusboost