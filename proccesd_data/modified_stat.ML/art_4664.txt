 high dimensional thresholded regression shrinkage effect high-dimensional sparse model via regularization provide powerful tool analyze large-scale data set obtain meaningful interpretable model use nonconvex penalty function show advantage select important feature high dimension global optimality method still demand understanding paper consider sparse regression hard-thresholding penalty show give rise thresholded regression approach motivate close connection l -regularization unrealistic implement practice appeal sample property computational advantage mild regularity condition allow possibly exponentially grow dimensionality establish oracle inequality result regularized estimator global minimizer various prediction variable selection loss well oracle risk inequality hard-thresholded estimator follow l -regularization risk property exhibit interesting shrinkage effect estimation prediction loss identify optimal choice ridge parameter show simultaneous advantage l -loss prediction loss new result phenomenon evidence simulation real data example