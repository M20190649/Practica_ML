 flexible low-rank statistical modeling side information propose general framework reduced-rank modeling matrix-valued data apply generalized nuclear norm penalty directly model low-dimensional latent variable associate row column framework flexibly incorporate row column feature smooth kernel source side information penalize deviation row column model moreover large class model estimate scalably use convex optimization computational bottleneck case one singular value decomposition per iteration large easy-to-apply matrix framework generalize traditional convex matrix completion multi-task learning method well maximum posteriori estimation large class popular hierarchical bayesian model