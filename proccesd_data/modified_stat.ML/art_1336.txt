 non-parametric estimation jensen-shannon divergence generative adversarial network train generative adversarial network gans become widely popular framework generative modelling high-dimensional datasets however training well-known difficult work present rigorous statistical analysis gans provide straight-forward explanation common train pathology vanish gradient furthermore propose new training objective kernel gans demonstrate practical effectiveness large-scale real-world data set key element analysis distinction train respect unknown data distribution empirical counterpart overcome issue gan training pursue idea smooth jensen-shannon divergence jsd incorporate noise input distribution discriminator show effectively lead empirical version jsd true generator density replace kernel density estimate lead kernel gans