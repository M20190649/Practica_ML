 open problem optimal adaboost decision stump significance study theoretical practical property adaboost unquestionable give simplicity wide practical use effectiveness real-world datasets present open problem regard behavior optimal adaboost term coin rudin daubechies schapire label simple version standard adaboost algorithm weak learner adaboost us always output weak classifier low weight error among respective hypothesis class weak classifier implicit weak learner concentrate standard vanilla version optimal adaboost binary classification result use exponential-loss upper bound misclassification training error present two type open problem one deal general weak hypothesis deal particular case decision stump often commonly use practice answer open problem immediate significant impact cement previously establish result asymptotic convergence property optimal adaboost finite datasets turn start convergence-rate analysis understand weak-hypotheses class effective decision stump generate data empirically observe significantly small typically obtained class well effect weak learner 's running time previously establish improved bound generalization performance optimal adaboost classifier shed light self control adaboost tends exhibit practice