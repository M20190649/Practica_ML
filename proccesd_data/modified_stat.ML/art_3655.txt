 fast saddle-point algorithm generalized dantzig selector fdr control ordered l -norm paper propose primal-dual proximal extragradient algorithm solve generalized dantzig selector gd estimation problem base new convex-concave saddle-point sp reformulation new formulation make possible adopt recent development saddle-point optimization achieve optimal k rate convergence compare optimal non-sp algorithm require specification sensitive parameter affect algorithm performance solution quality also provide new analysis show possibility local acceleration achieve rate k special case even without strong convexity strong smoothness application propose gd equip order ell -norm show false discovery rate control property variable selection algorithm performance compare alternative include linearized admm nesterov 's smoothing nemirovski 's mirror-prox accelerated hybrid proximal extragradient technique