 theoretical comparison positive-unlabeled learn positive-negative learning pu learning binary classifier train positive p unlabeled u data without negative n data although n data miss sometimes outperform pn learn i.e. ordinary supervise learning hitherto neither theoretical experimental analysis give explain phenomenon paper theoretically compare pu nu learning pn learn base upper bound estimation error find simple condition pu nu learning likely outperform pn learning prove term upper bound either pu nu learn depend class-prior probability size p n data give infinite u data improve pn learning theoretical finding well agree experimental result artificial benchmark data even experimental setup match theoretical assumption exactly