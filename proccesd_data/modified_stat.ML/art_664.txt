 fast second-order stochastic backpropagation variational inference propose second-order hessian hessian-free base optimization method variational inference inspire gaussian backpropagation argue quasi-newton optimization develop well accomplish generalize gradient computation stochastic backpropagation via reparametrization trick low complexity illustrative example apply approach problem bayesian logistic regression variational auto-encoder vae additionally compute bound estimator variance intractable expectation family lipschitz continuous function method practical scalable model free demonstrate method several real-world datasets provide comparison stochastic gradient method show substantial enhancement convergence rate