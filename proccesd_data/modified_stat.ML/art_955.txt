 interpretability beyond feature attribution quantitative test concept activation vector tcav interpretation deep learning model challenge due size complexity often opaque internal state addition many system image classifier operate low-level feature rather high-level concept address challenge introduce concept activation vector cavs provide interpretation neural net 's internal state term human-friendly concept key idea view high-dimensional internal state neural net aid obstacle show use cavs part technique test cavs tcav use directional derivative quantify degree user-defined concept important classification result -- example sensitive prediction zebra presence stripe use domain image classification testing ground describe cavs may use explore hypothesis generate insight standard image classification network well medical application