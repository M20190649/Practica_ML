 spicymkl propose new optimization algorithm multiple kernel learn mkl call spicymkl applicable general convex loss function general type regularization propose spicymkl iteratively solve smooth minimization problem thus need solve svm lp qp internally spicymkl view proximal minimization method converge super-linearly cost inner minimization roughly proportional number active kernel therefore aim sparse kernel combination algorithm scale well increase number kernel moreover give general block-norm formulation mkl include non-sparse regularization elastic-net ellp -norm regularization extend spicymkl propose efficient optimization method general regularization framework experimental result show algorithm faster exist method especially number kernel large