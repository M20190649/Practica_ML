 domain adaptation weighted majority vote via perturbed variation-based self-labeling machine learning domain adaptation problem arrive test target train source data generate different distribution key applied issue thus design algorithm able generalize new distribution label information focus learn classification model define weighted majority vote set real-val ued function context germain et al show measure disagreement function crucial control core measure theoretical bound -- c-bound lacasse et al. -- involve disagreement lead well perform majority vote learn algorithm usual non-adaptative supervised setting mincq work propose framework extend mincq domain adaptation scenario procedure take advantage recent perturbed variation divergence distribution propose harel mannor justify theoretical bound target risk vote provide mincq target sample label thanks perturbed variation-based self-labeling focus region source target marginals appear similar also study influence self-labeling deduce original process tune hyperparameters finally framework call pv-mincq show promise result rotation translation synthetic problem