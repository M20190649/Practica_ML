 convergence stochastic gradient mcmc algorithm high-order integrator recent advance bayesian learn large-scale data witness emergence stochastic gradient mcmc algorithm sg-mcmc stochastic gradient langevin dynamic sgld stochastic gradient hamiltonian mcmc sghmc stochastic gradient thermostat finite-time convergence property sgld st-order euler integrator recently study correspond theory general sg-mcmcs explore paper consider general sg-mcmcs high-order integrator develop theory analyze finite-time convergence property asymptotic invariant measure theoretical result show fast convergence rate accurate invariant measure sg-mcmcs higher-order integrator example propose efficient nd-order symmetric splitting integrator em mean square error mse posterior average sghmc achieve optimal convergence rate l l iteration compare l sghmc sgld st-order euler integrator furthermore convergence result decreasing-step-size sg-mcmcs also develop convergence rate fixed-step-size counterpart specific decrease sequence experiment synthetic real datasets verify theory show advantage propose method two large-scale real application