 sobolev norm learning rate regularized least-squares algorithm learn rate least-squares regression typically express term l -norms paper extend rate norm strong l -norm without require regression function contain hypothesis space special case sobolev reproduce kernel hilbert space use hypothesis space strong norm coincide fractional sobolev norm use sobolev space l consequence target function also derivative estimate without change algorithm technical point view combine well-known integral operator technique embed property far use combination empirical process argument combination result new finite sample bound respect strong norm finite sample bound rate easily follow finally prove asymptotic optimality result many case