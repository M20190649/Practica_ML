 second-order non-stationary online learning regression goal learner standard online learning cumulative loss much large compare best-performing function fixed class numerous algorithm show gap arbitrarily close zero compare best function choose off-line nevertheless many real-world application adaptive filtering non-stationary nature best prediction function may drift time introduce two novel algorithm online regression design work well non-stationary environment first algorithm performs adaptive reset forget history second last-step min-max optimal context drift analyze algorithm worst-case regret framework show maintain average loss close best slowly change sequence linear function long cumulative drift sublinear addition stationary case drift occur algorithms suffer logarithmic regret previous algorithm bound improve exist one simulation demonstrate usefulness algorithm compare state-of-the-art approach