 thompson sample learn parameterized markov decision process consider reinforcement learning parameterized markov decision process mdps parameterization may induce correlation across transition probability reward consequently observe particular state transition might yield useful information unobserved part mdp present version thompson sample parameterized reinforcement learn problem derive frequentist regret bound prior general parameter space result show number instant suboptimal action choose scale logarithmically time high probability hold prior distribution put significant probability near true model without additional specific closed-form structure conjugate product-form prior constant factor logarithmic scaling encode information complexity learn mdp term kullback-leibler geometry parameter space