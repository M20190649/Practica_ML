 proximal gradient method extrapolation line search class nonconvex nonsmooth problem paper consider class possibly nonconvex nonsmooth non-lipschitz optimization problem arise many contemporary application machine learning variable selection image processing solve class problem propose proximal gradient method extrapolation line search pgels method develop base special potential function successfully incorporate extrapolation non-monotone line search two simple efficient accelerate technique proximal gradient method thanks line search method allow flexibility choose extrapolation parameter update adaptively iteration certain line search criterion satisfy moreover proper choice parameter pgels reduces many exist algorithm also show mild condition line search criterion well define cluster point sequence generate pgels stationary point problem addition assume kurdyka- l ojasiewicz exponent objective problem analyze local convergence rate two special case pgels include widely use non-monotone proximal gradient method one case finally conduct numerical experiment solve ell regularize logistic regression problem ell text regularize least square problem numerical result illustrate efficiency pgels show potential advantage combine two accelerate technique