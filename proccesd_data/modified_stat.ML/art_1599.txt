 explore large feature space hierarchical multiple kernel learn supervise unsupervised learning positive definite kernel allow use large potentially infinite dimensional feature space computational cost depend number observation usually do penalization predictor function euclidean hilbertian norm paper explore penalize sparsity-inducing norm l -norm block l -norm assume kernel decompose large sum individual basis kernel embed directed acyclic graph show possible perform kernel selection hierarchical multiple kernel learn framework polynomial time number select kernel framework naturally apply non linear variable selection extensive simulation synthetic datasets datasets uci repository show efficiently explore large feature space sparsity-inducing norm lead state-of-the-art predictive performance