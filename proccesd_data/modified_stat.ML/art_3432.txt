 pca gaussian perturbation machine learn deal vector parameter ideally would like take high order information account make use matrix even tensor parameter however result algorithm usually inefficient address on-line learning matrix parameter often easy obtain online algorithm good generalization performance eigendecompose current parameter matrix trial cost n per trial ideally want avoid decomposition spend n per trial i.e linear time size matrix data core trade-off running time generalization performance measure regret on-line algorithm total gain best off-line predictor minus total gain on-line algorithm focus key matrix problem rank k principal component analysis mathbb r n k n n algorithm achieve optimum regret require eigendecompositions develop simple algorithm need kn per trial whose regret small factor n algorithm base follow perturbed leader paradigm replace full eigendecompositions trial problem find k principal component current covariance matrix perturb gaussian noise