 function approximation approach estimation policy gradient pomdp structured policy consider estimation policy gradient partially observable markov decision process pomdp special class structured policy finite-state controller show gradient estimation do actor-critic framework make critic compute value function depend state pomdp function conditional mean true value function depend state show critic implement use temporal difference td method linear function approximation analytical result td actor-critic transfer case although actor-critic algorithm use extensively markov decision process mdp propose pomdp alternative early proposal gpomdp algorithm actor-only method furthermore show idea applies semi-markov problem subset finite-state controller