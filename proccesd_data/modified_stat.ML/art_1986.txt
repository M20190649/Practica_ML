 l regularization learn kernel choice kernel critical success many learn algorithm typically leave user instead training data use learn kernel select give family non-negative linear combination p base kernel constrain trace l regularization paper study problem learn kernel family kernel l regularization instead regression problem analyze problem learn kernel ridge regression derive form solution optimization problem give efficient iterative algorithm compute solution present novel theoretical analysis problem base stability give learning bound orthogonal kernel contain additive term pp compare standard kernel ridge regression stability bound also report result experiment indicate l regularization lead modest improvement small number kernel performance degradation larger-scale case contrast l regularization never degrade performance fact achieves significant improvement large number kernel