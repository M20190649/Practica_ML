 accelerate mini-batch stochastic dual coordinate ascent stochastic dual coordinate ascent sdca effective technique solve regularized loss minimization problem machine learning paper consider extension sdca mini-batch setting often use practice main contribution introduce accelerated mini-batch version sdca prove fast convergence rate method discuss implementation method parallel computing system compare result vanilla stochastic dual coordinate ascent accelerate deterministic gradient descent method cite nesterov gradient