 new probabilistic bound eigenvalue eigenvectors random kernel matrix kernel method successful approach different machine learning problem success mainly root use feature map kernel matrix method rely eigenvalue eigenvectors kernel matrix method spectral information use estimate excess risk important question remain close sample eigenvalues eigenvectors population value paper improve early result concentration bound eigenvalue general kernel matrix distance inner product kernel function e.g radial basis function provide new concentration bound characterize eigenvalue sample covariance matrix meanwhile obstacle sharp bound account partially address case study derive concentration inequality sample kernel target-alignment