 multi-fidelity bayesian optimisation continuous approximation bandit method black-box optimisation bayesian optimisation use variety application include hyper-parameter tuning experiment design recently emph multi-fidelity method garner considerable attention since function evaluation become increasingly expensive application multi-fidelity method use cheap approximation function interest speed overall optimisation process however multi-fidelity method assume finite number approximation many practical application however continuous spectrum approximation might available instance tune expensive neural network one might choose approximate cross validation performance use less data n training iteration approximation best view arise continuous two dimensional space n work develop bayesian optimisation method boca setting characterise theoretical property show achieve well regret strategy ignore approximation boca outperforms several baseline synthetic real experiment