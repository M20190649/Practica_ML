 select near-optimal learner via incremental data allocation study novel machine learn ml problem setting sequentially allocate small subset train data amongst large set classifier goal select classifier give near-optimal accuracy train data also minimize cost misallocated sample motivate large modern datasets ml toolkits many combination learn algorithms hyper-parameters inspire principle optimism uncertainty propose innovative strategy data allocation use upper bound daub robustly achieve objective across variety real-world datasets develop substantial theoretical support daub idealized setting expected accuracy classifier train n sample know exactly condition establish rigorous sub-linear bound regret approach term misallocated data well rigorous bound suboptimality select classifier accuracy estimate use real-world datasets entail mild violation theoretical scenario suggest practical behavior daub likely approach idealized behavior