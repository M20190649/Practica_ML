 approximation vector machine large-scale online learn one challenging problem kernel online learning bind model size promote model sparsity sparse model improve computation memory usage also enhance generalization capacity principle concur law parsimony however inappropriate sparsity modeling may also significantly degrade performance paper propose approximation vector machine avm model simultaneously encourage sparsity safeguard risk compromise performance incoming instance arrives approximate instance one neighbor whose distance less predefined threshold key intuition since newly see instance express nearby neighbor optimal performance analytically formulate maintain develop theoretical foundation support intuition establish analysis characterize gap approximation optimal solution gap crucially depend frequency approximation predefined threshold perform convergence analysis wide spectrum loss function include hinge smooth hinge logistic classification task l l epsilon -insensitive regression task conduct extensive experiment classification task batch online mode regression task online mode several benchmark datasets result show propose avm achieve comparable predictive performance current state-of-the-art method simultaneously achieve significant computational speed-up due ability propose avm maintain model size