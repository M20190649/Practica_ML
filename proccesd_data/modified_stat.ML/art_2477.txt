 prior-free prior-dependent regret bound thompson sampling consider stochastic multi-armed bandit problem prior distribution reward distribution interested study prior-free prior-dependent regret bound much spirit usual distribution-free distribution-dependent bound non-bayesian stochastic bandit building technique audibert bubeck russo roy first show thompson sample attains optimal prior-free bound sense prior distribution bayesian regret bound sqrt n k result unimprovable sense exist prior distribution algorithm bayesian regret bound frac sqrt n k also study case prior setting bubeck et al optimal mean know well low bound small gap show case regret thompson sampling fact uniformly bound time thus show thompson sample greatly take advantage nice property prior