 universal variance reduction-based catalyst nonconvex low-rank matrix recovery propose generic framework base new stochastic variance-reduced gradient descent algorithm accelerate nonconvex low-rank matrix recovery start appropriate initial estimator propose algorithm performs project gradient descent base novel semi-stochastic gradient specifically design low-rank matrix recovery base upon mild restrict strong convexity smoothness condition derive projected notion restrict lipschitz continuous gradient property prove algorithm enjoy linear convergence rate unknown low-rank matrix improved computational complexity moreover algorithm employ noiseless noisy observation optimal sample complexity minimax optimal statistical rate attain respectively illustrate superiority generic framework several specific example theoretically experimentally