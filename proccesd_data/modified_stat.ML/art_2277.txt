 value function approximation noisy environment use locally smooth regularize approximate linear program recently petrik et al demonstrate l regularize approximate linear programming ralp could produce value function policy compare favorably establish linear value function approximation technique like lspi ralp 's success primarily stem ability solve feature selection value function approximation step simultaneously ralp 's performance guarantee become loose sample next state use noisy domain ralp require accurate model rather sample unrealistic practical scenario paper demonstrate weakness introduce locally smooth l -regularized approximate linear program ls-ralp demonstrate ls-ralp mitigates inaccuracy stem noise even without accurate model show give smoothness assumption number sample increase error noise approach zero provide experimental example ls-ralp 's success common reinforcement learn benchmark problem