 online stochastic gradient method non-decomposable loss function modern application sensitive domain biometrics medicine frequently require use non-decomposable loss function precision k f-measure etc compare point loss function hinge-loss offer much fine grain control prediction time present novel challenge term algorithm design analysis work initiate study online learn technique non-decomposable loss function aim enable incremental learning well design scalable solver batch problem end propose online learning framework loss function model enjoy several nice property chief amongst existence efficient online learn algorithm sublinear regret online batch conversion bound model provable extension exist online learning model point loss function instantiate two popular loss prec k pauc model prove sublinear regret bound proof require novel structural lemma ranked list may independent interest develop scalable stochastic gradient descent solver non-decomposable loss function show large family loss function satisfy certain uniform convergence property include prec k pauc f-measure method provably converge empirical risk minimizer uniform convergence result know loss establish use novel proof technique use extensive experimentation real life benchmark datasets establish method order magnitude faster recently propose cut plane method