 stability stochastic approximation controlled markov noise temporal difference learning interested understand stability almost sure boundedness stochastic approximation algorithm sas drive controlled markov process analyze class algorithm important since many reinforcement learn rl algorithm cast sa drive controlled markov process paper present easily verifiable sufficient condition stability convergence sa drive controlled markov process many rl application involve continuous state space analysis readily ensure stability continuous state application traditional analysis compare literature analysis present two-fold generalization markov process may evolve continuous state space b process need ergodic give stationary policy temporal difference learn td important policy evaluation method reinforcement learning theory develop herein use analyze generalized td important variant td theory also use analyze td formulation supervised learn forecast problem