 convergence rate sub-sampled newton method consider problem minimize sum n function convex parameter set mathcal c subset mathbb r p n gg p gg regime algorithm utilize sub-sampling technique know effective paper use sub-sampling technique together low-rank approximation design new randomize batch algorithm possess comparable convergence rate newton 's method yet much small per-iteration cost propose algorithm robust term start point step size enjoy composite convergence rate namely quadratic convergence start linear convergence iterate close minimizer develop theoretical analysis also allow u select near-optimal algorithm parameter theoretical result use obtain convergence rate previously propose sub-sampling base algorithm well demonstrate result apply well-known machine learning problem lastly evaluate performance algorithm several datasets various scenario