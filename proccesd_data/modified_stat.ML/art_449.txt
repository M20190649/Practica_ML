 learn non-iid data fast rate one-vs-all multiclass plug-in classifier prove new fast learning rate one-vs-all multiclass plug-in classifier train either exponentially strongly mix data data generate converging drift distribution two typical scenario training data iid learning rate obtain multiclass version tsybakov 's margin assumption type low-noise assumption depend number class result general include previous result binary-class plug-in classifier iid data special case contrast previous work least square svms binary-class setting result retain optimal learning rate iid case