 multi-task additive model share transfer function base dictionary learn additive model form widely popular class regression model represent relation covariates response variable sum low-dimensional transfer function besides flexibility accuracy key benefit model interpretability transfer function provide visual mean inspect model identify domain-specific relation input output however large-scale problem involve prediction many related task learn independently additive model result loss model interpretability cause overfitting train data scarce introduce novel multi-task learning approach provide corpus accurate interpretable additive model large number related forecasting task key idea share transfer function across model order reduce model complexity ease exploration corpus establish connection sparse dictionary learning propose new efficient fitting algorithm alternate sparse coding transfer function update former step solve via extension orthogonal matching pursuit whose property analyze use novel recovery condition extend exist result literature latter step address use traditional dictionary update rule experiment real-world data demonstrate approach compare favorably baseline method yield interpretable corpus model reveal structure among individual task robust train data scarce framework therefore extend well-known benefit additive model common regression setting possibly involve thousand task