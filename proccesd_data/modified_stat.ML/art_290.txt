 optimal computational statistical rate convergence sparse nonconvex learn problem provide theoretical analysis statistical computational property penalized -estimators formulate solution possibly nonconvex optimization problem many important estimator fall category include least square regression nonconvex regularization generalize linear model nonconvex regularization sparse elliptical random design regression problem intractable calculate global solution due nonconvex formulation paper propose approximate regularization path-following method solve variety learn problem nonconvex objective function unified analytic framework simultaneously provide explicit statistical computational rate convergence local solution attain algorithm computationally algorithm attain global geometric rate convergence calculate full regularization path optimal among first-order algorithm unlike exist method attain geometric rate convergence one single regularization parameter algorithm calculate full regularization path iteration complexity particular provide refined iteration complexity bound sharply characterize performance stage along regularization path statistically provide sharp sample complexity analysis approximate local solution along regularization path particular analysis improve upon exist result provide refined sample complexity bound well exact support recovery result final estimator result show final estimator attain oracle statistical property due usage nonconvex penalty