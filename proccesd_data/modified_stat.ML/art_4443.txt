 plan attend generate planning sequence-to-sequence model investigate integration planning mechanism sequence-to-sequence model use attention develop model plan ahead future compute alignment input output sequence construct matrix proposed future alignment commitment vector govern whether follow recompute plan mechanism inspire recently propose strategic attentive reader writer straw model reinforcement learning propose model end-to-end trainable use primarily differentiable operation show outperform strong baseline character-level translation task wmt algorithmic task find eulerian circuit graph question generation text analysis demonstrate model compute qualitatively intuitive alignment converges faster baseline achieve superior performance few parameter