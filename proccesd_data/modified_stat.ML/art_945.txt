 asymptotic analysis via stochastic differential equation gradient descent algorithm statistical computational paradigm paper investigate asymptotic behavior gradient descent algorithm particularly accelerate gradient descent stochastic gradient descent context stochastic optimization arise statistic machine learning objective function estimate available data show algorithm model continuous-time ordinary stochastic differential equation asymptotic dynamic evolution distribution govern linear ordinary stochastic differential equation data size go infinity illustrate study provide novel unified framework joint computational statistical asymptotic analysis dynamic behavior algorithm time number iteration algorithm large sample behavior statistical decision rule like estimator classifier algorithm apply compute statistical decision rule limit random sequence generate iterative algorithm number iteration go infinity analysis result may shed light empirically observed phenomenon escape saddle point avoid bad local minimizers converge good local minimizers depend local geometry learn rate batch size stochastic gradient descent algorithm apply solve non-convex optimization problem