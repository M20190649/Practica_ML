 distribute optimization multi-class svms training one-vs.-rest svms parallelize number class straight forward way give enough computational resource one-vs.-rest svms thus train data involve large number class state however so-called all-in-one svms require solve quadratic program size quadratically number class develop distributed algorithm two all-in-one svm formulation lee et al weston watkins parallelize computation evenly number class allow u compare model one-vs.-rest svms unprecedented scale result indicate superior accuracy text classification data