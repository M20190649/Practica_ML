 random projection linear support vector machine let x data matrix rank rho whose row represent n point d-dimensional space linear support vector machine construct hyperplane separator maximize -norm soft margin develop new oblivious dimension reduction technique precomputed apply input matrix x. prove high probability margin minimum enclose ball feature space preserve within epsilon-relative error ensure comparable generalization original space case classification regression show margin preserve epsilon-relative error high probability present extensive experiment real synthetic data support theory