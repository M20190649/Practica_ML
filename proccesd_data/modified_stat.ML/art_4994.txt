 dismec distributed sparse machine extreme multi-label classification extreme multi-label classification refers supervise multi-label learn involve hundred thousand even million label datasets extreme classification exhibit fit power-law distribution i.e large fraction label positive instance data distribution state-of-the-art approach extreme multi-label classification attempt capture correlation among label embed label matrix low-dimensional linear sub-space however presence power-law distribute extremely large diverse label space structural assumption low rank easily violate work present dismec large-scale distributed framework learn one-versus-rest linear classifier couple explicit capacity control control model size unlike state-of-the-art method dismec make low rank assumption label matrix use double layer parallelization dismec learn classifier datasets consist hundred thousand label within hour explicit capacity control mechanism filter spurious parameter keep model compact size without lose prediction accuracy conduct extensive empirical evaluation publicly available real-world datasets consist upto label compare dismec recent state-of-the-art approach include sleec leading approach learn sparse local embeddings fastxml tree-based approach optimize rank base loss function datasets dismec significantly boost prediction accuracy well compare slecc good compare fastxml absolute term