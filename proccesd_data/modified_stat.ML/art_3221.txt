 gradient-based hyperparameter optimization reversible learn tune hyperparameters learn algorithm hard gradient usually unavailable compute exact gradient cross-validation performance respect hyperparameters chain derivative backwards entire training procedure gradient allow u optimize thousand hyperparameters include step-size momentum schedule weight initialization distribution richly parameterized regularization scheme neural network architecture compute hyperparameter gradient exactly reverse dynamic stochastic gradient descent momentum