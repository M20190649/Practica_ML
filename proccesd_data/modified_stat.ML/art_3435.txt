 hamiltonian monte carlo acceleration use surrogate function random base big data analysis high computational cost bayesian method often limit application practice recent year many attempt improve computational efficiency bayesian inference propose efficient scalable computational technique state-of-the-art markov chain monte carlo mcmc method namely hamiltonian monte carlo hmc key idea explore exploit structure regularity parameter space underlying probabilistic model construct effective approximation geometric property end build surrogate function approximate target distribution use properly choose random base efficient optimization process result method provide flexible scalable efficient sample algorithm converge correct target distribution show choose basis function optimization process differently method relate approach construction surrogate function generalized additive model gaussian process model experiment base simulated real data show approach lead substantially efficient sample algorithm compare exist state-of-the art method