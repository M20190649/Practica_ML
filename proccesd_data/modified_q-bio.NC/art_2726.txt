 attractor neural network architecture ultra high information capacity numerical result attractor neural network important theoretical scenario model memory function hippocampus cortex model memory store plastic recurrent connection neural population form attractor state maximal information capacity conventional abstract attractor network unconstrained connection bits synapse however unconstrained synapse capacity store infinite amount bit noiseless theoretical scenario capacity conventional attractor network achieve propose hierarchical attractor network achieve ultra high information capacity network two layer visible layer n v neuron hidden layer n h neuron visible-to-hidden connection set random keep fix training phase memory pattern store fixed-points network dynamic hidden-to-visible connection initially normally distribute learn via local online learning rule call three-threshold learning rule within-layer connection result simulation suggest maximal information capacity grow exponentially expansion ratio n h n v first order approximation understand mechanism provide high capacity simulate naive mean-field approximation nmfa network exponential increase capture nmfa reveal key underlying factor correlation hidden visible unit additionally observe maximal capacity degree symmetry connectivity hidden visible neuron increase expansion ratio result highlight role hierarchical architecture remarkably increase performance information storage attractor network