 ajile movement prediction multimodal deep learning natural human neural recording video develop useful interface brain machine grand challenge neuroengineering effective interface capacity interpret neural signal predict intention human perform action near future prediction make even challenging outside well-controlled laboratory experiment paper describe approach detect predict natural human arm movement future key challenge brain computer interfacing never attempt introduce novel annotate joint long-term ecog ajile dataset ajile include automatically annotated pose upper body joint four human subject total hour million frame along correspond simultaneously acquire intracranial neural recording size scope ajile greatly exceed previous datasets movement electrocorticography ecog make possible take deep learning approach movement prediction propose multimodal model combine deep convolutional neural network cnn long short-term memory lstm block leverage ecog video modality demonstrate model able detect movement predict future movements msec movement initiation multimodal movement prediction model exhibit resilience simulated ablation input neural signal believe multimodal approach natural neural decoding take context account critical advance bioelectronic technology human neuroscience