 state space approach piecewise-linear recurrent neural network reconstruct nonlinear dynamic neural measurement computational property neural system often think implement term network dynamic hence recover system dynamic experimentally observe neuronal time series like multiple single-unit msu recording neuroimaging data important step toward understand computation ideally one would seek state space representation dynamic would wish access govern equation in-depth analysis recurrent neural network rnns computationally powerful dynamically universal formal framework extensively study computational dynamical system perspective develop semi-analytical maximum-likelihood estimation scheme piecewise-linear rnns plrnns within statistical framework state space model account noise underlying latent dynamic observation process expectation-maximization algorithm use infer latent state distribution global laplace approximation plrnn parameter iteratively validate procedure toy example approach apply msu recording rodent anterior cingulate cortex obtain performance classical work memory task delay alternation model state turn sufficient capture essential computational dynamic underlie task performance include stimulus-selective delay activity estimate model rarely multi-stable rather tune exhibit slow dynamic vicinity bifurcation point summary present work advance semi-analytical thus reasonably fast maximum-likelihood estimation framework plrnns may enable recover relevant dynamic underlie observe neuronal time series directly link computational property