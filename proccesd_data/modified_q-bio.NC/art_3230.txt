 superpose episodic semantic memory via sparse distribute representation ability perceive learn use generality similarity class i.e. semantic memory sm central cognition machine learn ml neural network ai research primarily drive task require ability however another central facet cognition single-trial formation permanent memory experience i.e. episodic memory em relatively little focus recently em-like functionality add deep learn dl model e.g. neural turing machine memory network however case em implement separate module entail substantial data movement time power dl net em b individual item store localistically within em preclude realize exponential representational efficiency distribute localist coding describe sparsey unsupervised hierarchical spatial spatiotemporal associative memory model differ fundamentally mainstream ml model crucially use sparse distribute representation sdrs cell assembly admit extremely efficient single-trial learning algorithm map input similarity code space similarity measure intersection sdrs individual input store superposition similarity preserve pattern intersection assigned code reflect similarity i.e. statistical structure order simply pairwise input thus sm i.e. generative model build computationally free side effect act store episodic memory trace individual input either spatial pattern sequence report initial result mnist weizmann video event recognition benchmark yet attain sota class accuracy learn take minute single cpu