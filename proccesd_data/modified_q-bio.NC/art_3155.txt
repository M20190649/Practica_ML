 exponential capacity autoencoder neural network hidden layer fundamental aspect limitation learn computation neural architecture characterize optimal capacity important widely-used neural architecture know autoencoders network reconstruct input output layer via representation hidden layer even though capacity several neural architecture address use statistical physic method capacity autoencoder neural network well-explored analytically show autoencoder network binary neuron hidden layer achieve capacity grow exponentially network size network fix random weight encode set dense input pattern dense expand emph overcomplete hide layer representation set learnable weight decode input patter output layer perform mean-field approximation model reduce model perceptron problem input-output dependency carry gardner 's emph replica calculation show expansion ratio define number hidden unit number input unit increase autoencoding capacity grow exponentially even sparseness cod level hidden layer representation change replica-symmetric solution locally stable good agreement simulation result obtain use local learning rule addition degree symmetry encoding decode weight monotonically increase expansion ratio