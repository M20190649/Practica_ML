 identity information deterministic dependency constrain information synergy redundancy understand different information source together transmit information crucial many domain example understand neural code require characterize different neuron contribute unique redundant synergistic piece information sensory behavioral variable williams beer propose partial information decomposition pid separate mutual information set source contains set target nonnegative term interpretable piece quantify redundancy require assign identity different information piece assess information common across source harder et al propose identity axiom state redundancy two independent source copy however bertschinger et al show deterministically related sources-target copy axiom incompatible ensure pid nonnegativity study systematically effect deterministic target-sources dependency introduce two synergy stochasticity axiom generalize identity axiom derive general expression separate stochastic deterministic pid component analysis identify negative term originate deterministic dependency show different assumption information identity implicit stochasticity identity axiom determine pid structure implication study neural coding discuss