 feedforward initialization fast inference deep generative network biologically plausible consider deep multi-layered generative model boltzmann machine hopfield net computation implement inference recurrent stochastic recurrence model sequential structure perform computation find condition simple feedforward computation good initialization inference input unit clamp observe value mean feedforward initialization recurrent network close fixed point network dynamic energy gradient main condition consecutive layer form good auto-encoder generally different group input unit particular bottom-up input one hand top-down input hand consistent produce contribution total weighted sum input biological term would correspond dendritic branch correctly predict aggregate input dendritic branch i.e. soma potential consistent prediction synaptic weight dendritic branch apical basal dendrite pyramidal cell train minimize prediction error make dendritic branch target somatic activity whereas previous work show achieve fast negative phase inference model unclamped predictive recurrent model contribution help achieve fast positive phase inference target output clamp recurrent neural model