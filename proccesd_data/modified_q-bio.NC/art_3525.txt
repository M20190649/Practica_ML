 neural network architecture match human behavior artificial grammar learning recent year artificial neural network achieve performance close good human several domain task previously human prerogative language processing witness remarkable improvement state art model one advantage technological boost facilitate comparison different neural network human performance order deepen understanding human cognition investigate neural network architecture feed-forward vs. recurrent match human behavior artificial grammar learning crucial aspect language acquisition prior experimental study prove artificial grammar learn human subject little exposure often without explicit knowledge underlying rule test four grammar different complexity level human feedforward recurrent network result show architecture 'learn via error back-propagation grammar number train sequence human recurrent network perform close human feedforward one irrespective grammar complexity level moreover similar visual processing feedforward recurrent architecture relate unconscious conscious process result suggest explicit learning best model recurrent architecture whereas feedforward network well capture dynamic involve implicit learning