 storage phase-coded pattern via stdp fully-connected sparse network study network capacity study storage retrieval phase-coded pattern stable dynamical attractor recurrent neural network analog integrate-and-fire spiking model synaptic strength determine learning rule base spike-time-dependent plasticity asymmetric time window depend relative timing pre- post-synaptic activity store multiple pattern study network capacity analog model find network capacity scale linearly network size capacity oscillation frequency retrieval state depend asymmetry learning time window addition fully-connected network study sparse network neuron connect small number z n neuron connection short range neighbor neuron place regular lattice long range randomly choose pair neuron find small fraction long range connection able amplify capacity network imply small-world-network topology optimal compromise cost long range connection capacity increase also spiking integrate fire model crucial result storing retrieval multiple phase-coded pattern observe capacity fully-connected spiking network investigate together relation oscillation frequency retrieval state window asymmetry