 doubly-attentive decoder multi-modal neural machine translation introduce multi-modal neural machine translation model doubly-attentive decoder naturally incorporate spatial visual feature obtain use pre-trained convolutional neural network bridge gap image description translation decoder learn attend source-language word part image independently mean two separate attention mechanism generate word target language find model efficiently exploit back-translated in-domain multi-modal data also large general-domain text-only mt corpus also report state-of-the-art result multi k data set