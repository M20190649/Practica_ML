 self-attention-based message-relevant response generation neural conversation model use sequence-to-sequence framework many neural conversation model chit-chat succeed naturalness response nevertheless neural conversation model tend give generic response specific give message still remain challenge alleviate tendency propose method promote message-relevant diverse response neural conversation model use self-attention time-efficient well effective furthermore present investigation effective self-attention deep comparison standard dialogue generation experiment result show propose method improve standard dialogue generation various evaluation metric