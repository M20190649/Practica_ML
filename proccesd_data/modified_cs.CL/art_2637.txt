 unlabeled data morphological generation character-based sequence-to-sequence model present semi-supervised way train character-based encoder-decoder recurrent neural network morphological reinflection task generate one inflected word form another achieve use unlabeled token random string training data autoencoding task adapt network morphological reinflection perform multi-task training thus use limited label data effectively obtain improvement state-of-the-art baseline different language