 deep contextualized word representation introduce new type deep contextualized word representation model complex characteristic word use e.g. syntax semantics us vary across linguistic context i.e. model polysemy word vector learned function internal state deep bidirectional language model bilm pre-trained large text corpus show representation easily add exist model significantly improve state art across six challenge nlp problem include question answering textual entailment sentiment analysis also present analysis show expose deep internals pre-trained network crucial allow downstream model mix different type semi-supervision signal