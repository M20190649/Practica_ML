 cell-aware stack lstms model sentence propose method stack multiple long short-term memory lstm layer model sentence contrast conventional stacked lstms hide state feed input next layer architecture accept hidden memory cell state precede layer fuse information left low context use soft gating mechanism lstms thus propose stack lstm architecture modulate amount information deliver horizontal recurrence also vertical connection useful feature extract low layer effectively convey upper layer dub architecture cell-aware stack lstm cas-lstm show experiment model achieve state-of-the-art result benchmark datasets natural language inference paraphrase detection sentiment classification