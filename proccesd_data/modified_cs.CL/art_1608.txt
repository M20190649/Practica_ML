 learn remember translation history continuous cache exist neural machine translation nmt model generally translate sentence isolation miss opportunity take advantage document-level information work propose augment nmt model light-weight cache-like memory network store recent hidden representation translation history probability distribution generated word updated online depend translation history retrieve memory endow nmt model capability dynamically adapt time experiment multiple domain different topic style show effectiveness propose approach negligible impact computational cost