 reduce gender bias abusive language detection abusive language detection model tend problem bias toward identity word certain group people imbalanced training datasets example good woman consider sexist train exist dataset model bias obstacle model robust enough practical use work measure gender bias model train different abusive language datasets analyze effect different pre-trained word embeddings model architecture also experiment three bias mitigation method debiased word embeddings gender swap data augmentation fine-tuning large corpus method effectively reduce gender bias extend correct model bias scenario