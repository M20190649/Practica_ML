 subword-augmented embed cloze reading comprehension representation learning foundation machine reading comprehension state-of-the-art model deep learning method broadly use word character level representation however character naturally minimal linguistic unit addition simple concatenation character word embedding previous model actually give suboptimal solution paper propose use subword rather character word embedding enhancement also empirically explore different augmentation strategy subword-augmented embed enhance cloze-style reading comprehension model reader detail present reader use subword-level representation augment word embed short list handle rare word effectively thorough examination conduct evaluate comprehensive performance generalization ability propose reader experimental result show propose approach help reader significantly outperform state-of-the-art baseline various public datasets