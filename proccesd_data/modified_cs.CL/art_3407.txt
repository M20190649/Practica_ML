 instance-based inductive deep transfer learning cross-dataset query locality sensitive hashing supervise learning model typically train single dataset performance model rely heavily size dataset i.e. amount data available ground truth learn algorithms try generalize solely base data present training work propose inductive transfer learn method augment learn model infuse similar instance different learn task natural language processing nlp domain propose use instance representation source dataset textit without inherit anything source learn model representation instance textit source textit target datasets learn retrieval relevant source instance perform use soft-attention mechanism textit locality sensitive hashing augment model train target dataset approach simultaneously exploit local textit instance level information well macro statistical viewpoint dataset use approach show significant improvement three major news classification datasets baseline experimental evaluation also show propose approach reduce dependency label data significant margin comparable performance propose cross dataset learning procedure show one achieve competitive good performance learn single dataset