 bi-directional neural machine translation synthetic parallel data despite impressive progress high-resource setting neural machine translation nmt still struggle low-resource out-of-domain scenario often fail match quality phrase-based translation propose novel technique combine back-translation multilingual nmt improve performance difficult case technique train single model direction language pair allow u back-translate source target monolingual data without require auxiliary model continue train augmented parallel data enable cycle improvement single model incorporate source target parallel data improve translation direction byproduct model reduce training deployment cost significantly compare uni-directional model extensive experiment show technique outperform standard back-translation low-resource scenario improve quality cross-domain task effectively reduces cost across board