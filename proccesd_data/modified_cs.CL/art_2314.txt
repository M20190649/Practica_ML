 learn concept embeddings efficient bag-of-concepts densification explicit concept space model prove efficacy text representation many natural language text mining application idea embed textual structure semantic space concept capture main idea object characteristic structure called bag concept boc representation suffers data sparsity cause low similarity score similar text due low concept overlap address problem propose two neural embed model learn continuous concept vector learn propose efficient vector aggregation method generate fully continuous boc representation evaluate concept embed model three task measure entity semantic relatedness rank achieve improvement correlation score dataless concept categorization achieve state-of-the-art performance reduce categorization error rate compare five prior word entity embed model dataless document classification model outperform sparse boc representation addition exploit efficient linear time vector aggregation method achieve good accuracy score much less concept dimension compare previous boc densification method operate polynomial time require hundred dimension boc representation