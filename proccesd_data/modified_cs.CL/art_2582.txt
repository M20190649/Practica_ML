 learn topic-sensitive word representation distribute word representation widely use model word nlp task exist model generate one representation per word consider different meaning word present two approach learn multiple topic-sensitive representation per word use hierarchical dirichlet process observe model topic integrate topic distribution document obtain representation able distinguish different meaning give word model yield statistically significant improvement lexical substitution task indicate commonly use single word representation even combine contextual information insufficient task