 compositional representation morphologically-rich input neural machine translation neural machine translation nmt model typically train fixed-size input output vocabulary create important bottleneck accuracy generalization capability solution various study propose segment word sub-word unit perform translation sub-lexical level however statistical word segmentation method recently show prone morphological error lead inaccurate translation paper propose overcome problem replace source-language embed layer nmt bi-directional recurrent neural network generate compositional representation input desired level granularity test approach low-resource setting five language different morphological typology different composition assumption train nmt compose word representation character n-grams approach consistently outperform bleu point nmt learn embeddings statistically generate sub-word unit