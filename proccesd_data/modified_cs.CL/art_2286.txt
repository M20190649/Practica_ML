 neural semantic parsing multiple knowledge-bases fundamental challenge develop semantic parser paucity strong supervision form language utterance annotate logical form paper propose exploit structural regularity language different domain train semantic parser multiple knowledge-bases kb share information across datasets find substantially improve parse accuracy train single sequence-to-sequence model multiple kb provide encoding domain decode time model achieve state-of-the-art performance overnight dataset contain eight domain improves performance single kb baseline obtain x reduction number model parameter