 code-switching language model use syntax-aware multi-task learn lack text data major issue code-switching language modeling paper introduce multi-task learning base language model share syntax representation language leverage linguistic information tackle low resource data issue model jointly learn language modeling part-of-speech tagging code-switched utterance way model able identify location code-switching point improve prediction next word approach outperform standard lstm base language model improvement perplexity seame phase phase ii dataset respectively