 chain reason entity relation text use recurrent neural network goal combine rich multistep inference symbolic logical reasoning generalization capability neural network particularly interested complex reason entity relation text large-scale knowledge base kbs neelakantan et al use rnns compose distributed semantics multi-hop path kb however multiple reason approach lack accuracy practicality paper propose three significant model advance learn jointly reason relation entity entity-types use neural attention model incorporate multiple path learn share strength single rnn represent logical composition across relation largescale freebase clueweb prediction task achieve error reduction error reduction sparse relation due shared strength chain reason wordnet reduce error mean quantile versus previous state-of-the-art code data available http rajarshd.github.io chainsofreasoning