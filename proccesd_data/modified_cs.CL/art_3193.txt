 dual encoder sequence sequence model open-domain dialogue model ever since successful application sequence sequence learn neural machine translation system interest surge applicability towards language generation problem domain recent work investigate use neural architecture towards model open-domain conversational dialogue find although model capable learn good distributional language model dialogue coherence still concern unlike translation conversation much one-to-many mapping utterance response even pressing model aware precede flow conversation paper propose tackle problem introduce previous conversational context term latent representation dialogue act time inject latent context representation sequence sequence neural network form dialog act use second encoder enhance quality coherence conversation generate main task research work show add latent variable capture discourse relation indeed result coherent response compare conventional sequence sequence model