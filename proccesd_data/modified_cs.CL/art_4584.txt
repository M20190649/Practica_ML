 simple fusion return language model neural machine translation nmt typically leverage monolingual data training backtranslation investigate alternative simple method use monolingual data nmt training combine score pre-trained fixed language model lm score translation model tm tm train scratch achieve train translation model predict residual probability training data add prediction lm enable tm focus capacity model source sentence since rely lm fluency show method outperform previous approach integrate lm nmt architecture simpler require gate network balance tm lm observe gain bleu four test set english-turkish turkish-english estonian-english xhosa-english top ensemble without lm compare method alternative way utilize monolingual data backtranslation shallow fusion cold fusion