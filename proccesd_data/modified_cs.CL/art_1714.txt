 recurrent memory network language model recurrent neural network rnn obtain excellent result many natural language processing nlp task however understand interpret source success remain challenge paper propose recurrent memory network rmn novel rnn architecture amplify power rnn also facilitate understanding internal functioning allow u discover underlying pattern data demonstrate power rmn language modeling sentence completion task language modeling rmn outperforms long short-term memory lstm network three large german italian english dataset additionally perform in-depth analysis various linguistic dimension rmn capture sentence completion challenge essential capture sentence coherence rmn obtains accuracy surpass previous state-of-the-art large margin