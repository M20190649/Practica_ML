 convolutional encoder model neural machine translation prevalent approach neural machine translation relies bi-directional lstms encode source sentence paper present faster simpler architecture base succession convolutional layer allow encode entire source sentence simultaneously compare recurrent network computation constrain temporal dependency wmt english-romanian translation achieve competitive accuracy state-of-the-art outperform several recently publish result wmt english-german task model obtain almost accuracy deep lstm setup wmt english-french translation convolutional encoder speed cpu decode two time high accuracy strong bi-directional lstm baseline