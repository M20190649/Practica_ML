 hybrid convolutional variational autoencoder text generation paper explore effect architectural choice learn variational autoencoder vae text generation contrast previously introduce vae model text encoder decoder rnns propose novel hybrid architecture blend fully feed-forward convolutional deconvolutional component recurrent language model architecture exhibit several attractive property faster run time convergence ability well handle long sequence importantly help avoid major difficulty pose train vae model textual data