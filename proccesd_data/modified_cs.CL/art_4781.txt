 re-ranker scheme integrate large scale nlu model large scale natural language understanding nlu system typically train large quantity data require fast scalable training strategy typical design nlu system consist domain-level nlu module domain classifier intent classifier name entity recognizer hypothesis nlu interpretation consist various intent slot combination domain specific module typically aggregate another downstream component re-ranker integrates output domain-level recognizers return scored list cross domain hypothesis ideal re-ranker exhibit follow two property prefer relevant hypothesis give input top hypothesis b interpretation score correspond hypothesis produce re-ranker calibrate calibration allow final nlu interpretation score comparable across domain propose novel re-ranker strategy address aspect also maintain domain specific modularity design optimization loss function modularized re-ranker present result decrease top hypothesis error rate well maintain model calibration also experiment extension involve train domain specific re-rankers datasets curated independently domain allow asynchronization propose re-ranker design showcases following improve nlu performance unweighted aggregation strategy ii cross-domain calibrate performance iii support use case involve train re-ranker datasets curated domain independently