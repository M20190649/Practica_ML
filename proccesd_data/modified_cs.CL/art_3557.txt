 reuse neural speech representation auditory emotion recognition acoustic emotion recognition aim categorize affective state speaker still difficult task machine learning model difficulty come scarcity training data general subjectivity emotion perception result low annotator agreement uncertainty feature relevant robust one classification paper tackle latter problem inspire recent success transfer learn method propose set architecture utilize neural representation infer train large speech database acoustic emotion recognition task experiment iemocap dataset show relative improvement accuracy f -score baseline recurrent neural network trained end-to-end emotion recognition