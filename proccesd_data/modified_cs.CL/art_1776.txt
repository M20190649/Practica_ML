 chinese song iambic generation neural attention-based model learning generate chinese poem charming yet challenge task traditional approach involve various language modeling machine translation technique however perform well generate poem complex pattern constraint example song iambic famous type poem involve variable-length sentence strict rhythmic pattern paper apply attention-based sequence-to-sequence model generate chinese song iambic specifically encode cue sentence bi-directional long-short term memory lstm model predict entire iambic information provide encoder form attention-based lstm regularize generation process fine structure input cue several technique investigate improve model include global context integration hybrid style training character vector initialization adaptation automatic subjective evaluation result show model indeed learn complex structural rhythmic pattern song iambic generation rather successful