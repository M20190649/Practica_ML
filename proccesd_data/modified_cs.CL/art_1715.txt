 language logical form neural attention semantic parsing aim map natural language machine interpretable meaning representation traditional approach rely high-quality lexicon manually-built template linguistic feature either domain- representation-specific paper present general method base attention-enhanced encoder-decoder model encode input utterance vector representation generate logical form condition output sequence tree encoding vector experimental result four datasets show approach performs competitively without use hand-engineered feature easy adapt across domain mean representation