 skip word character-sequential representation base framework question answer recent work use artificial neural network base word distribute representation greatly boost performance various natural language learning task especially question answering though also carry along attendant problem corpus selection embed learning dictionary transformation different learning task etc paper propose straightforwardly model sentence mean character sequence utilize convolutional neural network integrate character embed learn together point-wise answer selection training compare deep model pre-trained word embedding strategy character-sequential representation csr base method show much simpler procedure stable performance across different benchmark extensive experiment two benchmark answer selection datasets exhibit competitive performance compare state-of-the-art method