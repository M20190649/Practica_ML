 tree-to-sequence attentional neural machine translation exist neural machine translation nmt model focus conversion sequential data directly use syntactic information propose novel end-to-end syntactic nmt model extend sequence-to-sequence model source-side phrase structure model attention mechanism enable decoder generate translated word softly align phrase well word source sentence experimental result wat english-to-japanese dataset demonstrate propose model considerably outperform sequence-to-sequence attentional nmt model compare favorably state-of-the-art tree-to-string smt system