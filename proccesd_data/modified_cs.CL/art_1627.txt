 neural response generation dynamic vocabulary study response generation open domain conversation chatbots exist method assume word response generate identical vocabulary regardless input make vulnerable generic pattern irrelevant noise also cause high cost decode propose dynamic vocabulary sequence-to-sequence dvs model allow input possess vocabulary decoding training vocabulary construction response generation jointly learn maximize low bound true objective monte carlo sample method inference model dynamically allocate small vocabulary input word prediction model conduct decode small vocabulary dynamic vocabulary mechanism dvs eludes many generic pattern irrelevant word generation enjoy efficient decode time experimental result automatic metric human annotation show dvs significantly outperform state-of-the-art method term response quality require decoding time compare efficient baseline