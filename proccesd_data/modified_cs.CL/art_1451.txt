 exploration neural sequence-to-sequence architecture automatic post-editing work explore multiple neural architecture adapt task automatic post-editing machine translation output focus neural end-to-end model combine input mt raw mt output src source language input single neural architecture model mt src rightarrow pe directly apart investigate influence hard-attention model seem well-suited monolingual task well combination idea report result data set provide wmt- share task automatic post-editing demonstrate dual-attention model incorporate available data ape scenario single model improve best share task system publish result shared task dual-attention model combine hard attention remain competitive despite apply few change input