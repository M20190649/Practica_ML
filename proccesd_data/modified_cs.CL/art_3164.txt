 multi-task label embed text classification multi-task learning text classification leverage implicit correlation among related task extract common feature yield performance gain however previous work treat label task independent meaningless one-hot vector cause loss potential information make difficult model jointly learn three task paper propose multi-task label embed convert label text classification semantic vector thereby turn original task vector matching task implement unsupervised supervised semi-supervised model multi-task label embedding utilizing semantic correlation among task make particularly convenient scale transfer task involve extensive experiment five benchmark datasets text classification show model effectively improve performance related task semantic representation label additional information