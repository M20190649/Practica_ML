 generate high-quality informative conversation response sequence-to-sequence model sequence-to-sequence model apply conversation response generation problem source sequence conversation history target sequence response unlike translation conversation responding inherently creative generation long informative coherent diverse response remain hard task work focus single turn setting add self-attention decoder maintain coherence long response propose practical approach call glimpse-model scale large datasets introduce stochastic beam-search algorithm segment-by-segment reranking let u inject diversity earlier generation process train combine data set b conversation message mine web human evaluation study method produce long response overall high proportion rat acceptable excellent length increase compare baseline sequence-to-sequence model explicit length-promotion back-off strategy produce good response overall full spectrum length