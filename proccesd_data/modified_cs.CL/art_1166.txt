 multi-domain neural network language generation spoken dialogue system move limited-domain natural language generation nlg open domain difficult number semantic input combination grow exponentially number domain therefore important leverage existing resource exploit similarity domain facilitate domain adaptation paper propose procedure train multi-domain recurrent neural network-based rnn language generator via multiple adaptation step procedure model first train counterfeit data synthesise out-of-domain dataset fine tune small set in-domain utterance discriminative objective function corpus-based evaluation result show propose procedure achieve competitive performance term bleu score slot error rate significantly reduce data need train generator new unseen domain subjective testing human judge confirm procedure greatly improve generator performance small amount data available domain