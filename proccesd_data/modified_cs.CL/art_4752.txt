 symbolic prior rnn-based semantic parsing seq seq model base recurrent neural network rnns recently receive lot attention domain semantic parsing question answering principle train directly pair natural language utterance logical form performance limit amount available data alleviate problem propose exploit various source prior knowledge well-formedness logical form model weighted context-free grammar likelihood certain entity present input utterance also present logical form model weighted finite-state automaton grammar automaton combine together efficient intersection algorithm form soft guide background rnn test method extension overnight dataset show strongly improve rnn baseline also outperform non-rnn model base rich set hand-crafted feature