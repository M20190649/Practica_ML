 sharp model dull hardware fast accurate neural machine translation decode cpu attentional sequence-to-sequence model become new standard machine translation one challenge model significant increase training decode cost compare phrase-based system focus efficient decoding goal achieve accuracy close state-of-the-art neural machine translation nmt achieve cpu decode speed throughput close phrasal decoder approach problem two angle first describe several technique speed nmt beam search decoder obtain x speedup efficient baseline decoder without change decoder output second propose simple powerful network architecture use rnn gru lstm layer bottom follow series stacked fully-connected layer apply every timestep architecture achieve similar accuracy deep recurrent model small fraction training decode cost combine technique best system achieve competitive accuracy bleu wmt english-french newstest decode word sec single-threaded cpu believe best publish accuracy speed trade-off nmt system