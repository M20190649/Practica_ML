 trim improve skip-thought vector skip-thought model prove effective learn sentence representation capture sentence semantics paper propose suite technique trim improve first validate hypothesis give current sentence infer previous infer next sentence provide similar supervision power therefore one decoder predict next sentence preserve trimmed skip-thought model second present connection layer encoder decoder help model generalize good semantic relatedness task third find good word embed initialization also essential learn good sentence representation train model unsupervised large corpus contiguous sentence evaluate trained model supervised task include semantic relatedness paraphrase detection text classification benchmark empirically show propose model faster lighter-weight equally powerful alternative original skip-thought model