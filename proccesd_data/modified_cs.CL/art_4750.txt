 investigate linguistic pattern order hierarchical natural language generation natural language generation nlg critical component spoken dialogue system divide two phase sentence planning decide overall sentence structure surface realization determine specific word form flatten sentence structure string rise deep learning modern nlg model base sequence-to-sequence seq seq model basically contain encoder-decoder structure nlg model generate sentence scratch jointly optimize sentence planning surface realization however simple encoder-decoder architecture usually fail generate complex long sentence decoder difficulty learn grammar diction knowledge well paper introduce nlg model hierarchical attentional decoder hierarchy focus leverage linguistic knowledge specific order experiment show propose method significantly outperform traditional seq seq model small model size design hierarchical attentional decoder apply various nlg system furthermore different generation strategy base linguistic pattern investigate analyze order guide future nlg research work