 semi-supervised learning neural machine translation end-to-end neural machine translation nmt make remarkable progress recently nmt system rely parallel corpus parameter estimation since parallel corpus usually limit quantity quality coverage especially low-resource language appeal exploit monolingual corpus improve nmt propose semi-supervised approach train nmt model concatenation labeled parallel corpus unlabeled monolingual corpus data central idea reconstruct monolingual corpus use autoencoder source-to-target target-to-source translation model serve encoder decoder respectively approach exploit monolingual corpus target language also source language experiment chinese-english dataset show approach achieve significant improvement state-of-the-art smt nmt system