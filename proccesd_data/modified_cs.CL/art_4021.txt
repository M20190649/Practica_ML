 text normalization use memory augment neural network perform text normalization i.e transformation word write spoken form use memory augment neural network addition dynamic memory access storage mechanism present neural architecture serve language-agnostic text normalization system avoid kind unacceptable error make lstm-based recurrent neural network successfully reduce frequency mistake show novel architecture indeed well alternative propose system require significantly less amount data training time compute resource additionally perform data up-sampling circumvent data sparsity problem semiotic class show sufficient example particular class improve performance text normalization system although occurrence error still remain certain semiotic class demonstrate memory augment network meta-learning capability open many door superior text normalization system