 pathology neural model make interpretation difficult one way interpret neural model prediction highlight important input feature -- -for example heatmap visualization word input sentence exist interpretation method nlp word 's importance determine either input perturbation -- -measuring decrease model confidence word remove -- -or gradient respect word understand limitation method use input reduction iteratively remove least important word input expose pathological behavior neural model remain word appear nonsensical human one determine important interpretation method confirm human experiment reduced example lack information support prediction label model still make prediction high confidence explain counterintuitive result draw connection adversarial example confidence calibration pathological behavior reveal difficulty interpret neural model train maximum likelihood mitigate deficiency fine-tune model encourage high entropy output reduced example fine-tuned model become interpretable input reduction without accuracy loss regular example