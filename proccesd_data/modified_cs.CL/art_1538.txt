 lifted matrix-space model semantic composition tree-structured neural network architecture sentence encode draw inspiration approach semantic composition generally see formal linguistics show empirical improvement comparable sequence model moreover add multiplicative interaction term composition function model yield significant improvement however exist compositional approach adopt powerful composition function scale poorly parameter count explode model dimension vocabulary size grows introduce lifted matrix-space model use global transformation map vector word embeddings matrix compose via operation base matrix-matrix multiplication composition function effectively transmit large number activation across layer relatively model parameter evaluate model stanford nli corpus multi-genre nli corpus stanford sentiment treebank find consistently outperform treelstm tai et al. previous best know composition function tree-structured model