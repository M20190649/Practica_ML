 large scale distribute acoustic modeling back-off n-grams paper revive old approach acoustic modeling borrow n-gram language modeling attempt scale amount training data model size measure number parameter model approximately time large current size use automatic speech recognition data-rich setting expand phonetic context significantly beyond triphones well increase number gaussian mixture component context-dependent state allow experiment context span seven context-independent phone mixture component per state deal unseen phonetic context accomplish use familiar back-off technique use language modeling due implementation simplicity back-off acoustic model estimate store serve use mapreduce distribute computing infrastructure speech recognition experiment carry n-best list rescoring framework google voice search train big model large amount data prof effective way increase accuracy state-of-the-art automatic speech recognition system use hour train data speech along transcription obtain filter utterance voice search log automatic speech recognition confidence model range size -- million gaussians estimate use maximum likelihood training achieve relative reduction word-error-rate combine first-pass model train use maximum likelihood boost maximum mutual information respectively increase context size beyond five phone quinphones help