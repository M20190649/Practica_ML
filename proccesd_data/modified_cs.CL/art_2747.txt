 spherical paragraph model represent text fixed-length vector central many language processing task traditional method build text representation base simple bag-of-words bow representation lose rich semantic relation word recent advance natural language processing show semantically meaningful representation word efficiently acquire distributed model make possible build text representation base good foundation call bag-of-word-embedding bowe representation however exist text representation method use bowe often lack sound probabilistic foundation well capture semantic relatedness encode word vector address problem introduce spherical paragraph model spm probabilistic generative model base bowe text representation spm good probabilistic interpretability fully leverage rich semantics word word co-occurrence information well corpus-wide information help representation learning text experimental result topical classification sentiment analysis demonstrate spm achieve new state-of-the-art performance several benchmark datasets