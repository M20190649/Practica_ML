 train neural machine translation use word embedding-based loss neural machine translation nmt computational cost output layer increase size target-side vocabulary use limited-size vocabulary instead may cause significant decrease translation quality trade-off derive softmax-based loss function handle in-dictionary word independently word similarity consider paper propose novel nmt loss function include word similarity form distance word embed space propose loss function encourage nmt decoder generate word close reference embedding space help decoder choose similar acceptable word actual best candidate include vocabulary due size limitation experiment use aspec japanese-to-english iwslt english-to-french data set propose method show improvement standard nmt baseline datasets especially iwslt en-fr achieve bleu meteor target-side vocabulary limited word propose method demonstrate substantial gain meteor aspec ja-en