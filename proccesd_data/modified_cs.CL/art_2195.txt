 explore different dimension attention uncertainty detection neural network attention prove effective many natural language processing task paper develop attention mechanism uncertainty detection particular generalize standardly use attention mechanism introduce external attention sequence-preserving attention novel architecture differ standard approach use external resource compute attention weight preserve sequence information compare configuration along different dimension attention novel architecture set new state art wikipedia benchmark dataset perform similar state-of-the-art model biomedical benchmark use large set linguistic feature