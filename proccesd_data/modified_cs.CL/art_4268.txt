 hierarchical multi task learn ctc automatic speech recognition still challenge learn useful intermediate representation use high-level abstract target unit word reason character phoneme base system tend outperform word-based system hundred hour training data use paper first show hierarchical multi-task training encourage formation useful intermediate representation achieve perform connectionist temporal classification different level network target different granularity model thus performs prediction multiple scale input standard h switchboard training setup hierarchical multi-task architecture exhibit improvement single-task architecture number parameter model obtains word error rate eval switchboard subset without decoder language model outperform current state-of-the-art acoustic-to-word model