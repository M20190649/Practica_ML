 arabic name entity recognition use word representation recent work show effectiveness word representations feature significantly improve supervise ner english language study investigate whether word representation also boost supervised ner arabic use word representation additional feature conditional random field crf model systematically compare three popular neural word embed algorithms skip-gram cbow glove six different approach integrate word representation ner system experimental result show brown cluster achieve best performance among six approach concern word embedding feature cluster embedding feature outperform embed feature distributional prototype produce second best result moreover combination brown cluster word embedding feature provide additional improvement nearly f -score baseline