 recurrent neural network text classification multi-task learn neural network base method obtain great progress variety natural language processing task however previous work model learn base single-task supervise objective often suffer insufficient train data paper use multi-task learning framework jointly learn across multiple related task base recurrent neural network propose three different mechanism share information model text task-specific shared layer entire network train jointly task experiment four benchmark text classification task show propose model improve performance task help related task