 regularize neural machine translation target-bidirectional agreement although neural machine translation nmt achieve remarkable progress past several year nmt system still suffer fundamental shortcoming sequence generation task error make early generation process feed input model quickly amplify harm subsequent sequence generation address issue propose novel model regularization method nmt training aim improve agreement translation generate left-to-right l r right-to-left r l nmt decoder goal achieve introduce two kullback-leibler divergence regularization term nmt training objective reduce mismatch output probability l r r l model addition also employ joint training strategy allow l r r l model improve interactive update process experimental result show propose method significantly outperform state-of-the-art baseline chinese-english english-german translation task