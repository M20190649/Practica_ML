 multimodal speech emotion recognition use audio text speech emotion recognition challenging task extensive reliance place model use audio feature build well-performing classifier paper propose novel deep dual recurrent encoder model utilize text data audio signal simultaneously obtain good understanding speech data emotional dialogue compose sound spoken content model encode information audio text sequence use dual recurrent neural network rnns combine information source predict emotion class architecture analyze speech data signal level language level thus utilize information within data comprehensively model focus audio feature extensive experiment conduct investigate efficacy property propose model propose model outperform previous state-of-the-art method assign data one four emotion category i.e. angry happy sad neutral model apply iemocap dataset reflect accuracy range