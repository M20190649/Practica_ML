 high order lstm good accuracy segment label sequence data exist neural model usually predict tag current token independent neighboring tag popular lstm-crf model consider tag dependency every two consecutive tag however hard exist neural model take long distance dependency tag consideration scalability mainly limit complex model structure cost dynamic programming training work first design new model call high order lstm predict multiple tag current token contain current tag also previous several tag call number tag one prediction order propose new method call multi-order bilstm mo-bilstm combine low order high order lstms together mo-bilstm keep scalability high order model pruning technique evaluate mo-bilstm all-phrase chunking ner datasets experiment result show mo-bilstm achieve state-of-the-art result chunk highly competitive result two ner datasets