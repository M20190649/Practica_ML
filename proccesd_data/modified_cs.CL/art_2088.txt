 neural machine translation supervised attention attention mechanisim appeal neural machine translation since able dynam- ically encode source sentence generate alignment target word source word unfortunately prove bad conventional alignment model aligment accuracy paper analyze explain issue point view re- ordering propose supervised attention learn guidance conventional alignment model experiment two chinese-to-english translation task show super- vised attention mechanism yield well alignment lead substantial gain standard attention base nmt