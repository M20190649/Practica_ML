 language generation recurrent generative adversarial network without pre-training generative adversarial network gans show great promise recently image generation training gans language generation prove difficult non-differentiable nature generate text recurrent neural network consequently past work either resort pre-training maximum-likelihood use convolutional network generation work show recurrent neural network train generate text gans scratch use curriculum learning slowly teach model generate sequence increase variable length empirically show approach vastly improve quality generated sequence compare convolutional baseline