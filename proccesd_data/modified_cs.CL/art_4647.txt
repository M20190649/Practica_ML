 use sparse semantic embeddings learn multimodal text image data model human conceptual knowledge distributional model provide convenient way model semantics use dense embed space derive unsupervised learn algorithm however dimension dense embedding space design resemble human semantic knowledge moreover embeddings often build single source information typically text data even though neurocognitive research suggest semantics deeply link language perception paper combine multimodal information text image-based representation derive state-of-the-art distributional model produce sparse interpretable vector use joint non-negative sparse embedding in-depth analysis compare sparse model human-derived behavioural neuroimaging data demonstrate ability predict interpretable linguistic description human ground-truth semantic knowledge