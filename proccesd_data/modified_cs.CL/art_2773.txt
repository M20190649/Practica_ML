 end-to-end neural coreference resolution introduce first end-to-end coreference resolution model show significantly outperform previous work without use syntactic parser hand-engineered mention detector key idea directly consider span document potential mention learn distribution possible antecedent model compute span embeddings combine context-dependent boundary representation head-finding attention mechanism train maximize marginal likelihood gold antecedent span coreference cluster factor enable aggressive pruning potential mention experiment demonstrate state-of-the-art performance gain f ontonotes benchmark f use -model ensemble despite fact first approach successfully train external resource