 model source syntax neural machine translation even though linguistics-free sequence sequence model neural machine translation nmt certain capability implicitly learn syntactic information source sentence paper show source syntax explicitly incorporate nmt effectively provide improvement specifically linearize parse tree source sentence obtain structural label sequence basis propose three different sort encoders incorporate source syntax nmt parallel rnn encoder learn word label annotation vector parallelly hierarchical rnn encoder learn word label annotation vector two-level hierarchy mixed rnn encoder stitchingly learn word label annotation vector sequence word label mixed experimentation chinese-to-english translation demonstrate three propose syntactic encoders able improve translation accuracy interest note simple rnn encoder i.e. mixed rnn encoder yield best performance significant improvement bleu point moreover in-depth analysis several perspective provide reveal source syntax benefit nmt