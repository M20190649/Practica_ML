 spherical latent space stable variational autoencoders hallmark variational autoencoders vaes text processing combination powerful encoder-decoder model lstms simple latent distribution typically multivariate gaussians model pose difficult optimization problem especially bad local optimum variational posterior always equal prior model use latent variable kind collapse encourage kl divergence term objective work experiment another choice latent distribution namely von mises-fisher vmf distribution place mass surface unit hypersphere choice prior posterior kl divergence term depend variance vmf distribution give u ability treat fixed hyperparameter show avert kl collapse consistently give good likelihood gaussians across range model condition include recurrent language modeling bag-of-words document modeling analysis property vmf representation show learn rich nuanced structure latent representation gaussian counterpart