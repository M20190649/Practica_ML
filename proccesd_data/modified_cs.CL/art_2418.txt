 deep lstm large vocabulary continuous speech recognition recurrent neural network rnns especially long short-term memory lstm rnns effective network sequential task like speech recognition deep lstm model perform well large vocabulary continuous speech recognition impressive learning ability however difficult train deep network introduce training framework layer-wise training exponential moving average method deep lstm model competitive framework lstm model layer successfully train shenma voice search data mandarin outperform deep lstm model train conventional approach moreover order online stream speech recognition application shallow model low real time factor distil deep model recognition accuracy little loss distillation process therefore model train propose training framework reduces relative character error rate compare original model similar real-time capability furthermore novel transfer learn strategy segmental minimum bayes-risk also introduce framework strategy make possible train small part dataset could outperform full dataset training beginning