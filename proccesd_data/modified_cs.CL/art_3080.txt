 dynamic time-aware attention speaker role context spoken language understand spoken language understanding slu essential component conversational system slu component treat utterance independently following component aggregate multi-turn information separate phase order avoid error propagation effectively utilize context prior work leveraged history contextual slu however previous model pay attention content history utterance without consider temporal information speaker role dialogue recent utterance important least recent one furthermore user usually pay attention self history reason others utterance listening speaker utterance may provide informative cue help understanding therefore paper propose attention-based network additionally leverage temporal information speaker role good slu attention contexts speaker role automatically learn end-to-end manner experiment benchmark dialogue state tracking challenge dstc dataset show time-aware dynamic role attention network significantly improve understanding performance