 rankme reliable human rating natural language generation human evaluation natural language generation nlg often suffer inconsistent user rating previous research tend attribute problem individual user preference show quality human judgement also improve experimental design present novel rank-based magnitude estimation method rankme combine use continuous scale relative assessment show rankme significantly improve reliability consistency human rating compare traditional evaluation method addition show possible evaluate nlg system accord multiple distinct criterion important error analysis finally demonstrate rankme combination bayesian estimation system quality cost-effective alternative rank multiple nlg system