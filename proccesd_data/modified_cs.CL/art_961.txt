 hierarchical neural autoencoder paragraph document natural language generation coherent long texts like paragraph long document challenging problem recurrent network model paper explore important step toward generation task train lstm long-short term memory auto-encoder preserve reconstruct multi-sentence paragraph introduce lstm model hierarchically build embedding paragraph embeddings sentence word decode embed reconstruct original paragraph evaluate reconstructed paragraph use standard metric like rouge entity grid show neural model able encode text way preserve syntactic semantic discourse coherence first step toward generate coherent text unit neural model work potential significantly impact natural language generation summarization footnote code three model describe paper find www.stanford.edu jiweil