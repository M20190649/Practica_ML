 globally normalize reader rapid progress make towards question answer qa system extract answer text exist neural approach make use expensive bi-directional attention mechanism score possible answer span limit scalability propose instead cast extractive qa iterative search problem select answer 's sentence start word end word representation reduce space search step allow computation conditionally allocate promise search path show globally normalize decision process back-propagating beam search make representation viable learning efficient empirically demonstrate benefit approach use model globally normalized reader gnr achieve second high single model performance stanford question answer dataset em f dev x faster bi-attention-flow also introduce data-augmentation method produce semantically valid example align name entity knowledge base swap new entity type method improve performance model consider work independent interest variety nlp task