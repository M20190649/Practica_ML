 ruminate reader reasoning gated multi-hop attention answer question machine comprehension mc task model need establish interaction question context tackle problem single-pass model reflect correct answer present ruminate reader ruminate reader add second pas attention novel information fusion component bi-directional attention flow model bidaf propose novel layer structure construct query-aware context vector representation fuse encode representation intermediate representation top bidaf model show multi-hop attention mechanism apply bi-directional attention structure experiment squad find reader outperform bidaf baseline substantial margin match surpass performance publish system