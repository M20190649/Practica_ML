 exploit domain knowledge via grouped weight share application text categorization fundamental advantage neural model nlp ability learn representation scratch however practice often mean ignore exist external linguistic resource e.g. wordnet domain specific ontology unified medical language system umls propose general novel method exploit resource via weight sharing prior work weight share neural network consider largely mean model compression contrast treat weight sharing flexible mechanism incorporate prior knowledge neural model show approach consistently yield improved performance classification task compare baseline strategy exploit weight sharing