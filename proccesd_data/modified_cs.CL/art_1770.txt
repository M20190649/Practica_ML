 multilingual part-of-speech tagging bidirectional long short-term memory model auxiliary loss bidirectional long short-term memory bi-lstm network recently prove successful various nlp sequence modeling task little know reliance input representation target language data set size label noise address issue evaluate bi-lstms word character unicode byte embeddings po tagging compare bi-lstms traditional po tagger across language data size also present novel bi-lstm model combine po tag loss function auxiliary loss function account rare word model obtain state-of-the-art performance across language work especially well morphologically complex language analysis suggest bi-lstms less sensitive train data size label corruption small noise level previously assume