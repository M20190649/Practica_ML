 learn meta-embeddings use ensemble embed set word embeddings -- distribute representation word -- deep learning beneficial many task natural language processing nlp however different embed set vary greatly quality characteristic captured semantics instead rely advanced algorithm embed learning paper propose ensemble approach combine different public embed set aim learn meta-embeddings experiment word similarity analogy task part-of-speech tagging show well performance meta-embeddings compare individual embed set one advantage meta-embeddings increased vocabulary coverage release meta-embeddings publicly