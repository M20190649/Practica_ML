 latent attention if-then program synthesis automatic translation natural language description program longstanding challenging problem work consider simple yet important sub-problem translation textual description if-then program devise novel neural network architecture task train end-to-end specifically introduce latent attention compute multiplicative weight word description two-stage process goal good leverage natural language structure indicate relevant part predict program element architecture reduce error rate compare prior art also propose one-shot learning scenario if-then program synthesis simulate exist dataset demonstrate variation training procedure scenario outperform original procedure significantly close gap model train data