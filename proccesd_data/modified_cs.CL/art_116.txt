 estimation stochastic attribute-value grammar use informative sample argue computational complexity associate estimation stochastic attribute-value grammar reduce train upon informative subset full training set result use parse wall street journal corpus show circumstance possible obtain good estimation result use informative sample train upon available material experimentation demonstrate unlexicalised model gaussian prior reduce overfitting however model lexicalise contain overlap feature overfitting seem problem gaussian prior make minimal difference performance approach applicable situation infeasibly large number par training set else recovery par packed representation computationally expensive