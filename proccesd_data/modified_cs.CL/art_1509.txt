 multi-mention learning read comprehension neural cascade read comprehension challenging task especially execute across longer across multiple evidence document answer likely reoccur exist neural architecture typically scale entire evidence hence resort select single passage document either via truncation mean carefully search answer within passage however case strategy suboptimal since focus specific passage become difficult leverage multiple mention answer throughout document work take different approach construct lightweight model combine cascade find answer submodel consist feed-forward network equip attention mechanism make trivially parallelizable show approach scale approximately order magnitude large evidence document aggregate information representation level multiple mention answer candidate across document empirically approach achieve state-of-the-art performance wikipedia web domain triviaqa dataset outperform complex recurrent architecture