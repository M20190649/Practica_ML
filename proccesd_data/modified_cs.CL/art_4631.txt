 dynamically context-sensitive time-decay attention dialogue modeling spoken language understanding slu essential component conversational system consider context provide informative cue good understanding history leverage contextual slu however prior work pay attention related content history utterance ignore temporal information dialogue intuitive recent utterance important least recent one time-aware attention decaying manner therefore paper allow model automatically learn time-decay attention function attentional weight dynamically decide base content role 's context effectively integrate content-aware time-aware perspective demonstrate remarkable flexibility complex dialogue context experiment benchmark dialogue state tracking challenge dstc dataset show propose dynamically context-sensitive time-decay attention mechanism significantly improve state-of-the-art model contextual understanding performance