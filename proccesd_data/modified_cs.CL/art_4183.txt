 neural machine translation key-value memory-augmented attention although attention-based neural machine translation nmt achieve remarkable progress recent year still suffer issue repeat drop translation alleviate issue propose novel key-value memory-augmented attention model nmt call kvmematt specifically maintain timely updated keymemory keep track attention history fixed value-memory store representation source sentence throughout whole translation process via nontrivial transformation iterative interaction two memory decoder focus appropriate source word predict next target word decode step therefore improve adequacy translation experimental result chinese english wmt german english translation task demonstrate superiority propose model