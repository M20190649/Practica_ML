 exploit cross-sentence context neural machine translation translation consider document whole help resolve ambiguity inconsistency paper propose cross-sentence context-aware approach investigate influence historical contextual information performance neural machine translation nmt first history summarize hierarchical way integrate historical representation nmt two strategy warm-start encoder decoder state auxiliary context source update decoder state experimental result large chinese-english translation task show approach significantly improve upon strong attention-based nmt system bleu point