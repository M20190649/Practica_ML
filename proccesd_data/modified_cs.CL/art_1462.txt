 empirical study mini-batch creation strategy neural machine translation training neural machine translation nmt model usually use mini-batches efficiency purpose mini-batched training process necessary pad short sentence mini-batch equal length long sentence therein efficient computation previous work note sort corpus base sentence length make mini-batches reduces amount padding increase processing speed however despite fact mini-batch creation essential step nmt training widely use nmt toolkits implement disparate strategy empirically validate compare work investigate mini-batch creation strategy experiment two different datasets result suggest choice mini-batch creation strategy large effect nmt training length-based sorting strategy always work well compare simple shuffling