 neural structural correspondence learn domain adaptation domain adaptation adapt model domain rich labeled training data domain poor data fundamental nlp challenge introduce neural network model marry together idea two prominent strand research domain adaptation representation learning structural correspondence learn scl blitzer et al. autoencoder neural network particularly model three-layer neural network learn encode nonpivot feature input example low-dimensional representation existence pivot feature feature prominent domain convey useful information nlp task example decode representation low-dimensional representation employ learning algorithm task moreover show inject pre-trained word embeddings model order improve generalization across example similar pivot feature task cross-domain product sentiment classification blitzer et al. consist domain pair model outperform scl marginalize stack denoising autoencoder msda chen et al. method respectively average across domain pair