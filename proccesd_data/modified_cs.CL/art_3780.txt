 constituency parse self-attentive encoder demonstrate replace lstm encoder self-attentive architecture lead improvement state-of-the-art discriminative constituency parser use attention make explicit manner information propagate different location sentence use analyze model propose potential improvement example find separate positional content information encoder lead improve parsing accuracy additionally evaluate different approach lexical representation parser achieve new state-of-the-art result single model train penn treebank f without use external data f use pre-trained word representation parser also outperform previous best-published accuracy figure language spmrl dataset