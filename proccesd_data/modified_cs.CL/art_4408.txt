 post-processing word representation via variance normalization dynamic embed although embed vector representation word offer impressive performance many natural language processing nlp application information ordered input sequence lose extent context-based sample use training performance improvement two new post-processing technique call post-processing via variance normalization pvn post-processing via dynamic embed pde propose work pvn method normalize variance principal component word vector pde method learn orthogonal latent variable order input sequence pvn pde method integrate achieve good performance apply post-processing technique two popular word embed method i.e. word vec glove yield post-processed representation extensive experiment conduct demonstrate effectiveness propose post-processing technique