 model sentence pair tree-structured attentive encoder describe attentive encoder combine tree-structured recursive neural network sequential recurrent neural network model sentence pair since exist attentive model exert attention sequential structure propose way incorporate attention tree topology specially give pair sentence attentive encoder use representation one sentence generate via rnn guide structural encoding sentence dependency parse tree evaluate propose attentive encoder three task semantic similarity paraphrase identification true-false question selection experimental result show encoder outperform baseline achieve state-of-the-art result two task