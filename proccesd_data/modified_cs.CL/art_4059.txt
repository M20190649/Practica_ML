 multilingual neural machine translation task-specific attention multilingual machine translation address task translate multiple source target language propose task-specific attention model simple effective technique improve quality sequence-to-sequence neural multilingual translation approach seek retain much parameter share generalization nmt model possible still allow language-specific specialization attention model particular language-pair task experiment four language europarl corpus show use target-specific model attention provide consistent gain translation quality possible translation direction compare model parameter share observe improve translation quality even extreme low-resource zero-shot translation direction model never saw explicitly pair parallel data