 improve transformer translation model document-level context although transformer translation model vaswani et al. achieve state-of-the-art performance variety translation task use document-level context deal discourse phenomenon problematic transformer still remain challenge work extend transformer model new context encoder represent document-level context incorporate original encoder decoder large-scale document-level parallel corpus usually available introduce two-step training method take full advantage abundant sentence-level parallel corpus limited document-level parallel corpus experiment nist chinese-english datasets iwslt french-english datasets show approach improve transformer significantly