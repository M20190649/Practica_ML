 sparse coding neural word embeddings multilingual sequence labeling paper propose carefully evaluate sequence labeling framework solely utilizes sparse indicator feature derive dense distribute word representation propose model obtain near state-of-the art performance part-of-speech tagging name entity recognition variety language model rely thousand sparse coding-derived feature without apply modification word representation employ different task propose model favorable generalization property retain average pos tag accuracy train total available training data i.e sentence per language