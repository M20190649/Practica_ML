 abstractive text classification use sequence-to-convolution neural network propose new deep neural network model training scheme text classification model sequence-to-convolution neural network seq cnn consists two block sequential block summarize input text convolution block receive summary input classify label seq cnn train end-to-end classify various-length text without preprocessing input fixed length also present gradual weight shift gws method stabilize training gws apply model 's loss function compare model word-based textcnn train different data preprocessing method obtain significant improvement classification accuracy word-based textcnn without ensemble data augmentation