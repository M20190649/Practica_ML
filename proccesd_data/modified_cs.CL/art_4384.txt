 toward domain-invariant speech recognition via large scale training current state-of-the-art automatic speech recognition system train work specific domain define base factor like application sample rate codec recognizers use condition match training domain performance significantly drop work explore idea build single domain-invariant model varied use-cases combine large scale training data multiple application domain final system train use hour speech additionally utterance artificially distort training simulate effect like background noise codec distortion sample rate result show even scale model thus train work almost well fine-tuned specific subset single model robust multiple application domain variation like codecs noise importantly model generalize good unseen condition allow rapid adaptation -- show use little hour data new domain adapted domain-invariant model match performance domain-specific model train scratch use time much data also highlight limitation model area need address future work