 bidirectional attentional encoder-decoder model bidirectional beam search abstractive summarization sequence generative model rnn variant lstm gru show promising performance abstractive document summarization however still issue limit performance especially deal-ing long sequence one issue best knowledge current model employ unidirectional decoder reason past still limit retain future context give prediction make model suffer generate unbalanced output moreover unidirec-tional attention-based document summarization capture partial aspect attentional regularity due inherited challenge document summarization end propose end-to-end trainable bidirectional rnn model tackle aforementioned issue model bidirectional encoder-decoder architecture encoder decoder bidirectional lstms forward decoder initialize last hidden state backward encoder backward decoder initialize last hidden state for-ward encoder addition bidirectional beam search mechanism propose approximate inference algo-rithm generate output summary bidi-rectional model enable model reason past future generate balanced output result experimental result cnn daily mail dataset show propose model outperform current abstractive state-of-the-art model considerable mar-gin