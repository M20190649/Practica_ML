 question-answering grammatically-interpretable representation introduce architecture tensor product recurrent network tprn application tprn internal representation learn end-to-end optimization deep neural network perform textual question-answering qa task interpret use basic concept linguistic theory performance penalty need pay increase interpretability propose model perform comparably state-of-the-art system squad qa task internal representation interpret tensor product representation input word model select symbol encode word role place symbol bind two together selection via soft attention overall interpretation build interpretation symbol recruit trained model interpretation role use model find support initial hypothesis symbol interpret lexical-semantic word meaning role interpret approximation grammatical role category subject wh-word determiner etc fine-grained analysis reveals specific correspondence learned role part speech assign standard tagger toutanova et al find several discrepancy model 's favor sense model learn significant aspect grammar expose solely linguistically unannotated text question answer prior linguistic knowledge give model give mean build representation use symbol role inductive bias favor use approximately discrete manner