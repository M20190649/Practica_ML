 pervasive attention convolutional neural network sequence-to-sequence prediction current state-of-the-art machine translation system base encoder-decoder architecture first encode input sequence generate output sequence base input encode interfaced attention mechanism recombine fixed encoding source token base decoder state propose alternative approach instead rely single convolutional neural network across sequence layer network re-codes source token basis output sequence produce far attention-like property therefore pervasive throughout network model yield excellent result outperform state-of-the-art encoder-decoder system conceptually simpler few parameter