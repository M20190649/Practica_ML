 efficient estimation word representation vector space propose two novel model architecture compute continuous vector representation word large data set quality representation measure word similarity task result compare previously best perform technique base different type neural network observe large improvement accuracy much low computational cost i.e take less day learn high quality word vector billion word data set furthermore show vector provide state-of-the-art performance test set measure syntactic semantic word similarity