 context-dependent word representation neural machine translation first observe potential weakness continuous vector representation symbol neural machine translation continuous vector representation word embed vector symbol encode multiple dimension similarity equivalent encode one meaning word consequence encoder decoder recurrent network neural machine translation need spend substantial amount capacity disambiguate source target word base context define source sentence base observation paper propose contextualize word embed vector use nonlinear bag-of-words representation source sentence additionally propose represent special token number proper noun acronym typed symbol facilitate translate word well-suited translate via continuous vector experiment en-fr en-de reveal propose approach contextualization symbolization improve translation quality neural machine translation system significantly