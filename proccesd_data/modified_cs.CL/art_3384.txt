 understanding recurrent neural state use memory signatures demonstrate network visualization technique analyze recurrent state inside lstms grus use commonly language acoustic model interpret intermediate state network activation inside end-to-end model remain open challenge method allow user understand exactly much history encode inside recurrent state grapheme sequence model procedure train multiple decoder predict prior input history compile result decoder user obtain signature recurrent kernel characterize memory behavior demonstrate method 's usefulness reveal information divergence base recurrent factorize kernel visualize character-level difference memory n-gram recurrent language model extract knowledge history encode layer grapheme-based end-to-end asr network