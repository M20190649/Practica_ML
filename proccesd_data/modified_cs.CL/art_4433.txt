 neural name entity recognition subword unit name entity recognition ner vital task language technology exist neural model ner rely mostly dedicate word-level representation suffer two main shortcoming vocabulary size large yield large memory requirement training time learn morphological representation adopt neural solution base bidirectional lstms conditional random field rely subword unit namely character phoneme byte remedy shortcoming conduct experiment large dataset cover four language utterance per language experiment show increase train data performance model train solely subword unit becomes closer model dedicated word-level embeddings v f english use much small vocabulary size v k subword unit enhance model dedicated word-level embeddings combine different subword unit improve performance