 contrastive entropy new evaluation metric unnormalized language model perplexity per word widely use metric evaluate language model despite dearth criticism metric criticism center around lack correlation extrinsic metric like word error rate wer dependence upon share vocabulary model comparison unsuitability unnormalized language model evaluation paper address last problem propose new discriminative entropy base intrinsic metric work traditional word level model unnormalized language model like sentence level model also propose discriminatively trained sentence level interpretation recurrent neural network base language model rnn example unnormalized sentence level model demonstrate word level model contrastive entropy show strong correlation perplexity also observe train low distortion level sentence level rnn considerably outperform traditional rnns new metric