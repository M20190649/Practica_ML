 pyramidal recurrent unit language modeling lstms powerful tool model contextual information evidence success task language modeling however model context high dimensional space lead poor generalizability introduce pyramidal recurrent unit pru enable learn representation high dimensional space generalization power few parameter prus replace linear transformation lstms sophisticated interaction include pyramidal group linear transformation architecture give strong result word-level language model reduce number parameter significantly particular pru improve perplexity recent state-of-the-art language model merity et al point learn few parameter similar number model parameter pru outperforms previous rnn model exploit different gate mechanism transformation provide detailed examination pru behavior language modeling task code open-source available http sacmehta.github.io pru