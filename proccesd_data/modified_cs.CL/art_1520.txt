 learn word embeddings speech paper propose novel deep neural network architecture sequence-to-sequence audio vec unsupervised learning fixed-length vector representation audio segment excise speech corpus vector contain semantic information pertain segment close vector embed space corresponding segment semantically similar design propose model base rnn encoder-decoder framework borrow methodology continuous skip-grams training learned vector representation evaluate widely use word similarity benchmark achieve competitive result glove big advantage propose model capability extract semantic information audio segment take directly raw speech without rely modality text image challenge expensive collect annotate