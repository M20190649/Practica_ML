 natural language generation speak dialogue system use rnn encoder-decoder network natural language generation nlg critical component spoken dialogue system paper present recurrent neural network base encoder-decoder architecture lstm-based decoder introduce select aggregate semantic element produce attention mechanism input element produce required utterance propose generator jointly train sentence planning surface realization produce natural language sentence propose model extensively evaluate four different nlg datasets experimental result show propose generator consistently outperform previous method across nlg domain also show ability generalize new unseen domain learn multi-domain datasets