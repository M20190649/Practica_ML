 learn multimodal word representation via dynamic fusion method multimodal model prove outperform text-based model learn semantic word representation almost previous multimodal model typically treat representation different modality equally however obvious information different modality contribute differently meaning word motivate u build multimodal model dynamically fuse semantic representation different modality accord different type word end propose three novel dynamic fusion method assign importance weight modality weight learn weak supervision word association pair extensive experiment demonstrate propose method outperform strong unimodal baseline state-of-the-art multimodal model