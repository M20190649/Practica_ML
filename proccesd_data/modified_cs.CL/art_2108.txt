 joint ctc-attention base end-to-end speech recognition use multi-task learning recently increase interest end-to-end speech recognition directly transcribe speech text without predefined alignment one approach attention-based encoder-decoder framework learn mapping variable-length input output sequence one step use purely data-driven method attention model often show improve performance another end-to-end approach connectionist temporal classification ctc mainly explicitly use history target character without conditional independence assumption however observe performance attention show poor result noisy condition hard learn initial training stage long input sequence attention model flexible predict proper alignment case due lack left-to-right constraint use ctc paper present novel method end-to-end speech recognition improve robustness achieve fast convergence use joint ctc-attention model within multi-task learning framework thereby mitigate alignment issue experiment wsj chime- task demonstrate advantage ctc attention-based encoder-decoder baseline show relative improvement character error rate cer