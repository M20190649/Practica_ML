 address data sparsity issue neural amr parse neural attention model achieve great success different nlp task how- ever fulfil promise amr parse task due data sparsity issue paper de- scribe sequence-to-sequence model amr parsing present different way tackle data sparsity problem show method achieve significant improvement baseline neural atten- tion model result also compet- itive state-of-the-art system use extra linguistic resource