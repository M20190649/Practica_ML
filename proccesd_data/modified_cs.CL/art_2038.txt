 fast small exact infinite-order language model compressed suffix tree efficient method store query critical scale high-order n-gram language model large corpus propose language model base compressed suffix tree representation highly compact easily hold memory support query need compute language model probabilities on-the-fly present several optimisation improve query runtimes x despite incur modest increase construction time memory usage large corpus high markov order method highly competitive state-of-the-art kenlm package impose much low memory requirement often order magnitude runtimes either similar training comparable query