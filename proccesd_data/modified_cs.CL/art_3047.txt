 improve language model noise-contrastive estimation neural language model scale well vocabulary large noise-contrastive estimation nce sampling-based method allow fast learning large vocabulary although nce show promising performance neural machine translation consider unsuccessful approach language modelling sufficient investigation hyperparameters nce-based neural language model also miss paper show nce successful approach neural language modelling hyperparameters neural network tune appropriately introduce 'search-then-converge learning rate schedule nce design heuristic specify use schedule impact important hyperparameters dropout rate weight initialisation range also demonstrate show appropriate tuning nce-based neural language model outperform state-of-the-art single-model method popular benchmark