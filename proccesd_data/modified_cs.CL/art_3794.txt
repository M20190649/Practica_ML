 chinese ner use lattice lstm investigate lattice-structured lstm model chinese ner encode sequence input character well potential word match lexicon compare character-based method model explicitly leverage word word sequence information compare word-based method lattice lstm suffer segmentation error gate recurrent cell allow model choose relevant character word sentence good ner result experiment various datasets show lattice lstm outperform word-based character-based lstm baseline achieve best result