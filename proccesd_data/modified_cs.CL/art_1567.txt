 attention focus neural machine translation bridge source target embeddings neural machine translation source sequence word encode vector target sequence generate decoding phase differently statistical machine translation association source word possible target counterpart explicitly store source target word two end long information processing procedure mediate hidden state source encoding target decoding phase make possible source word incorrectly translate target word admissible equivalent counterpart target language paper seek somewhat shorten distance source target word procedure thus strengthen association mean method term bridge source target word embeddings experiment three strategy source-side bridging model source word embeddings move one step closer output target sequence target-side bridging model explore relevant source word embeddings prediction target sequence direct bridging model directly connect source target word embeddings seek minimize error translation one others experiment analysis present paper demonstrate propose bridging model able significantly improve quality sentence translation general alignment translation individual source word target word particular