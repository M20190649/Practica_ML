 gen cnn convolutional architecture word sequence prediction propose novel convolutional architecture name gen cnn word sequence prediction different previous work neural network-based language modeling generation e.g. rnn lstm choose greedily summarize history word fixed length vector instead use convolutional neural network predict next word history word variable length also different exist feedforward network language modeling model effectively fuse local correlation global correlation word sequence convolution-gating strategy specifically design task argue model give adequate representation history therefore naturally exploit short long range dependency model fast easy train readily parallelize extensive experiment text generation n -best re-ranking machine translation show gen cnn outperform state-of-the-arts big margin