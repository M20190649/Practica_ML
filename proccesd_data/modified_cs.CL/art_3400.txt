 dr-bilstm dependent read bidirectional lstm natural language inference present novel deep learning architecture address natural language inference nli task exist approach mostly rely simple reading mechanism independent encoding premise hypothesis instead propose novel dependent read bidirectional lstm network dr-bilstm efficiently model relationship premise hypothesis encode inference also introduce sophisticated ensemble strategy combine propose model noticeably improve final prediction finally demonstrate result improve additional preprocessing step evaluation show dr-bilstm obtain best single model ensemble model result achieve new state-of-the-art score stanford nli dataset