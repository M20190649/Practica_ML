 knowledge distillation small-footprint highway network deep learning significantly advance state-of-the-art speech recognition past year however compare conventional gaussian mixture acoustic model neural network model usually much large therefore deployable embedded device previously investigate compact highway deep neural network hdnn acoustic modelling type depth-gated feedforward neural network show hdnn-based acoustic model achieve comparable recognition accuracy much small number model parameter compare plain deep neural network dnn acoustic model paper push boundary leverage knowledge distillation technique also know teacher-student training i.e. train compact hdnn model supervision high accuracy cumbersome model furthermore also investigate sequence training adaptation context teacher-student training experiment perform ami meeting speech recognition corpus technique significantly improve recognition accuracy hdnn acoustic model less million parameter narrow gap model plain dnn million parameter