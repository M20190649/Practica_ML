 neural semantic parsing character-based translation experiment abstract mean representation evaluate character-level translation method neural semantic parsing large corpus sentence annotate abstract mean representation amrs use sequence-to-sequence model trivial preprocessing postprocessing amrs obtain baseline accuracy f-score amr-triples examine five different approach improve baseline result reorder amr branch match word order input sentence increase performance ii add part-of-speech tag automatically produce input show improvement well iii introduction super character conflate frequent sequence character single character reach iv optimize training process use pre-training average set model increase performance v add silver-standard training data obtain off-the-shelf parser yield big improvement result f-score combine five technique lead f-score holdout data state-of-the-art amr parsing remarkable relative simplicity approach