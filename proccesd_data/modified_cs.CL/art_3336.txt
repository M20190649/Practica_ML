 question-focused multi-factor attention network question answer neural network model recently propose question answer qa primarily focus capture passage-question relation however minimal capability link relevant fact distribute across multiple sentence crucial achieve deep understanding perform multi-sentence reasoning co-reference resolution etc also explicitly focus question answer type often play critical role qa paper propose novel end-to-end question-focused multi-factor attention network answer extraction multi-factor attentive encode use tensor-based transformation aggregate meaningful fact even locate multiple sentence implicitly infer answer type also propose max-attentional question aggregation mechanism encode question vector base important word question prediction incorporate sequence-level encoding first wh-word immediately follow word additional source question type information propose model achieve significant improvement best prior state-of-the-art result three large-scale challenge qa datasets namely newsqa triviaqa searchqa