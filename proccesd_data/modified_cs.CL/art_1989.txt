 syntax-based attention model natural language inference introduce attentional mechanism neural network powerful concept achieve impressive result many natural language processing task however exist model impose attentional distribution flat topology namely entire input representation sequence clearly well-formed sentence accompany syntactic tree structure much rich topology apply attention topology exploit underlying syntax also make attention interpretable paper explore direction context natural language inference result demonstrate efficacy also perform extensive qualitative analysis derive insight intuition model work