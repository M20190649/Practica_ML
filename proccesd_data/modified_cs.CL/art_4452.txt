 visual attention ground neural model multimodal machine translation introduce novel multimodal machine translation model utilize parallel visual textual information model jointly optimize learning share visual-language embedding translator model leverage visual attention ground mechanism link visual semantics correspond textual semantics approach achieve competitive state-of-the-art result multi k ambiguous coco datasets also collect new multilingual multimodal product description dataset simulate real-world international online shopping scenario dataset visual attention ground model outperform method large margin