 graph-to-sequence model amr-to-text generation problem amr-to-text generation recover text represent meaning input amr graph current state-of-the-art method use sequence-to-sequence model leverage lstm encode linearized amr structure although able model non-local semantic information sequence lstm lose information amr graph structure thus face challenge large graph result long sequence introduce neural graph-to-sequence model use novel lstm structure directly encode graph-level semantics standard benchmark model show superior result exist method literature