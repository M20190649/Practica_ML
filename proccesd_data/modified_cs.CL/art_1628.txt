 model coherence neural machine translation dynamic topic cache sentence well-formed text connect via various link form cohesive structure text current neural machine translation nmt system translate text conventional sentence-by-sentence fashion ignore cross-sentence link dependency may lead generate incoherent target text coherent source text order handle issue propose cache-based approach model coherence neural machine translation capture contextual information either recently translate sentence entire document particularly explore two type cache dynamic cache store word best translation hypothesis precede sentence topic cache maintain set target-side topical word semantically relate document translate basis build new layer score target word two cache cache-based neural model estimate probability cache-based neural model combine nmt probability final word prediction probability via gating mechanism finally propose cache-based neural model train jointly nmt system end-to-end manner experiment analysis present paper demonstrate propose cache-based model achieve substantial improvement several state-of-the-art smt nmt baseline