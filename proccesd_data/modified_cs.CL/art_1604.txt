 exploration word embed initialization deep-learning task word embeddings interface world discrete unit text processing continuous differentiable world neural network work examine various random pretrained initialization method embeddings use deep network effect performance four nlp task recurrent convolutional architecture confirm pretrained embeddings little good random initialization especially consider speed learning hand see significant difference various method random initialization long variance keep reasonably low high-variance initialization prevent network use space embeddings force use free parameter accomplish task support hypothesis observe performance learn lexical relation fact network learn perform reasonably task even fixed random embeddings