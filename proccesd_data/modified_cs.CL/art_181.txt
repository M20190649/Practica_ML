 bit progress language modeling past several year number different language modeling improvement simple trigram model find include caching higher-order n-grams skip interpolate kneser-ney smoothing clustering present exploration variation limit technique include show sentence mixture model may potential technique study separately rarely study combination find significant interaction especially smooth cluster technique compare combination technique together katz smooth trigram model count cutoff achieve perplexity reduction bit entropy depend train data size well word error rate reduction perplexity reduction perhaps high report compare fair baseline extended version paper contain additional detail proof design good introduction state art language modeling