 pragmatic neural language modelling machine translation paper present in-depth investigation integrate neural language model translation system scale neural language model difficult task crucial real-world application paper evaluate impact end-to-end mt quality new exist scale technique show explicitly normalise neural model necessary optimisation trick one use scenario also focus scalable training algorithm investigate noise contrastive estimation diagonal context source speed improvement explore trade-off neural model back-off n-gram model find neural model make strong candidate natural language application memory constrain environment yet still lag behind traditional model raw translation quality conclude set recommendation one follow build scalable neural language model mt