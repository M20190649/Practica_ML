 multi-task learn domain-general spoken disfluency detection dialogue system spontaneous spoken dialogue often disfluent contain pause hesitation self-corrections false start processing phenomenon essential understand speaker 's intend meaning control flow conversation furthermore processing need word-by-word incremental allow downstream processing begin early possible order handle real spontaneous human conversational behaviour addition developer 's point view highly desirable able develop system train clean example also able generalise diverse disfluent variation data -- thereby enhance data-efficiency robustness paper present multi-task lstm-based model incremental detection disfluency structure hook component incremental interpretation e.g incremental semantic parser else simply use clean current utterance produce train system switchboard dialogue act swda corpus present accuracy dataset model outperform prior neural network-based incremental approach percentage point swda employ simpler architecture test model 's generalisation potential evaluate model babi dataset without additional training babi dataset synthesised goal-oriented dialogue control distribution disfluency type show approach good generalisation potential shed light type disfluency might amenable domain-general processing