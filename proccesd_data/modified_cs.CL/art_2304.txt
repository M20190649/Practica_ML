 neural machine translation source-side latent graph parse paper present novel neural machine translation model jointly learn translation source-side latent graph representation sentence unlike exist pipelined approach use syntactic parser end-to-end model learn latent graph parser part encoder attention-based neural machine translation model thus parser optimize accord translation objective experiment first show model compare favorably state-of-the-art sequential pipelined syntax-based nmt model also show performance model improve pre-training small amount treebank annotation final ensemble model significantly outperform previous best model standard english-to-japanese translation dataset