 graph-based filtering out-of-vocabulary word encoder-decoder model encoder-decoder model typically employ word frequently use training corpus reduce computational cost exclude noise however vocabulary set may still include word interfere learn encoder-decoder model paper propose method select suitable word learn encoders utilize frequency also co-occurrence information capture use hit algorithm apply propose method two task machine translation grammatical error correction japanese-to-english translation method achieve bleu score point baseline also outperform baseline method english grammatical error correction f -measure point higher