 fine-grained analysis sentence embeddings use auxiliary prediction task lot research interest encode variable length sentence fixed length vector way preserve sentence meaning two common method include representation base average word vector representation base hidden state recurrent neural network lstms sentence vector use feature subsequent machine learn task pre-training context deep learning however much know property encode sentence representation language information capture propose framework facilitate well understanding encoded representation define prediction task around isolated aspect sentence structure namely sentence length word content word order score representation ability train classifier solve prediction task use representation input demonstrate potential contribution approach analyze different sentence representation mechanism analysis shed light relative strength different sentence embed method respect low level prediction task effect encoded vector 's dimensionality resulting representation