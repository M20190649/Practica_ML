 network-efficient distribute word vec training system large vocabulary word vec popular family algorithm unsupervised training dense vector representation word large text corpus result vector show capture semantic relationship among corresponding word show promise reduce number natural language processing nlp task mathematical operation vector heretofore application word vec center around vocabulary million word wherein vocabulary set word vector simultaneously train novel application emerge area outside nlp vocabulary comprise several million word exist word vec training system impractical train large vocabulary either require vector vocabulary word store memory single server suffer unacceptable training latency due massive network data transfer paper present novel distribute parallel training system enable unprecedented practical training vector vocabulary several million word share cluster commodity server use far less network traffic exist solution evaluate proposed system benchmark dataset show quality vector degrade relative non-distributed training finally several quarter system deploy purpose match query ad gemini sponsor search advertising platform yahoo result significant improvement business metric