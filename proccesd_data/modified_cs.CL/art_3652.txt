 ntua-slp semeval- task predict affective content tweet deep attentive rnns transfer learning paper present deep-learning model submit semeval- task competition affect tweet participate subtasks english tweet propose bi-lstm architecture equip multi-layer self attention mechanism attention mechanism improve model performance allow u identify salient word tweet well gain insight model make interpretable model utilize set word vec word embeddings train large collection million twitter message augment set word affective feature due limited amount task-specific training data opt transfer learn approach pretraining bi-lstms dataset semeval task a. propose approach rank st subtask e multi-label emotion classification nd subtask emotion intensity regression achieve competitive result subtasks