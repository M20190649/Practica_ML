 multi-channel encoder neural machine translation attention-based encoder-decoder effective architecture neural machine translation nmt typically rely recurrent neural network rnn build block lately call attentive reader decoding process design encoder yield relatively uniform composition source sentence despite gating mechanism employ encode rnn hand often hope decoder take piece source sentence varying level suit linguistic structure example may want take entity name raw form take idiom perfectly compose unit motivate demand propose multi-channel encoder mce enhance encode component different level composition specifically addition hidden state encode rnn mce take original word embed raw encode composition particular design external memory neural turing machine ntm complex composition three encode strategy properly blend decoding empirical study chinese-english translation show model improve bleu point upon strong open source nmt system dl mt wmt english- french task single shallow system achieve bleu comparable state-of-the-art deep model