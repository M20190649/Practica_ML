 hash embeddings efficient word representation present hash embeddings efficient method represent word continuous vector form hash embedding may see interpolation standard word embedding word embedding create use random hash function hashing trick hash embeddings token represent k -dimensional embeddings vector one k dimensional weight vector final dimensional representation token product two rather fit embedding vector token select hash trick share pool b embed vector experiment show hash embeddings easily deal huge vocabulary consist million token use hash embed need create dictionary train perform kind vocabulary pruning training show model train use hash embeddings exhibit least level performance model train use regular embeddings across wide range task furthermore number parameter need embedding fraction require regular embedding since standard embeddings embeddings construct use hashing trick actually special case hash embedding hash embeddings consider extension improvement exist regular embed type