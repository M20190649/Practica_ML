 evaluation neural machine translation model historical spell normalization paper apply different nmt model problem historical spell normalization five language english german hungarian icelandic swedish nmt model different level different attention mechanism different neural network architecture result show nmt model much good smt model term character error rate vanilla rnns competitive grus lstms historical spelling normalization transformer model perform good provide training data also find subword-level model small subword vocabulary good character-level model low-resource language addition propose hybrid method improve performance historical spell normalization