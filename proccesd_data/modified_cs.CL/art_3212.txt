 deep semantic role label self-attention semantic role label srl believe crucial step towards natural language understanding widely study recent year end-to-end srl recurrent neural network rnn gain increase attention however remain major challenge rnns handle structural information long range dependency paper present simple effective architecture srl aim address problem model base self-attention directly capture relationship two token regardless distance single model achieves f conll- shared task dataset f conll- shared task dataset outperform previous state-of-the-art result f score respectively besides model computationally efficient parse speed k token per second single titan x gpu