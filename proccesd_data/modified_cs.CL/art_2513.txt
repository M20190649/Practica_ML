 empirical analysis nmt-derived interlingual embeddings use parallel sentence identification end-to-end neural machine translation overtake statistical machine translation term translation quality language pair specially large amount parallel data besides palpable improvement neural network provide several new property single system train translate many language almost additional cost train time furthermore internal representation learn network serve new semantic representation word -or sentences- unlike standard word embeddings learn essentially bilingual even multilingual context view property contribution present work two-fold first systematically study nmt context vector i.e output encoder power interlingua representation sentence assess quality effectiveness measure similarity across translation well semantically relate semantically unrelated sentence pair second extrinsic evaluation first point identify parallel sentence comparable corpus obtain f data share task use nmt context vector use context vector jointly similarity measure f reach