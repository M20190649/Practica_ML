 sequential neural encoder latent structure description model sentence paper propose sequential neural encoder latent structure description snelsd model sentence model introduce latent chunk-level representation conventional sequential neural encoders i.e. recurrent neural network rnns long short-term memory lstm unit consider compositionality language semantic modeling snelsd model hierarchical structure include detection layer description layer detection layer predict boundary latent word chunk input sentence derive chunk-level vector word description layer utilizes modify lstm unit process chunk-level vector recurrent manner produce sequential encoding output output vector concatenate word vector output chain lstm encoder obtain final sentence representation model parameter learn end-to-end manner without dependency additional text chunking syntax parsing natural language inference nli task sentiment analysis sa task adopt evaluate performance propose model experimental result demonstrate effectiveness propose snelsd model explore task-dependent chunking pattern semantic modeling sentence furthermore propose method achieve good performance conventional chain lstms tree-structured lstms task