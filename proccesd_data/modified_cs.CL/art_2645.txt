 recurrent additive network introduce recurrent additive network rans new gate rnn distinguish use purely additive latent state update every time step new state compute gated component-wise sum input previous state without non-linearities commonly use rnn transition dynamic formally show ran state weight sum input vector gate contribute compute weight sum despite relatively simple functional form experiment demonstrate rans perform par lstms benchmark language model problem result show many non-linear computation lstms related network essential least problem consider suggest gate computational work previously understand