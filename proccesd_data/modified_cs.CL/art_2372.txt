 soft label memorization-generalization natural language inference often multiple label obtain training example assume element noise must account show disagreement consider signal instead noise work investigate use soft label train data improve generalization machine learning model however use soft label train deep neural network dnns practical due cost involve obtain multiple label large data set propose soft label memorization-generalization slmg fine-tuning approach use soft label train dnns assume difference label provide human annotator represent ambiguity true label instead noise experiment slmg demonstrate improve generalization performance natural language inference nli task experiment show inject small percentage soft label training data training set size improve generalization performance several baseline