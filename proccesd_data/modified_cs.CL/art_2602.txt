 supervise learning universal sentence representation natural language inference data many modern nlp system rely word embeddings previously train unsupervised manner large corpus base feature effort obtain embeddings large chunk text sentence however successful several attempt learn unsupervised representation sentence reach satisfactory enough performance widely adopt paper show universal sentence representation train use supervise data stanford natural language inference datasets consistently outperform unsupervised method like skipthought vector wide range transfer task much like computer vision use imagenet obtain feature transfer task work tend indicate suitability natural language inference transfer learning nlp task encoder publicly available