 learn embed word context syntactic task present model embed word context surround word model refer token embeddings represent characteristic word specific give context word sense syntactic category semantic role explore simple efficient token embed model base standard neural network architecture learn token embeddings large amount unannotated text evaluate feature part-of-speech tagger dependency parser train much small amount annotate data find predictor endow token embeddings consistently outperform baseline predictor across range context window training set size