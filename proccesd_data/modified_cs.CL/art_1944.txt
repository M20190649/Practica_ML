 topic aware neural response generation consider incorporate topic information sequence-to-sequence framework generate informative interesting response chatbots end propose topic aware sequence-to-sequence ta-seq seq model model utilizes topic simulate prior knowledge human guide form informative interesting response conversation leverage topic information generation joint attention mechanism biased generation probability joint attention mechanism summarize hidden vector input message context vector message attention synthesize topic vector topic attention topic word message obtain pre-trained lda model let vector jointly affect generation word decoding increase possibility topic word appear response model modify generation probability topic word add extra probability item bias overall distribution empirical study automatic evaluation metric human annotation show ta-seq seq generate informative interesting response significantly outperform the-state-of-the-art response generation model