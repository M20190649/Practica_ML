 deep architecture neural machine translation show increase model depth improve quality neural machine translation however different architectural variant increase model depth propose far thorough comparative study work describe evaluate several exist approach introduce depth neural machine translation additionally explore novel architectural variant include deep transition rnns vary attention use deep decoder introduce novel bideep rnn architecture combine deep transition rnns stack rnns evaluation carry english german wmt news translation dataset use single-gpu machine training inference find several propose architecture improve upon exist approach term speed translation quality obtain best improvement bideep rnn combined depth obtain average improvement bleu strong shallow baseline release code ease adoption