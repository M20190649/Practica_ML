 goldilocks principle reading child 's book explicit memory representation introduce new test well language model capture mean child 's book unlike standard language modelling benchmark distinguish task predict syntactic function word predict lower-frequency word carry great semantic content compare range state-of-the-art model different way encode previously read show model store explicit representation long-term contexts outperform state-of-the-art neural language model predict semantic content word although advantage observe syntactic function word interestingly find amount text encode single memory representation highly influential performance sweet-spot big small single word full sentence allow meaningful information text effectively retain recall attention window-based memory train effectively self-supervision assess generality principle apply cnn qa benchmark involve identify name entity paraphrased summary news article achieve state-of-the-art performance