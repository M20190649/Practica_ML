 learn word embeddings hyponymy entailment-based distributional semantics lexical entailment hyponymy fundamental issue semantics natural language paper propose distributional semantic model efficiently learn word embeddings entailment use recently-proposed framework model entailment vector-space model postulate latent vector pseudo-phrase containing two neighbouring word vector investigate model word evidence contribute phrase vector posterior distribution one-word phrase vector find posterior vector perform good result word embeddings outperform best previous result predict hyponymy word unsupervised semi-supervised experiment