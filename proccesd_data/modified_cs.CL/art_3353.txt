 reinforce self-attention network hybrid hard soft attention sequence model many natural language processing task solely rely sparse dependency token sentence soft attention mechanism show promising performance model local global dependency soft probability every two token effective efficient apply long sentence contrast hard attention mechanism directly select subset token difficult inefficient train due combinatorial nature paper integrate soft hard attention one context fusion model reinforce self-attention resa mutual benefit resa hard attention trim sequence soft self-attention process soft attention feed reward signal back facilitate training hard one purpose develop novel hard attention call reinforce sequence sample r select token parallel trained via policy gradient use two rss module resa efficiently extract sparse dependency pair select token finally propose rnn cnn-free sentence-encoding model reinforce self-attention network resan solely base resa achieve state-of-the-art performance stanford natural language inference snli sentence involve compositional knowledge sick datasets