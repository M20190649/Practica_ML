 spine sparse interpretable neural embeddings prediction without justification limit utility much success neural model attribute ability learn rich dense expressive representation representation capture underlying complexity latent trend data far interpretable propose novel variant denoising k-sparse autoencoders generate highly efficient interpretable distribute word representation word embeddings begin exist word representation state-of-the-art method like glove word vec large scale human evaluation report result word embedddings much interpretable original glove word vec embeddings moreover embeddings outperform exist popular word embeddings diverse suite benchmark downstream task