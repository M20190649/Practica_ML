 hierarchical recurrent attention network response generation study multi-turn response generation chatbots response generate accord conversation context exist work model hierarchy context pay enough attention fact word utterance context differentially important result may lose important information context generate irrelevant response propose hierarchical recurrent attention network hran model aspect unified framework hran hierarchical attention mechanism attend important part within among utterance word level attention utterance level attention respectively word level attention hidden vector word level encoder synthesize utterance vector fed utterance level encoder construct hidden representation context hidden vector context process utterance level attention form context vector decode response empirical study automatic evaluation human judgment show hran significantly outperform state-of-the-art model multi-turn response generation