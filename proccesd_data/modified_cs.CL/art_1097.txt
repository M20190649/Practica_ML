 character-based neural machine translation introduce neural machine translation model view input output sentence sequence character rather word since word-level information provide crucial source bias input model compose representation character sequence representation word determine whitespace boundary translate use joint attention translation model target language translation model sequence word vector word generate one character time conditional previous character generation word representation generation word perform character level model capable interpret generate unseen word form secondary benefit approach alleviate much challenge associate preprocessing tokenization source target language show model achieve translation result par conventional word-based model