 graph convolution pruned dependency tree improve relation extraction dependency tree help relation extraction model capture long-range relation word however exist dependency-based model either neglect crucial information e.g. negation prune dependency tree aggressively computationally inefficient difficult parallelize different tree structure propose extension graph convolutional network tailor relation extraction pool information arbitrary dependency structure efficiently parallel incorporate relevant information maximally remove irrelevant content apply novel pruning strategy input tree keep word immediately around short path two entity among relation might hold result model achieve state-of-the-art performance large-scale tacred dataset outperform exist sequence dependency-based neural model also show detail analysis model complementary strength sequence model combine improve state art