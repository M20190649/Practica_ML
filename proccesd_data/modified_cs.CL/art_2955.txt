 transfer learn across low-resource related language neural machine translation present simple method improve neural translation low-resource language pair use parallel data related also low-resource language pair method base transfer method zoph et al. whereas method ignore source vocabulary overlap exploit first split word use byte pair encode bpe increase vocabulary overlap train model first language pair transfer parameter include source word embeddings another model continue train second language pair experiment show transfer learning help word-based translation slightly use top much strong bpe baseline yield large improvement bleu