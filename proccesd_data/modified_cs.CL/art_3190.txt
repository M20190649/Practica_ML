 study all-convolutional encoders connectionist temporal classification connectionist temporal classification ctc popular sequence prediction approach automatic speech recognition typically use model base recurrent neural network rnns explore whether deep convolutional neural network cnns use effectively instead rnns encoder ctc cnns lack explicit representation entire sequence advantage much faster train present exploration cnns encoders ctc model context character-based lexicon-free automatic speech recognition particular explore range one-dimensional convolutional layer particularly efficient compare performance cnn-based model typical rnnbased model term training time decode time model size word error rate wer switchboard eval corpus find cnn-based model close performance lstms match much faster train decode