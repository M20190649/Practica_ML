 model coverage neural machine translation attention mechanism enhance state-of-the-art neural machine translation nmt jointly learn align translate tend ignore past alignment information however often lead over-translation under-translation address problem propose coverage-based nmt paper maintain coverage vector keep track attention history coverage vector feed attention model help adjust future attention let nmt system consider untranslated source word experiment show propose approach significantly improve translation quality alignment quality standard attention-based nmt