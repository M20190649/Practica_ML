 neural language model dynamically represent meaning unknown word entity discourse study address problem identify meaning unknown word entity discourse respect word embed approach use neural language model propose method on-the-fly construction exploitation word embeddings input output layer neural model track context extend dynamic entity representation use kobayashi et al incorporate copy mechanism propose independently gu et al gulcehre et al addition construct new task dataset call anonymized language model evaluate ability capture word meaning reading experiment conduct use novel dataset show propose variant rnn language model outperform baseline model furthermore experiment also demonstrate dynamic update output layer help model predict reappear entity whereas input layer effective predict word follow reappear entity