 convolutional sequence sequence learn prevalent approach sequence sequence learn map input sequence variable length output sequence via recurrent neural network introduce architecture base entirely convolutional neural network compare recurrent model computation element fully parallelize training optimization easy since number non-linearities fix independent input length use gated linear unit ease gradient propagation equip decoder layer separate attention module outperform accuracy deep lstm setup wu et al wmt english-german wmt english-french translation order magnitude faster speed gpu cpu