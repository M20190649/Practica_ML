 learn well word embed asymmetric low-rank projection knowledge graph word embedding refer low-dimensional dense vector representation natural word demonstrate power many natural language processing task however may suffer inaccurate incomplete information contain free text corpus training data tackle challenge quite work leverage knowledge graph additional information source improve quality word embedding although work achieve certain success neglect important fact knowledge graph many relationship knowledge graph emph many-to-one emph one-to-many even emph many-to-many rather simply emph one-to-one ii head entity tail entity knowledge graph come different semantic space address issue paper propose new algorithm name projectnet projecnet model relationship head tail entity transform different low-rank projection matrix low-rank projection allow non emph one-to-one relationship entity different projection matrix head tail entity allow originate different semantic space experimental result demonstrate projectnet yield accurate word embed previous work thus lead clear improvement various natural language processing task