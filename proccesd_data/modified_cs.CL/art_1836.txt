 unsupervised word dependency path embeddings aspect term extraction paper develop novel approach aspect term extraction base unsupervised learning distributed representation word dependency path basic idea connect two word w w dependency path r embedding space specifically method optimize objective w r w low-dimensional space multi-hop dependency path treat sequence grammatical relation model recurrent neural network design embedding feature consider linear context dependency context information conditional random field crf base aspect term extraction experimental result semeval datasets show embed feature achieve state-of-the-art result embed method incorporate syntactic information among word yield good performance representative one aspect term extraction