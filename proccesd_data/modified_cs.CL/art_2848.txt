 recurrent neural network-based sentence encoder gated attention natural language inference repeval share task aim evaluate natural language understanding model sentence representation sentence represent fixed-length vector neural network quality representation test natural language inference task paper describe system alpha rank among top share task in-domain test set obtain accuracy cross-domain test set also attain accuracy demonstrate model generalize well cross-domain data model equip intra-sentence gated-attention composition help achieve good performance addition submit model share task also test stanford natural language inference snli dataset obtain accuracy best report result snli cross-sentence attention allow condition enforce repeval