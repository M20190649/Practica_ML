 one billion word benchmark measure progress statistical language model propose new benchmark corpus use measure progress statistical language modeling almost one billion word training data hope benchmark useful quickly evaluate novel language model technique compare contribution combine advanced technique show performance several well-known type language model best result achieve recurrent neural network base language model baseline unpruned kneser-ney -gram model achieve perplexity combination technique lead reduction perplexity reduction cross-entropy bit baseline benchmark available code.google.com project besides script need rebuild training held-out data also make available log-probability value word ten held-out data set baseline n-gram model