 knowledge representation via joint learning sequential text knowledge graph textual information consider significant supplement knowledge representation learn krl two main challenge construct knowledge representation plain text take full advantage sequential context entity plain text krl dynamically select informative sentence corresponding entity krl paper propose sequential text-embodied knowledge representation learn build knowledge representation multiple sentence give reference sentence entity first utilize recurrent neural network pooling long short-term memory network encode semantic information sentence respect entity design attention model measure informativeness sentence build text-based representation entity evaluate method two task include triple classification link prediction experimental result demonstrate method outperform baseline task indicate method capable select informative sentence encode textual information well knowledge representation