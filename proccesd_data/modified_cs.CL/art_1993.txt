 latent tree language model paper introduce latent tree language model ltlm novel approach language model encode syntax semantics give sentence tree word role learning phase iteratively update tree move node accord gibbs sampling introduce two algorithm infer tree give sentence first one base gibbs sampling fast guarantee find probable tree second one base dynamic programming slow guarantee find probable tree provide comparison algorithm combine ltlm -gram modify kneser-ney language model via linear interpolation experiment english czech corpus show significant perplexity reduction english czech compare standalone -gram modify kneser-ney language model