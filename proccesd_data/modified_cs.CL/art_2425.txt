 toktrack complete token provenance change tracking dataset english wikipedia present dataset contain every instance token word ever write undeleted non-redirect english wikipedia article october total instance token annotate article revision originally create ii list revision token ever delete potentially re-added re-deleted article enable complete straightforward tracking history data would exceedingly hard create average potential user expensive compute ii accurately track history token revisioned document non-trivial task adapt state-of-the-art algorithm produce dataset allow range analysis metric already popular research go beyond generate complete-wikipedia scale ensure quality allow researcher forego expensive text-comparison computation far hinder scalable usage show data enable token-level computation provenance measure survival content time detailed conflict metric fine-grained interaction editor like partial reverts re-additions metric process gain several novel insight