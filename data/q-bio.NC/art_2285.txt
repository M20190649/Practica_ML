Input Statistics and Hebbian Crosstalk Effects
As an extension of prior work, we study inspecific Hebbian learning using the
classical Oja model. We use a combination of analytical tools and numerical
simulations to investigate how the effects of inspecificity (or synaptic
"cross-talk") depend on the input statistics. We investigated a variety of
patterns that appear in dimensions higher than 2 (and classified them based on
covariance type and input bias). The effects of inspecificity on the learning
outcome were found to depend very strongly on the nature of the input, and in
some cases were very dramatic, making unlikely the existence of a generic
neural algorithm to correct learning inaccuracy due to cross-talk. We discuss
the possibility that sophisticated learning, such as presumably occurs in the
neocortex, is enabled as much by special proofreading machinery for enhancing
specificity, as by special algorithms.