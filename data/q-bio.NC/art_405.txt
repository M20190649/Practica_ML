Reinforcement and inference in cross-situational word learning
Cross-situational word learning is based on the notion that a learner can
determine the referent of a word by finding something in common across many
observed uses of that word. Here we propose an adaptive learning algorithm that
contains a parameter that controls the strength of the reinforcement applied to
associations between concurrent words and referents, and a parameter that
regulates inference, which includes built-in biases, such as mutual
exclusivity, and information of past learning events. By adjusting these
parameters so that the model predictions agree with data from representative
experiments on cross-situational word learning, we were able to explain the
learning strategies adopted by the participants of those experiments in terms
of a trade-off between reinforcement and inference. These strategies can vary
wildly depending on the conditions of the experiments. For instance, for fast
mapping experiments (i.e., the correct referent could, in principle, be
inferred in a single observation) inference is prevalent, whereas for
segregated contextual diversity experiments (i.e., the referents are separated
in groups and are exhibited with members of their groups only) reinforcement is
predominant. Other experiments are explained with more balanced doses of
reinforcement and inference.