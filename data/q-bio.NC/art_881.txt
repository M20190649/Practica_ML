Classification of meaningful and meaningless visual objects: a graph
  similarity approach
Cognition involves dynamic reconfiguration of functional brain networks at
sub-second time scale. A precise tracking of these reconfigurations to
categorize visual objects remains elusive. Here, we use dense
electroencephalography (EEG) data recorded during naming meaningful (tools,
animals) and scrambled objects from 20 healthy subjects. We combine technique
for identifying functional brain networks and recently developed algorithm for
estimating networks similarity to discriminate between the two categories.
First, we showed that dynamic networks of both categories can be segmented into
several brain network states (times windows with consistent brain networks)
reflecting sequential information processing from object representation to
reaction time. Second, using a network similarity algorithm, results showed
high intra-category and very low inter-category values. An average accuracy of
76% was obtained at different brain network states.