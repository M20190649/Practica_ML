Neuronal networks and controlled symmetries, a generic framework
The extraordinary computational power of the brain may be related in part to
the fact that each of the smaller neural networks that compose it can behave
transiently in many different ways, depending on its inputs. Mathematically,
input continuity helps to show how a large network, constructed recursively
from smaller blocks, can exhibit robust specific properties according to its
input. By extending earlier work on synchrony and symmetry, we exploit input
continuity of contracting systems to ensure robust control of diverse spatial
and spatio-temporal symmetries of the output signal in such a network.