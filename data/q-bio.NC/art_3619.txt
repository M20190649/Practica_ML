A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition
The neuroscience study has revealed the discrepancy of emotion expression
between left and right hemispheres of human brain. Inspired by this study, in
this paper, we propose a novel bi-hemispheric discrepancy model (BiHDM) to
learn the asymmetric differences between two hemispheres for
electroencephalograph (EEG) emotion recognition. Concretely, we first employ
four directed recurrent neural networks (RNNs) based on two spatial
orientations to traverse electrode signals on two separate brain regions, which
enables the model to obtain the deep representations of all the EEG electrodes'
signals while keeping the intrinsic spatial dependence. Then we design a
pairwise subnetwork to capture the discrepancy information between two
hemispheres and extract higher-level features for final classification.
Besides, in order to reduce the domain shift between training and testing data,
we use a domain discriminator that adversarially induces the overall feature
learning module to generate emotion-related but domain-invariant feature, which
can further promote EEG emotion recognition. We conduct experiments on three
public EEG emotional datasets, and the experiments show that the new
state-of-the-art results can be achieved.