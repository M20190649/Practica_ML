Encoding Sensory and Motor Patterns as Time-Invariant Trajectories in
  Recurrent Neural Networks
Much of the information the brain processes and stores is temporal in nature
- a spoken word or a handwritten signature, for example, is defined by how it
unfolds in time. However, it remains unclear how neural circuits encode complex
time-varying patterns. We show that by tuning the weights of a recurrent neural
network (RNN), it can recognize and then transcribe spoken digits. The model
elucidates how neural dynamics in cortical networks may resolve three
fundamental challenges: first, encode multiple time-varying sensory and motor
patterns as stable neural trajectories; second, generalize across relevant
spatial features; third, identify the same stimuli played at different speeds -
we show that this temporal invariance emerges because the recurrent dynamics
generate neural trajectories with appropriately modulated angular velocities.
Together our results generate testable predictions as to how recurrent networks
may use different mechanisms to generalize across the relevant spatial and
temporal features of complex time-varying stimuli.