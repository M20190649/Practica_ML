The PoincarÃ©-Boltzmann Machine: from Statistical Physics to Machine
  Learning and back
This paper presents the computational methods of information cohomology
applied to genetic expression in and in the companion paper and proposes its
interpretations in terms of statistical physics and machine learning. In order
to further underline the Hochschild cohomological nature af information
functions and chain rules, following, the computation of the cohomology in low
degrees is detailed to show more directly that the $k$ multivariate
mutual-informations (I_k) are k-coboundaries. The k-cocycles condition
corresponds to I_k=0, generalizing statistical independence. Hence the
cohomology quantifies the statistical dependences and the obstruction to
factorization. The topological approach allows to investigate information in
the multivariate case without the assumptions of independent identically
distributed variables and without mean field approximations. We develop the
computationally tractable subcase of simplicial information cohomology
represented by entropy H_k and information I_k landscapes and their respective
paths. The I_1 component defines a self-internal energy U_k, and I_k,k>1
components define the contribution to a free energy G_k (the total correlation)
of the k-body interactions. The set of information paths in simplicial
structures is in bijection with the symmetric group and random processes,
provides a trivial topological expression of the 2nd law of thermodynamic. The
local minima of free-energy, related to conditional information negativity, and
conditional independence, characterize a minimum free energy complex. This
complex formalizes the minimum free-energy principle in topology, provides a
definition of a complex system, and characterizes a multiplicity of local
minima that quantifies the diversity observed in biology. I give an
interpretation of this complex in terms of frustration in glass and of Van Der
Walls k-body interactions for data points.