Learning Through Time in the Thalamocortical Loops
We present a comprehensive, novel framework for understanding how the
neocortex, including the thalamocortical loops through the deep layers, can
support a temporal context representation in the service of predictive
learning. Many have argued that predictive learning provides a compelling,
powerful source of learning signals to drive the development of human
intelligence: if we constantly predict what will happen next, and learn based
on the discrepancies from our predictions (error-driven learning), then we can
learn to improve our predictions by developing internal representations that
capture the regularities of the environment (e.g., physical laws governing the
time-evolution of object motions). Our version of this idea builds upon
existing work with simple recurrent networks (SRN's), which have a
discretely-updated temporal context representations that are a direct copy of
the prior internal state representation. We argue that this discretization of
temporal context updating has a number of important computational and
functional advantages, and further show how the strong alpha-frequency (10hz,
100ms cycle time) oscillations in the posterior neocortex could reflect this
temporal context updating. We examine a wide range of data from biology to
behavior through the lens of this LeabraTI model, and find that it provides a
unified account of a number of otherwise disconnected findings, all of which
converge to support this new model of neocortical learning and processing. We
describe an implemented model showing how predictive learning of tumbling
object trajectories can facilitate object recognition with cluttered
backgrounds.