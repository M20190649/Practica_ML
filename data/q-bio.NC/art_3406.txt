A nonequilibrium-potential approach to competition in neural populations
Energy landscapes are a useful aid for the understanding of dynamical
systems, and a valuable tool for their analysis. For a broad class of rate
models of neural networks, we derive a global Lyapunov function which provides
an energy landscape without any symmetry constraint. This newly obtained
`nonequilibrium potential' (NEP) predicts with high accuracy the outcomes of
the dynamics in the globally stable cases studied here. Common features of the
models in this class are bistability --with implications for working memory and
slow neural oscillations --and `population burst', also relevant in
neuroscience. Instead, limit cycles are not found. Their nonexistence can be
proven by resort to the Bendixson--Dulac theorem, at least when the NEP remains
positive and in the (also generic) singular limit of these models. Hopefully,
this NEP will help understand average neural network dynamics from a more
formal standpoint, and will also be of help in the description of large
heterogeneous neural networks.