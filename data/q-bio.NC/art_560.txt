Critical and maximally informative encoding between neural populations
  in the retina
Computation in the brain involves multiple types of neurons, yet the
organizing principles for how these neurons work together remain unclear.
Information theory has offered explanations for how different types of neurons
can optimize the encoding of different stimulus features. However, recent
experiments indicate that separate neuronal types exist that encode the same
stimulus features, but do so with different thresholds. Here we show that the
emergence of these types of neurons can be quantitatively described by the
theory of transitions between different phases of matter. The two key
parameters that control the separation of neurons into subclasses are the mean
and standard deviation of noise levels among neurons in the population. The
mean noise level plays the role of temperature in the classic theory of phase
transitions, whereas the standard deviation is equivalent to pressure, in the
case of liquid-gas transitions, or to magnetic field for magnetic transitions.
Our results account for properties of two recently discovered types of
salamander OFF retinal ganglion cells, as well as the absence of multiple types
of ON cells. We further show that, across visual stimulus contrasts, retinal
circuits continued to operate near the critical point whose quantitative
characteristics matched those expected near a liquid-gas critical point and
described by the nearest-neighbor Ising model in three dimensions. By operating
near a critical point, neural circuits can optimize the trade-off between
maximizing information transmission in a given environment and quickly adapting
to a new environment.