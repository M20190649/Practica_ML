Input nonlinearities can shape beyond-pairwise correlations and improve
  information transmission by neural populations
While recent recordings from neural populations show beyond-pairwise, or
higher-order correlations (HOC), we have little understanding of how HOC arise
from network interactions and of how they impact encoded information. Here, we
show that input nonlinearities imply HOC in spin-glass-type statistical models.
We then discuss one such model with parameterized pairwise- and higher-order
interactions, revealing conditions under which beyond-pairwise interactions
increase the mutual information between a given stimulus type and the
population responses. For jointly Gaussian stimuli, coding performance is
improved by shaping output HOC only when neural firing rates are constrained to
be low. For stimuli with skewed probability distributions (like natural image
luminances), performance improves for all firing rates. Our work suggests
surprising connections between nonlinear integration of neural inputs, stimulus
statistics, and normative theories of population coding. Moreover, it suggests
that the inclusion of beyond-pairwise interactions could improve the
performance of Boltzmann machines for machine learning and signal processing
applications.