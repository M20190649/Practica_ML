Cross-modal codification of images with auditory stimuli: a language for
  the visually impaired
In this study we describe a methodology to realize visual images cognition in
the broader sense, by a cross-modal stimulation through the auditory channel.
An original algorithm of conversion from bi-dimensional images to sounds has
been established and tested on several subjects. Our results show that subjects
where able to discriminate with a precision of 95\% different sounds
corresponding to different test geometric shapes. Moreover, after brief
learning sessions on simple images, subjects where able to recognize among a
group of 16 complex and never-trained images a single target by hearing its
acoustical counterpart. Rate of recognition was found to depend on image
characteristics, in 90% of the cases, subjects did better than choosing at
random. This study contribute to the understanding of cross-modal perception
and help for the realization of systems that use acoustical signals to help
visually impaired persons to recognize objects and improve navigation