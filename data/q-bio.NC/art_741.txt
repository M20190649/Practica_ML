Semantic vector space models predict neural responses to complex visual
  stimuli
Encoding models have as their objective to predict neural responses to
naturalistic stimuli with the aim of elucidating how sensory information is
represented in the brain. This prediction is achieved by representing the
stimulus in terms of a suitable feature space and using this feature space to
linearly predict observed neural responses. Here, we investigate to what extent
semantic vector space models can be used to predict neural responses to complex
visual stimuli. We show that these models provide good predictions of neural
responses in downstream visual areas, improving significantly over a low-level
control model based on Gabor wavelet pyramids. The outlined approach provides a
new way to model and map high-level semantic representations across cortex.