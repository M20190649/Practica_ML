On Human Consciousness
We consider the implications of the mathematical analysis of
neurone-to-neurone dynamical complex networks. We show how the dynamical
behaviour of small scale strongly connected networks lead naturally to
non-binary information processing and thus multiple hypothesis decision making,
even at the very lowest level of the brain's architecture. In turn we build on
these ideas to address the hard problem of consciousness. We discuss how a
proposed "dual hierarchy model", made up form of both external perceived,
physical, elements of increasing complexity, and internal mental elements
(experiences), may support a leaning and evolving consciousness. We discuss the
idea that a human brain ought to be able to re-conjure subjective mental
feelings at will and thus these cannot depend on internal nose (chatter) or
internal instability-driven activity. An immediate consequence of this model,
grounded in dynamical systems and non-binary information processing, is that
finite human brains must always be learning or forgetteing and that any
possible subjective internal feeling that may be idealised with a countable
infinity of facets, can never be learned by zombies or automata: though it can
be experienced more and more fully by an evolving brain (yet never in totality,
not even in a lifetime).