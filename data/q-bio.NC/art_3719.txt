A replica free evaluation of the neuronal population information with
  mixed continuous and discrete stimuli: from the linear to the asymptotic
  regime
Recent studies have explored theoretically the ability of populations of
neurons to carry information about a set of stimuli, both in the case of purely
discrete or purely continuous stimuli, and in the case of multidimensional
continuous angular and discrete correlates, in presence of additional quenched
disorder in the distribution. An analytical expression for the mutual
information has been obtained in the limit of large noise by means of the
replica trick. Here we show that the same results can actually be obtained in
most cases without the use of replicas, by means of a much simpler expansion of
the logarithm. Fitting the theoretical model to real neuronal data, we show
that the introduction of correlations in the quenched disorder improves the
fit, suggesting a possible role of signal correlations-actually detected in
real data- in a redundant code. We show that even in the more difficult
analysis of the asymptotic regime, an explicit expression for the mutual
information can be obtained without resorting to the replica trick despite the
presence of quenched disorder, both with a gaussian and with a more realistic
thresholded-gaussian model. When the stimuli are mixed continuous and discrete,
we find that with both models the information seem to grow logarithmically to
infinity with the number of neurons and with the inverse of the noise, even
though the exact general dependence cannot be derived explicitly for the
thresholded gaussian model. In the large noise limit lower values of
information were obtained with the thresholded-gaussian model, for a fixed
value of the noise and of the population size. On the contrary, in the
asymptotic regime, with very low values of the noise, a lower information value
is obtained with the gaussian model.