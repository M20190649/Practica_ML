Consciousness: Here, There but Not Everywhere
The science of consciousness has made great strides by focusing on the
behavioral and neuronal correlates of experience. However, correlates are not
enough if we are to understand even basic neurological fact; nor are they of
much help in cases where we would like to know if consciousness is present:
patients with a few remaining islands of functioning cortex, pre-term infants,
non-mammalian species, and machines that are rapidly outperforming people at
driving, recognizing faces and objects, and answering difficult questions. To
address these issues, we need a theory of consciousness that specifies what
experience is and what type of physical systems can have it. Integrated
Information Theory (IIT) does so by starting from conscious experience via five
phenomenological axioms of existence, composition, information, integration,
and exclusion. From these it derives five postulates about the properties
required of physical mechanisms to support consciousness. The theory provides a
principled account of both the quantity and the quality of an individual
experience, and a calculus to evaluate whether or not a particular system of
mechanisms is conscious and of what. IIT explains a range of clinical and
laboratory findings, makes testable predictions, and extrapolates to unusual
conditions. The theory vindicates some panpsychist intuitions - consciousness
is an intrinsic, fundamental property, is graded, is common among biological
organisms, and even some very simple systems have some. However, unlike
panpsychism, IIT implies that not everything is conscious, for example group of
individuals or feed forward networks. In sharp contrast with widespread
functionalist beliefs, IIT implies that digital computers, even if their
behavior were to be functionally equivalent to ours, and even if they were to
run faithful simulations of the human brain, would experience next to nothing.