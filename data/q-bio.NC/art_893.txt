Computational models of long term plasticity and memory
Memory is often defined as the mental capacity of retaining information about
facts, events, procedures and more generally about any type of previous
experience. Memories are remembered as long as they influence our thoughts,
feelings, and behavior at the present time. Memory is also one of the
fundamental components of learning, our ability to acquire any type of
knowledge or skills. In the brain it is not easy to identify the physical
substrate of memory. Basically, any long-lasting alteration of a biochemical
process can be considered a form of memory, although some of these alterations
last only a few milliseconds, and most of them, if taken individually, cannot
influence our behavior. However, if we want to understand memory, we need to
keep in mind that memory is not a unitary phenomenon, and it certainly involves
several distinct mechanisms that operate at different spatial and temporal
levels. One of the goals of theoretical neuroscience is to try to understand
how these processes are orchestrated to store memories rapidly and preserve
them over a lifetime. Theorists have mostly focused on synaptic plasticity, as
it is one of the most studied memory mechanisms in experimental neuroscience
and it is known to be highly effective in training artificial neural networks
to perform real world tasks. Some of the synaptic plasticity models are purely
phenomenological, some others have been designed to solve computational
problems. In this article I will review some of these models and I will try to
identify computational principles that underlie memory storage and
preservation.