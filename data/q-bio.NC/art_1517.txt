The neural and cognitive architecture for learning from a small sample
Artificial intelligence algorithms are capable of fantastic exploits, yet
they are still grossly inefficient compared with the brain's ability to learn
from few exemplars or solve problems that have not been explicitly defined.
What is the secret that the evolution of human intelligence has unlocked?
Generalization is one answer, but there is more to it. The brain does not
directly solve difficult problems, it is able to recast them into new and more
tractable problems. Here we propose a model whereby higher cognitive functions
profoundly interact with reinforcement learning to drastically reduce the
degrees of freedom of the search space, simplifying complex problems and
fostering more efficient learning.