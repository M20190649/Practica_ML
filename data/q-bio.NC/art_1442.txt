How the visual system can detect feature homogeneity from spike
  latencies
We propose that homogeneous image regions may be used to quickly segment a
visual scene, when an object hypothesis is not yet available. In a cooperative
model of the konio-cellular and the parvo- or magno-cellular visual pathway of
primates, we demonstrate how homogeneity-selective responses can be gained from
LGN neurons using a spike-latency code, and how these responses can confine
edge detection to borders between mid-sized objects. We propose that
spike-latency-based homogeneity detection is a general neural principle that
may apply to any sensory feature and modality. The mechanism is sensitive to
exact spike timing, which makes it vulnerable to noise. Nevertheless we
demonstrate how the mechanism can be made robust against realistic levels of
neural cross talk in the brain. We show that biphasic synaptic events do yield
very sharp post synaptic currents that maintain good separation of homogeneity
responses in massively noisy environments. The same technique opens up a neural
method of tuning neurons to varying degrees of homogeneity. The simple neural
implementation, generality, robustness, and variable tuning make
homogeneity-detection an attractive scheme of computation in spiking neural
networks and in the brain.