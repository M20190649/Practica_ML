How the brain might work: statistics flowing in redundant population
  codes
It is widely believed that the brain performs approximate probabilistic
inference to estimate causal variables in the world from ambiguous sensory
data. To understand these computations, we need to analyze how information is
represented and transformed by the actions of nonlinear recurrent neural
networks. We propose that these probabilistic computations function by a
message-passing algorithm operating at the level of redundant neural
populations. To explain this framework, we review its underlying concepts,
including graphical models, sufficient statistics, and message-passing, and
then describe how these concepts could be implemented by recurrently connected
probabilistic population codes. The relevant information flow in these networks
will be most interpretable at the population level, particularly for redundant
neural codes. We therefore outline a general approach to identify the essential
features of a neural message-passing algorithm. Finally, we argue that to
reveal the most important aspects of these neural computations, we must study
large-scale activity patterns during moderately complex, naturalistic
behaviors.