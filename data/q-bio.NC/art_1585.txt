Visual novelty, curiosity, and intrinsic reward in machine learning and
  the brain
A strong preference for novelty emerges in infancy and is prevalent across
the animal kingdom. When incorporated into reinforcement-based machine learning
algorithms, visual novelty can act as an intrinsic reward signal that vastly
increases the efficiency of exploration and expedites learning, particularly in
situations where external rewards are difficult to obtain. Here we review
parallels between recent developments in novelty-driven machine learning
algorithms and our understanding of how visual novelty is computed and signaled
in the primate brain. We propose that in the visual system, novelty
representations are not configured with the principal goal of detecting novel
objects, but rather with the broader goal of flexibly generalizing novelty
information across different states in the service of driving novelty-based
learning.