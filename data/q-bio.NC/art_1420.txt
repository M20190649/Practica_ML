Task-dependent modulation of the visual sensory thalamus assists
  visual-speech recognition
The cerebral cortex modulates early sensory processing via feed-back
connections to sensory pathway nuclei. The functions of this top-down
modulation for human behavior are poorly understood. Here, we show that
top-down modulation of the visual sensory thalamus (the lateral geniculate
body, LGN) is involved in visual-speech recognition. In two independent
functional magnetic resonance imaging (fMRI) studies, LGN response increased
when participants processed fast-varying features of articulatory movements
required for visual-speech recognition, as compared to temporally more stable
features required for face identification with the same stimulus material. The
LGN response during the visual-speech task correlated positively with the
visual-speech recognition scores across participants. In addition, the
task-dependent modulation was present for speech movements and did not occur
for control conditions involving non-speech biological movements. In
face-to-face communication, visual speech recognition is used to enhance or
even enable understanding what is said. Speech recognition is commonly
explained in frameworks focusing on cerebral cortex areas. Our findings suggest
that task-dependent modulation at subcortical sensory stages has an important
role for communication: Together with similar findings in the auditory modality
the findings imply that task-dependent modulation of the sensory thalami is a
general mechanism to optimize speech recognition.