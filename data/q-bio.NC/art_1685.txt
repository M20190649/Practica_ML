Blocking facial mimicry selectively alters early stages of facial
  expression processing
Simulation models of facial expressions suggest that posterior visual areas
and brain areas underpinning sensorimotor simulations might interact to improve
facial expression processing. According to these models, facial mimicry may
contribute to the visual perceptual processing of facial expressions by
influencing early stages of face processing, thus playing a crucial role in
understanding the observed emotion. The aim of the present study was to assess
whether and how early sensorimotor simulation influences face structural
encoding/processing. A secondary aim was to investigate whether there is a
relationship between alexithymic traits and sensorimotor simulation as a
mechanism for fine facial expression discrimination. In order to examine the
time-course of face processing, we monitored P1 and N170 components of the
event-related potentials (ERP) in participants performing a fine discrimination
task of facial expressions. An animal discrimination task was implemented as a
control condition. In half of the experiment, participants could freely use
their facial mimicry whereas, in the other half, they had their facial mimicry
blocked by a gel. Our results revealed that the P1 ERP component was not
modulated by the mimicry manipulation while the N170 amplitude was larger in
the blocked mimicry condition when compared to the free mimicry condition
selectively for the face stimuli. Interestingly, this modulation interacted
with the alexithymic traits, with a reduction of the N170 amplitude modulation
as a function of the facial mimicry manipulation for participants with the
highest levels of alexithymic traits. These results demonstrate that
sensorimotor simulation influences visual processing of facial expressions at
early stages and that participants with higher alexithymic traits tend to
underutilize the sensorimotor simulation system.