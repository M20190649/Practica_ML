Visual Motion Onset Brain-computer Interface
The paper presents a study of two novel visual motion onset stimulus-based
brain-computer interfaces (vmoBCI). Two settings are compared with afferent and
efferent to a computer screen center motion patterns. Online vmoBCI experiments
are conducted in an oddball event-related potential (ERP) paradigm allowing for
"aha-responses" decoding in EEG brainwaves. A subsequent stepwise linear
discriminant analysis classification (swLDA) classification accuracy comparison
is discussed based on two inter-stimulus-interval (ISI) settings of 700 and 150
ms in two online vmoBCI applications with six and eight command settings. A
research hypothesis of classification accuracy non-significant differences with
various ISIs is confirmed based on the two settings of 700 ms and 150 ms, as
well as with various numbers of ERP response averaging scenarios. The efferent
in respect to display center visual motion patterns allowed for a faster
interfacing and thus they are recommended as more suitable for the
no-eye-movements requiring visual BCIs.