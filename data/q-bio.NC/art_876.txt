Hierarchical Neural Representation of Dreamed Objects Revealed by Brain
  Decoding with Deep Neural Network Features
Dreaming is generally thought to be generated by spontaneous brain activity
during sleep with patterns common to waking experience. This view is supported
by a recent study demonstrating that dreamed objects can be predicted from
brain activity during sleep using statistical decoders trained with
stimulus-induced brain activity. However, it remains unclear whether and how
visual image features associated with dreamed objects are represented in the
brain. In this study, we used a deep neural network (DNN) model for object
recognition as a proxy for hierarchical visual feature representation, and DNN
features for dreamed objects were analyzed with brain decoding of fMRI data
collected during dreaming. The decoders were first trained with
stimulus-induced brain activity labeled with the feature values of the stimulus
image from multiple DNN layers. The decoders were then used to decode DNN
features from the dream fMRI data, and the decoded features were compared with
the averaged features of each object category calculated from a large-scale
image database. We found that the feature values decoded from the dream fMRI
data positively correlated with those associated with dreamed object categories
at mid- to high-level DNN layers. Using the decoded features, the dreamed
object category could be identified at above-chance levels by matching them to
the averaged features for candidate categories. The results suggest that
dreaming recruits hierarchical visual feature representations associated with
objects, which may support phenomenal aspects of dream experience.