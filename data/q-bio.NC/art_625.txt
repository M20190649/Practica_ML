Estimating Information-Theoretic Quantities
Information theory is a practical and theoretical framework developed for the
study of communication over noisy channels. Its probabilistic basis and
capacity to relate statistical structure to function make it ideally suited for
studying information flow in the nervous system. It has a number of useful
properties: it is a general measure sensitive to any relationship, not only
linear effects; it has meaningful units which in many cases allow direct
comparison between different experiments; and it can be used to study how much
information can be gained by observing neural responses in single trials,
rather than in averages over multiple trials. A variety of information
theoretic quantities are in common use in neuroscience - (see entry "Summary of
Information-Theoretic Quantities"). Estimating these quantities in an accurate
and unbiased way from real neurophysiological data frequently presents
challenges, which are explained in this entry.