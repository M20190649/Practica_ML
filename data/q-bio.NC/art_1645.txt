Decoding hand kinematics from population responses in sensorimotor
  cortex during grasping
The hand, a complex effector comprising dozens of degrees of freedom of
movement, endows us with the ability to flexibly, precisely, and effortlessly
interact with objects. The neural signals associated with dexterous hand
movements in primary motor cortex (M1) and somatosensory cortex (SC) have
received comparatively less attention than have those that are associated with
proximal limb control. To fill this gap, we trained three monkeys to grasp
objects varying in size, shape and orientation while tracking their hand
postures and recording single-unit activity from M1 and SC. We then decoded
their hand kinematics across 30 joints from population activity in these areas.
We found that we could accurately decode kinematics with a small number of
neural signals and that performance was higher for decoding joint angles than
joint angular velocities, in contrast to what has been found with proximal limb
decoders. We conclude that cortical signals can be used for dexterous hand
control in brain machine interface applications and that postural
representations in SC may be exploited via intracortical stimulation to close
the sensorimotor loop.