Which Neural Network Architecture matches Human Behavior in Artificial
  Grammar Learning?
In recent years artificial neural networks achieved performance close to or
better than humans in several domains: tasks that were previously human
prerogatives, such as language processing, have witnessed remarkable
improvements in state of the art models. One advantage of this technological
boost is to facilitate comparison between different neural networks and human
performance, in order to deepen our understanding of human cognition. Here, we
investigate which neural network architecture (feed-forward vs. recurrent)
matches human behavior in artificial grammar learning, a crucial aspect of
language acquisition. Prior experimental studies proved that artificial
grammars can be learnt by human subjects after little exposure and often
without explicit knowledge of the underlying rules. We tested four grammars
with different complexity levels both in humans and in feedforward and
recurrent networks. Our results show that both architectures can 'learn' (via
error back-propagation) the grammars after the same number of training
sequences as humans do, but recurrent networks perform closer to humans than
feedforward ones, irrespective of the grammar complexity level. Moreover,
similar to visual processing, in which feedforward and recurrent architectures
have been related to unconscious and conscious processes, our results suggest
that explicit learning is best modeled by recurrent architectures, whereas
feedforward networks better capture the dynamics involved in implicit learning.