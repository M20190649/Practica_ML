Capturing human categorization of natural images at scale by combining
  deep networks and cognitive models
Human categorization is one of the most important and successful targets of
cognitive modeling in psychology, yet decades of development and assessment of
competing models have been contingent on small sets of simple, artificial
experimental stimuli. Here we extend this modeling paradigm to the domain of
natural images, revealing the crucial role that stimulus representation plays
in categorization and its implications for conclusions about how people form
categories. Applying psychological models of categorization to natural images
required two significant advances. First, we conducted the first large-scale
experimental study of human categorization, involving over 500,000 human
categorization judgments of 10,000 natural images from ten non-overlapping
object categories. Second, we addressed the traditional bottleneck of
representing high-dimensional images in cognitive models by exploring the best
of current supervised and unsupervised deep and shallow machine learning
methods. We find that selecting sufficiently expressive, data-driven
representations is crucial to capturing human categorization, and using these
representations allows simple models that represent categories with abstract
prototypes to outperform the more complex memory-based exemplar accounts of
categorization that have dominated in studies using less naturalistic stimuli.