Estimations of Integrated Information Based on Algorithmic Complexity
  and Dynamic Querying
The concept of information has emerged as a language in its own right,
bridging several disciplines that analyze natural phenomena and man-made
systems. Integrated information has been introduced as a metric to quantify the
amount of information generated by a system beyond the information generated by
its elements. Yet, this intriguing notion comes with the price of being
prohibitively expensive to calculate, since the calculations require an
exponential number of sub-divisions of a system. Here we introduce a novel
framework to connect algorithmic randomness and integrated information and a
numerical method for estimating integrated information using a perturbation
test rooted in algorithmic information dynamics. This method quantifies the
change in program size of a system when subjected to a perturbation. The
intuition behind is that if an object is random then random perturbations have
little to no effect to what happens when a shorter program but when an object
has the ability to move in both directions (towards or away from randomness) it
will be shown to be better integrated as a measure of sophistication telling
apart randomness and simplicity from structure. We show that an object with a
high integrated information value is also more compressible, and is, therefore,
more sensitive to perturbations. We find that such a perturbation test
quantifying compression sensitivity provides a system with a means to extract
explanations--causal accounts--of its own behaviour. Our technique can reduce
the number of calculations to arrive at some bounds or estimations, as the
algorithmic perturbation test guides an efficient search for estimating
integrated information. Our work sets the stage for a systematic exploration of
connections between algorithmic complexity and integrated information at the
level of both theory and practice.