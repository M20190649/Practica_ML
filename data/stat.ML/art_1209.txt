Gauging Variational Inference
Computing partition function is the most important statistical inference task
arising in applications of Graphical Models (GM). Since it is computationally
intractable, approximate methods have been used to resolve the issue in
practice, where mean-field (MF) and belief propagation (BP) are arguably the
most popular and successful approaches of a variational type. In this paper, we
propose two new variational schemes, coined Gauged-MF (G-MF) and Gauged-BP
(G-BP), improving MF and BP, respectively. Both provide lower bounds for the
partition function by utilizing the so-called gauge transformation which
modifies factors of GM while keeping the partition function invariant.
Moreover, we prove that both G-MF and G-BP are exact for GMs with a single loop
of a special structure, even though the bare MF and BP perform badly in this
case. Our extensive experiments, on complete GMs of relatively small size and
on large GM (up-to 300 variables) confirm that the newly proposed algorithms
outperform and generalize MF and BP.