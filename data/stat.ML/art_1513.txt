Composite Gaussian Processes: Scalable Computation and Performance
  Analysis
Gaussian process (GP) models provide a powerful tool for prediction but are
computationally prohibitive using large data sets. In such scenarios, one has
to resort to approximate methods. We derive an approximation based on a
composite likelihood approach using a general belief updating framework, which
leads to a recursive computation of the predictor as well as of learning the
hyper-parameters. We then provide an analysis of the derived composite GP model
in predictive and information-theoretic terms. Finally, we evaluate the
approximation with both synthetic data and a real-world application.