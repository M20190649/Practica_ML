Probing for sparse and fast variable selection with model-based boosting
We present a new variable selection method based on model-based gradient
boosting and randomly permuted variables. Model-based boosting is a tool to fit
a statistical model while performing variable selection at the same time. A
drawback of the fitting lies in the need of multiple model fits on slightly
altered data (e.g. cross-validation or bootstrap) to find the optimal number of
boosting iterations and prevent overfitting. In our proposed approach, we
augment the data set with randomly permuted versions of the true variables, so
called shadow variables, and stop the step-wise fitting as soon as such a
variable would be added to the model. This allows variable selection in a
single fit of the model without requiring further parameter tuning. We show
that our probing approach can compete with state-of-the-art selection methods
like stability selection in a high-dimensional classification benchmark and
apply it on gene expression data for the estimation of riboflavin production of
Bacillus subtilis.