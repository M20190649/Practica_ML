Kernel regression, minimax rates and effective dimensionality: beyond
  the regular case
We investigate if kernel regularization methods can achieve minimax
convergence rates over a source condition regularity assumption for the target
function. These questions have been considered in past literature, but only
under specific assumptions about the decay, typically polynomial, of the
spectrum of the the kernel mapping covariance operator. In the perspective of
distribution-free results, we investigate this issue under much weaker
assumption on the eigenvalue decay, allowing for more complex behavior that can
reflect different structure of the data at different scales.