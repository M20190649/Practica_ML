Universal Consistency and Robustness of Localized Support Vector
  Machines
The massive amount of available data potentially used to discover patters in
machine learning is a challenge for kernel based algorithms with respect to
runtime and storage capacities. Local approaches might help to relieve these
issues. From a statistical point of view local approaches allow additionally to
deal with different structures in the data in different ways. This paper
analyses properties of localized kernel based, non-parametric statistical
machine learning methods, in particular of support vector machines (SVMs) and
methods close to them. We will show there that locally learnt kernel methods
are universal consistent. Furthermore, we give an upper bound for the maxbias
in order to show statistical robustness of the proposed method.