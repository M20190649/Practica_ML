Sensitivity Analysis for Predictive Uncertainty in Bayesian Neural
  Networks
We derive a novel sensitivity analysis of input variables for predictive
epistemic and aleatoric uncertainty. We use Bayesian neural networks with
latent variables as a model class and illustrate the usefulness of our
sensitivity analysis on real-world datasets. Our method increases the
interpretability of complex black-box probabilistic models.