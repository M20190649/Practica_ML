Optimal rates for the regularized learning algorithms under general
  source condition
We consider the learning algorithms under general source condition with the
polynomial decay of the eigenvalues of the integral operator in vector-valued
function setting. We discuss the upper convergence rates of Tikhonov
regularizer under general source condition corresponding to increasing monotone
index function. The convergence issues are studied for general regularization
schemes by using the concept of operator monotone index functions in minimax
setting. Further we also address the minimum possible error for any learning
algorithm.