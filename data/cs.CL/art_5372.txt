Phoneme Level Language Models for Sequence Based Low Resource ASR
Building multilingual and crosslingual models help bring different languages
together in a language universal space. It allows models to share parameters
and transfer knowledge across languages, enabling faster and better adaptation
to a new language. These approaches are particularly useful for low resource
languages. In this paper, we propose a phoneme-level language model that can be
used multilingually and for crosslingual adaptation to a target language. We
show that our model performs almost as well as the monolingual models by using
six times fewer parameters, and is capable of better adaptation to languages
not seen during training in a low resource scenario. We show that these
phoneme-level language models can be used to decode sequence based
Connectionist Temporal Classification (CTC) acoustic model outputs to obtain
comparable word error rates with Weighted Finite State Transducer (WFST) based
decoding in Babel languages. We also show that these phoneme-level language
models outperform WFST decoding in various low-resource conditions like
adapting to a new language and domain mismatch between training and testing
data.