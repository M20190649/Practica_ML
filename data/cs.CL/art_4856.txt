An Empirical Study on Crosslingual Transfer in Probabilistic Topic
  Models
Probabilistic topic modeling is a popular choice as the first step of
crosslingual tasks to enable knowledge transfer and extract multilingual
features. While many multilingual topic models have been developed, their
assumptions on the training corpus are quite varied, and it is not clear how
well the models can be applied under various training conditions. In this
paper, we systematically study the knowledge transfer mechanisms behind
different multilingual topic models, and through a broad set of experiments
with four models on ten languages, we provide empirical insights that can
inform the selection and future development of multilingual topic models.