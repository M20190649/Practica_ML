Neural Network Acceptability Judgments
In this work, we explore the ability of artificial neural networks to judge
the grammatical acceptability of a sentence. Machine learning research of this
kind is well placed to answer important open questions about the role of prior
linguistic bias in language acquisition by providing a test for the Poverty of
the Stimulus Argument. In service of this goal, we introduce the Corpus of
Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as
grammatical or ungrammatical by expert linguists. We train several recurrent
neural networks to do binary acceptability classification. These models set a
baseline for the task. Error-analysis testing the models on specific
grammatical phenomena reveals that they learn some systematic grammatical
generalizations like subject-verb-object word order without any grammatical
supervision. We find that neural sequence models show promise on the
acceptability classification task. However, human-like performance across a
wide range of grammatical constructions remains far off.