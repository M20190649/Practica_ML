A Comprehensive Exploration on WikiSQL with Table-Aware Word
  Contextualization
WikiSQL is the task of mapping a natural language question to a SQL query
given a table from a Wikipedia article. We first show that learning highly
context- and table-aware word representations is arguably the most important
consideration for achieving a high accuracy in the task. We explore three
variants of BERT-based architecture and our best model outperforms the previous
state of the art by 8.2% and 2.5% in logical form and execution accuracy,
respectively. We provide a detailed analysis of the models to guide how word
contextualization can be utilized in a such semantic parsing task. We then
argue that this score is near the upper bound in WikiSQL, where we observe that
the most of the evaluation errors are due to wrong annotations. We also measure
human accuracy on a portion of the dataset and show that our model exceeds the
human performance, at least by 1.4% execution accuracy.