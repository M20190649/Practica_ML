Learning to Explicitate Connectives with Seq2Seq Network for Implicit
  Discourse Relation Classification
Implicit discourse relation classification is one of the most difficult steps
in discourse parsing. The difficulty stems from the fact that the coherence
relation must be inferred based on the content of the discourse relational
arguments. Therefore, an effective encoding of the relational arguments is of
crucial importance. We here propose a new model for implicit discourse relation
classification, which consists of a classifier, and a sequence-to-sequence
model which is trained to generate a representation of the discourse relational
arguments by trying to predict the relational arguments including a suitable
implicit connective. Training is possible because such implicit connectives
have been annotated as part of the PDTB corpus. Along with a memory network,
our model could generate more refined representations for the task. And on the
now standard 11-way classification, our method outperforms previous state of
the art systems on the PDTB benchmark on multiple settings including cross
validation.