Multiple Range-Restricted Bidirectional Gated Recurrent Units with
  Attention for Relation Classification
Most of neural approaches to relation classification have focused on finding
short patterns that represent the semantic relation using Convolutional Neural
Networks (CNNs) and those approaches have generally achieved better
performances than using Recurrent Neural Networks (RNNs). In a similar
intuition to the CNN models, we propose a novel RNN-based model that strongly
focuses on only important parts of a sentence using multiple range-restricted
bidirectional layers and attention for relation classification. Experimental
results on the SemEval-2010 relation classification task show that our model is
comparable to the state-of-the-art CNN-based and RNN-based models that use
additional linguistic information.