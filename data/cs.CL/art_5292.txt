Context in Neural Machine Translation: A Review of Models and
  Evaluations
This review paper discusses how context has been used in neural machine
translation (NMT) in the past two years (2017-2018). Starting with a brief
retrospect on the rapid evolution of NMT models, the paper then reviews studies
that evaluate NMT output from various perspectives, with emphasis on those
analyzing limitations of the translation of contextual phenomena. In a
subsequent version, the paper will then present the main methods that were
proposed to leverage context for improving translation quality, and
distinguishes methods that aim to improve the translation of specific phenomena
from those that consider a wider unstructured context.