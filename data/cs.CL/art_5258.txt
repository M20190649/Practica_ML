Human few-shot learning of compositional instructions
People learn in fast and flexible ways that have not been emulated by
machines. Once a person learns a new verb "dax," he or she can effortlessly
understand how to "dax twice," "walk and dax," or "dax vigorously." There have
been striking recent improvements in machine learning for natural language
processing, yet the best algorithms require vast amounts of experience and
struggle to generalize new concepts in compositional ways. To better understand
these distinctively human abilities, we study the compositional skills of
people through language-like instruction learning tasks. Our results show that
people can learn and use novel functional concepts from very few examples
(few-shot learning), successfully applying familiar functions to novel inputs.
People can also compose concepts in complex ways that go beyond the provided
demonstrations. Two additional experiments examined the assumptions and
inductive biases that people make when solving these tasks, revealing three
biases: mutual exclusivity, one-to-one mappings, and iconic concatenation. We
discuss the implications for cognitive modeling and the potential for building
machines with more human-like language learning capabilities.