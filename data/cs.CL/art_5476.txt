Absit invidia verbo: Comparing Deep Learning methods for offensive
  language
This document describes our approach to building an Offensive Language
Classifier. More specifically, the OffensEval 2019 competition required us to
build three classifiers with slightly different goals:
  - Offensive language identification: would classify a tweet as offensive or
not.
  - Automatic categorization of offense types: would recognize if the target of
the offense was an individual or not.
  - Offense target identification: would identify the target of the offense
between an individual, group or other.
  In this report, we will discuss the different architectures, algorithms and
pre-processing strategies we tried, together with a detailed description of the
designs of our final classifiers and the reasons we choose them over others.
  We evaluated our classifiers on the official test set provided for the
OffenseEval 2019 competition, obtaining a macro-averaged F1-score of 0.7189 for
Task A, 0.6708 on Task B and 0.5442 on Task C.